{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day7_features_matrixFactv1.csv\n",
      "day8_features_matrixFactv1.csv\n",
      "day9_features_matrixFactv1.csv\n",
      "test_features_matrixFactv1.csv\n"
     ]
    }
   ],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/'\n",
    "file_format = '{}_features_matrixFactv1.csv'\n",
    "day_list = ['day7', 'day8', 'day9']\n",
    "df_dict = {}\n",
    "for file in ['day7', 'day8', 'day9', 'test']: \n",
    "    df_dict[file] = pd.read_csv(load_path+file_format.format(file))\n",
    "    print(file_format.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1688"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train\n",
    "del test\n",
    "del df_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Compensate Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get those only appears on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: app\n",
      "whole train index length is: 706\n",
      "test index length is: 417\n",
      "intersection index length is: 393\n",
      "missing length: 24\n",
      "---\n",
      "processing: device\n",
      "whole train index length is: 3475\n",
      "test index length is: 1985\n",
      "intersection index length is: 1661\n",
      "missing length: 324\n",
      "---\n",
      "processing: os\n",
      "whole train index length is: 800\n",
      "test index length is: 395\n",
      "intersection index length is: 339\n",
      "missing length: 56\n",
      "---\n",
      "processing: channel\n",
      "whole train index length is: 202\n",
      "test index length is: 178\n",
      "intersection index length is: 178\n",
      "missing length: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def intersec_category_test(df_train_all, df_test_all,  col_list):\n",
    "    missing = {}\n",
    "    for col in col_list:\n",
    "        print('processing: {}'.format(col))\n",
    "        train_index = set(df_train_all[col].value_counts().index)\n",
    "        test_index = set(df_test_all[col].value_counts().index)                 \n",
    "        inter_index = list(train_index.intersection(test_index))\n",
    "        print('whole train index length is: {}'.format(len(train_index)))\n",
    "        print('test index length is: {}'.format(len(test_index)))\n",
    "        print('intersection index length is: {}'.format(len(inter_index)))\n",
    "        miss_value = list(test_index - set(inter_index))\n",
    "        print('missing length: {}'.format(len(miss_value)))\n",
    "        missing[col] = list(miss_value)\n",
    "        print('---')\n",
    "    return missing\n",
    "col_list = [ 'app', 'device', 'os', 'channel']\n",
    "tmp_test = intersec_category_test(train.copy(), test.copy(), col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get those appear on train but not in day8 day9 day10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: app\n",
      "whole train index length is: 706\n",
      "test index length is: 417\n",
      "intersection index length is: 393\n",
      "missing length: 21\n",
      "---\n",
      "processing: device\n",
      "whole train index length is: 3475\n",
      "test index length is: 1985\n",
      "intersection index length is: 1661\n",
      "missing length: 224\n",
      "---\n",
      "processing: os\n",
      "whole train index length is: 800\n",
      "test index length is: 395\n",
      "intersection index length is: 339\n",
      "missing length: 39\n",
      "---\n",
      "processing: channel\n",
      "whole train index length is: 202\n",
      "test index length is: 178\n",
      "intersection index length is: 178\n",
      "missing length: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def intersec_category(df_train_all, df_test_all, df, col_list):\n",
    "    missing = {}\n",
    "    for col in col_list:\n",
    "        print('processing: {}'.format(col))\n",
    "        train_index = set(df_train_all[col].value_counts().index)\n",
    "        test_index = set(df_test_all[col].value_counts().index)                 \n",
    "        inter_index = list(train_index.intersection(test_index))\n",
    "        print('whole train index length is: {}'.format(len(train_index)))\n",
    "        print('test index length is: {}'.format(len(test_index)))\n",
    "        print('intersection index length is: {}'.format(len(inter_index)))\n",
    "        miss_value = set(inter_index) - set(df[col].value_counts().index)\n",
    "        print('missing length: {}'.format(len(miss_value)))\n",
    "        missing[col] = list(miss_value)\n",
    "        print('---')\n",
    "    return missing\n",
    "col_list = [ 'app', 'device', 'os', 'channel']\n",
    "tmp = intersec_category(train.copy(), test.copy(), pd.concat([df_dict['day7'],df_dict['day8'],df_dict['day9']]), col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_index = set(train.index) - set(df_dict['day7'].index) -set(df_dict['day8'].index) -set(df_dict['day9'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history = train.iloc[list(history_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    col = kwargs.pop('col')\n",
    "    diction = kwargs.pop('value_dict')\n",
    "    return df[col].apply(func, args=(col,diction,))\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "    \n",
    "def square(x):\n",
    "    return x**x\n",
    "\n",
    "def func(x, col, diction):\n",
    "    return x in diction[col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worker = 10\n",
    "# app = apply_by_multiprocessing(df_history, func, axis=1, workers=worker, col='app', value_dict=tmp)  \n",
    "app_test = apply_by_multiprocessing(test, func, axis=1, workers=worker, col='app', value_dict=tmp_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# app = df_history[app]\n",
    "app_test = test[app_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4436"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(app)\n",
    "len(app_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/compensate/'\n",
    "np.save(load_path+'app_onlyappearon_test.npy', app_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# device = apply_by_multiprocessing(df_history, func, axis=1, workers=worker, col='device', value_dict=tmp)  \n",
    "device_test = apply_by_multiprocessing(test, func, axis=1, workers=worker, col='device', value_dict=tmp_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# device = df_history[device]\n",
    "device_test = test[device_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77196"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(device)\n",
    "len(device_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/compensate/'\n",
    "np.save(load_path+'device_onlyappearon_test.npy', device_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os = apply_by_multiprocessing(df_history, func, axis=1, workers=worker, col='os', value_dict=tmp)  \n",
    "os_test = apply_by_multiprocessing(test, func, axis=1, workers=worker, col='os', value_dict=tmp_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os = df_history[os]\n",
    "os_test = test[os_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128743"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(os)\n",
    "len(os_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/compensate/'\n",
    "np.save(load_path+'os_onlyappearon_test.npy', os_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_comp = list(set(list(app_test.index.values) + list(device_test.index.values) + list(os_test.index.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130073"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/compensate/'\n",
    "np.save(load_path+'all_compen.npy', np.array(all_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comp = df_history.loc[all_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914634146341464"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_comp[df_comp.is_attributed == 0])/len(df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134999.99999999913"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18000000*(1-0.9925)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: app\n",
      "train index length is: 556\n",
      "test index length is: 417\n",
      "intersection index length is: 372\n",
      "---\n",
      "processing: device\n",
      "train index length is: 2438\n",
      "test index length is: 1985\n",
      "intersection index length is: 1437\n",
      "---\n",
      "processing: os\n",
      "train index length is: 492\n",
      "test index length is: 395\n",
      "intersection index length is: 300\n",
      "---\n",
      "processing: channel\n",
      "train index length is: 193\n",
      "test index length is: 178\n",
      "intersection index length is: 178\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def intersec_category(df_train_all, df_test_all, df, col_list):\n",
    "    for col in col_list:\n",
    "        print('processing: {}'.format(col))\n",
    "        train_index = set(df_train_all[col].value_counts().index)\n",
    "        test_index = set(df_test_all[col].value_counts().index)                 \n",
    "        inter_index = list(train_index.intersection(test_index))\n",
    "        print('train index length is: {}'.format(len(train_index)))\n",
    "        print('test index length is: {}'.format(len(test_index)))\n",
    "        print('intersection index length is: {}'.format(len(inter_index)))\n",
    "        index_map = pd.Series(inter_index, index=inter_index)\n",
    "        df.loc[:,col] = df[col].map(index_map).fillna(-1)\n",
    "        print('---')\n",
    "    return df\n",
    "col_list = [ 'app', 'device', 'os', 'channel']\n",
    "tmp = intersec_category(pd.concat([df_dict['day7'],df_dict['day8'],df_dict['day9']]), test.copy(), test.copy(),col_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### channel app os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = train['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = train.groupby(['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val - front\n",
    "total_length = len(train)\n",
    "val_length = 1600 * 10000\n",
    "train_length = 5900 * 10000\n",
    "\n",
    "valset = {}\n",
    "trainset = {}\n",
    "lgb_val = train.iloc[total_length-(val_length+train_length): total_length-train_length]\n",
    "lgb_train = train.iloc[total_length-train_length: ]\n",
    "\n",
    "for col in ['channel', 'app', 'os', 'device', 'ip']:\n",
    "    valset[col] = set(lgb_val[col].value_counts().index.values)\n",
    "#     valset[col] = set(train.loc[total_length-75000000: total_length-52500000,col].value_counts().index.values)\n",
    "    trainset[col] = set(lgb_train[col].value_counts().index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val - rear\n",
    "total_length = len(train)\n",
    "val_length = 2000 * 10000\n",
    "train_length = 5500 * 10000\n",
    "\n",
    "valset = {}\n",
    "trainset = {}\n",
    "lgb_val = train.iloc[total_length-val_length:]\n",
    "lgb_train = train.iloc[total_length-(val_length+train_length): total_length-val_length]\n",
    "\n",
    "for col in ['channel', 'app', 'os', 'device']:\n",
    "    valset[col] = set(lgb_val[col].value_counts().index.values)\n",
    "#     valset[col] = set(train.loc[total_length-75000000: total_length-52500000,col].value_counts().index.values)\n",
    "    trainset[col] = set(lgb_train[col].value_counts().index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21500000\n",
      "0\n",
      "21500000\n",
      "55000000\n"
     ]
    }
   ],
   "source": [
    "#### val\n",
    "total_length = len(train)\n",
    "val_length = 2150 * 10000\n",
    "train_length = 5500 * 10000\n",
    "val_front = 1\n",
    "val_front_length = int(val_length * val_front)\n",
    "val_rear_length = val_length - val_front_length\n",
    "valset = {}\n",
    "trainset = {}\n",
    "\n",
    "lgb_val_front = train.iloc[total_length-(val_length+train_length): total_length-(val_length+train_length) + val_front_length]\n",
    "print(len(lgb_val_front))\n",
    "lgb_val_rear = train.iloc[total_length-(val_rear_length):]\n",
    "print(len(lgb_val_rear))\n",
    "lgb_val = pd.concat([lgb_val_front,lgb_val_rear])\n",
    "lgb_train = train.iloc[total_length-(val_length+train_length) + val_front_length: total_length-(val_rear_length)]\n",
    "\n",
    "print(len(lgb_val))\n",
    "print(len(lgb_train))\n",
    "\n",
    "for col in ['channel', 'app', 'os', 'device']:\n",
    "    trainset[col] = set(lgb_train[col].value_counts().index.values)\n",
    "    valset[col] = set(lgb_val[col].value_counts().index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In val not in train\n",
    "\n",
    "app - 5%  \n",
    "device - 16.3%  \n",
    "os - 14.1%  \n",
    "channel - 0.0%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\n",
      "0.06005221932114883\n",
      "-------\n",
      "device\n",
      "0.1453055141579732\n",
      "-------\n",
      "os\n",
      "0.1411042944785276\n",
      "-------\n",
      "channel\n",
      "0.011428571428571429\n",
      "-------\n",
      "ip\n",
      "0.48494051346274264\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for col in [ 'app', 'device', 'os', 'channel','ip']:\n",
    "    print(col)\n",
    "    pro = len(valset[col] - trainset[col]) / len(valset[col])\n",
    "    print(pro)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valset[col] - trainset[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valset['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
