{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')\n",
    "\n",
    "###\n",
    "from sklearn.model_selection import KFold\n",
    "K = 3\n",
    "\n",
    "kf = KFold(n_splits=K, shuffle = False)\n",
    "history_index = []\n",
    "train_index = []\n",
    "for h,t in kf.split(train):\n",
    "    history_index.append(h)\n",
    "    train_index.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184903890"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_index[2])\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    group = get_group(df_train, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    return group.map(mean_map).fillna(-1)\n",
    "\n",
    "\n",
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)\n",
    "\n",
    "\n",
    "def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    df_reverse = df_train.sort_values([timecol], ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse[timecol]):\n",
    "        if g in next_heard:\n",
    "            result.append(next_heard[g] - t)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    group = get_group(df_train, cols)\n",
    "\n",
    "    last_heard = {}\n",
    "    for t, g in zip(df_train[timecol], group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfrompast(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfromfuture(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_values([timecol], ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def lasttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    last_time = df_train.groupby(group)[timecol].last()\n",
    "    \n",
    "    return group.map(last_time) - df_train[timecol]\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', 'app',  'device', 'os', 'channel', 'day',  'hour','intesthh']\n",
    "\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(df_history[col].max(),df_all[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count function\n",
      "all 1: \t fold:0 \t ip_count \t size: 3.214496470987797 \t length: 61634630\n",
      "count function\n",
      "all 2: \t fold:0 \t app_count \t size: 3.673710249364376 \t length: 61634630\n",
      "count function\n",
      "all 3: \t fold:0 \t device_count \t size: 4.132924027740955 \t length: 61634630\n",
      "count function\n",
      "all 4: \t fold:0 \t os_count \t size: 4.592137806117535 \t length: 61634630\n",
      "count function\n",
      "all 5: \t fold:0 \t channel_count \t size: 5.051351584494114 \t length: 61634630\n",
      "count function\n",
      "all 6: \t fold:0 \t day_count \t size: 5.510565362870693 \t length: 61634630\n",
      "count function\n",
      "all 7: \t fold:0 \t hour_count \t size: 5.9697791412472725 \t length: 61634630\n",
      "count function\n",
      "all 8: \t fold:0 \t intesthh_count \t size: 6.428992919623852 \t length: 61634630\n",
      "count function\n",
      "all 9: \t fold:0 \t ip_app_count \t size: 6.888206698000431 \t length: 61634630\n",
      "count function\n",
      "all 10: \t fold:0 \t ip_device_count \t size: 7.34742047637701 \t length: 61634630\n",
      "count function\n",
      "all 11: \t fold:0 \t ip_os_count \t size: 7.80663425475359 \t length: 61634630\n",
      "count function\n",
      "all 12: \t fold:0 \t ip_channel_count \t size: 8.265848033130169 \t length: 61634630\n",
      "count function\n",
      "all 13: \t fold:0 \t ip_day_count \t size: 8.725061811506748 \t length: 61634630\n",
      "count function\n",
      "all 14: \t fold:0 \t ip_hour_count \t size: 9.184275589883327 \t length: 61634630\n",
      "count function\n",
      "all 15: \t fold:0 \t ip_intesthh_count \t size: 9.643489368259907 \t length: 61634630\n",
      "count function\n",
      "all 16: \t fold:0 \t app_device_count \t size: 10.102703146636486 \t length: 61634630\n",
      "count function\n",
      "all 17: \t fold:0 \t app_os_count \t size: 10.561916925013065 \t length: 61634630\n",
      "count function\n",
      "all 18: \t fold:0 \t app_channel_count \t size: 11.021130703389645 \t length: 61634630\n",
      "count function\n",
      "all 19: \t fold:0 \t app_day_count \t size: 11.480344481766224 \t length: 61634630\n",
      "count function\n",
      "all 20: \t fold:0 \t app_hour_count \t size: 11.939558260142803 \t length: 61634630\n",
      "count function\n",
      "all 21: \t fold:0 \t app_intesthh_count \t size: 12.398772038519382 \t length: 61634630\n",
      "count function\n",
      "all 22: \t fold:0 \t device_os_count \t size: 12.857985816895962 \t length: 61634630\n",
      "count function\n",
      "all 23: \t fold:0 \t device_channel_count \t size: 13.317199595272541 \t length: 61634630\n",
      "count function\n",
      "all 24: \t fold:0 \t device_day_count \t size: 13.77641337364912 \t length: 61634630\n",
      "count function\n",
      "all 25: \t fold:0 \t device_hour_count \t size: 14.2356271520257 \t length: 61634630\n",
      "count function\n",
      "all 26: \t fold:0 \t device_intesthh_count \t size: 14.694840930402279 \t length: 61634630\n",
      "count function\n",
      "all 27: \t fold:0 \t os_channel_count \t size: 15.154054708778858 \t length: 61634630\n",
      "count function\n",
      "all 28: \t fold:0 \t os_day_count \t size: 15.613268487155437 \t length: 61634630\n",
      "count function\n",
      "all 29: \t fold:0 \t os_hour_count \t size: 16.072482265532017 \t length: 61634630\n",
      "count function\n",
      "all 30: \t fold:0 \t os_intesthh_count \t size: 16.531696043908596 \t length: 61634630\n",
      "count function\n",
      "all 31: \t fold:0 \t channel_day_count \t size: 16.990909822285175 \t length: 61634630\n",
      "count function\n",
      "all 32: \t fold:0 \t channel_hour_count \t size: 17.450123600661755 \t length: 61634630\n",
      "count function\n",
      "all 33: \t fold:0 \t channel_intesthh_count \t size: 17.909337379038334 \t length: 61634630\n",
      "count function\n",
      "all 34: \t fold:0 \t day_hour_count \t size: 18.368551157414913 \t length: 61634630\n",
      "count function\n",
      "all 35: \t fold:0 \t day_intesthh_count \t size: 18.827764935791492 \t length: 61634630\n",
      "count function\n",
      "all 36: \t fold:0 \t hour_intesthh_count \t size: 19.28697871416807 \t length: 61634630\n",
      "count function\n",
      "all 37: \t fold:0 \t ip_app_device_count \t size: 19.74619249254465 \t length: 61634630\n",
      "count function\n",
      "all 38: \t fold:0 \t ip_app_os_count \t size: 20.20540627092123 \t length: 61634630\n",
      "count function\n",
      "all 39: \t fold:0 \t ip_app_channel_count \t size: 20.66462004929781 \t length: 61634630\n",
      "count function\n",
      "all 40: \t fold:0 \t ip_app_day_count \t size: 21.12383382767439 \t length: 61634630\n",
      "count function\n",
      "all 41: \t fold:0 \t ip_app_hour_count \t size: 21.583047606050968 \t length: 61634630\n",
      "count function\n",
      "all 42: \t fold:0 \t ip_app_intesthh_count \t size: 22.042261384427547 \t length: 61634630\n",
      "count function\n",
      "all 43: \t fold:0 \t ip_device_os_count \t size: 22.501475162804127 \t length: 61634630\n",
      "count function\n",
      "all 44: \t fold:0 \t ip_device_channel_count \t size: 22.960688941180706 \t length: 61634630\n",
      "count function\n",
      "all 45: \t fold:0 \t ip_device_day_count \t size: 23.419902719557285 \t length: 61634630\n",
      "saving train -- train_fold0_count_0.csv\n"
     ]
    }
   ],
   "source": [
    "entry_size = 45\n",
    "counter = 0\n",
    "combine_col = ['ip', 'app',  'device', 'os', 'channel', 'day',  'hour','intesthh']\n",
    "base_col = [ 'app',  'device', 'os', 'channel', 'hour']\n",
    "for fold in range(K):\n",
    "    df_train = train.iloc[train_index[fold]]\n",
    "    df_history = train.iloc[history_index[fold]]\n",
    "    df_all = pd.concat([df_train, test])\n",
    "    for func in [count, mean, reversemean, time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff]:\n",
    "        save_train = df_train[base_col].copy()\n",
    "        save_test = test[base_col].copy()\n",
    "        entry_pressed = 0\n",
    "        entry_counter = 0\n",
    "        for num_col in [1,2,3,4,5]:\n",
    "            for cols in combinations(combine_col, num_col):\n",
    "                feature_name = col_name(cols, func=func)\n",
    "                if func.__name__ == count.__name__:\n",
    "                    print('count function')\n",
    "                    save_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "                    save_test[feature_name] = func(df_all, test, cols, target='is_attributed')\n",
    "                    \n",
    "                elif func.__name__ == mean.__name__:\n",
    "                    print('mean function')\n",
    "                    save_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                    save_test[feature_name] = func(train, test, cols, target='is_attributed')\n",
    "                    \n",
    "                else:\n",
    "                    print('time related function')\n",
    "                    save_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "                    save_test[feature_name] = func(test, test, cols, target='is_attributed')\n",
    "                    \n",
    "                entry_counter += 1\n",
    "                counter += 1\n",
    "                \n",
    "                all_str = 'all {}: \\t fold:{} \\t {} \\t size: {} \\t length: {}'.format(counter, fold, feature_name, sys.getsizeof(save_train)/ 1024 **3, len(save_train))\n",
    "                print(all_str)\n",
    "                with open('feature_all.txt', 'w') as text_file:\n",
    "                    text_file.write(all_str + '\\n')\n",
    "                \n",
    "                \n",
    "                \n",
    "                if entry_counter >= entry_size:\n",
    "                    \n",
    "                    train_file_name = 'train_fold{}_{}_{}.csv'.format(fold, func.__name__, entry_pressed)\n",
    "                    test_file_name = 'test_fold{}_{}_{}.csv'.format(fold, func.__name__, entry_pressed)\n",
    "                    print('saving train -- {}'.format(train_file_name))\n",
    "                    save_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/stacking/train/' + train_file_name, index=False)\n",
    "                    print('saving test -- {}'.format(test_file_name))\n",
    "                    save_test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/stacking/test/' + test_file_name, index=False)\n",
    "                    save_train = df_train[base_col].copy()\n",
    "                    save_test = test[base_col].copy()\n",
    "                    entry_pressed += 1\n",
    "                    entry_counter = 0\n",
    "                gc.collect()\n",
    "        print('saving file at end of function: {}'.format(func.__name__))\n",
    "        train_file_name = 'train_fold{}_{}_{}.csv'.format(fold, func.__name__, entry_pressed)\n",
    "        test_file_name = 'test_fold{}_{}_{}.csv'.format(fold, func.__name__, entry_pressed)\n",
    "        save_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/stacking/train/' + train_file_name, index=False)\n",
    "        save_test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/stacking/test/' + test_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
