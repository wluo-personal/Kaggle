{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load training index\n",
    "indexfile = '/home/kai/data/kaggle/talkingdata/wl/data/trainset/train_index_all_shuffle.npy'\n",
    "train_index = np.load(indexfile)\n",
    "### load validation index\n",
    "indexfile = '/home/kai/data/kaggle/talkingdata/wl/data/trainset/val_index_all_shuffle.npy'\n",
    "val_index = np.load(indexfile)\n",
    "\n",
    "\n",
    "\n",
    "### load feature cols\n",
    "import json as js\n",
    "featurefile = '/home/kai/data/kaggle/talkingdata/wl/data/features/feature_cols.json'\n",
    "with open(featurefile, 'r') as myjs:\n",
    "    added_features = js.load(myjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip_count',\n",
       " 'ip_minute_count',\n",
       " 'app_channel_count',\n",
       " 'ip_app_count',\n",
       " 'ip_app_hour_count',\n",
       " 'ip_second_count',\n",
       " 'ip_app_os_count',\n",
       " 'ip_device_hour_count',\n",
       " 'ip_os_hour_count',\n",
       " 'ip_day_hour_count',\n",
       " 'ip_channel_count',\n",
       " 'app_channel_day_count',\n",
       " 'ip_device_count',\n",
       " 'ip_day_count',\n",
       " 'ip_hour_count',\n",
       " 'ip_mean',\n",
       " 'app_os_channel_mean',\n",
       " 'hour_minute_second_mean',\n",
       " 'app_os_hour_mean',\n",
       " 'ip_second_mean',\n",
       " 'ip_app_device_mean',\n",
       " 'device_minute_second_mean',\n",
       " 'ip_app_mean',\n",
       " 'ip_channel_mean',\n",
       " 'device_minute_mean',\n",
       " 'app_channel_hour_mean',\n",
       " 'app_device_os_mean',\n",
       " 'device_os_hour_mean',\n",
       " 'ip_app_channel_mean',\n",
       " 'channel',\n",
       " 'app',\n",
       " 'os',\n",
       " 'device',\n",
       " 'second',\n",
       " 'minute',\n",
       " 'hour',\n",
       " 'ip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_index = list(set(range(len(train))) - set(train_index) - set(val_index))\n",
    "df_history = train.iloc[history_index].copy()\n",
    "df_train = train.iloc[train_index].copy()\n",
    "df_val = train.iloc[val_index].copy()\n",
    "\n",
    "\n",
    "df_all = pd.concat([df_train, df_val, test])\n",
    "train_length = len(df_train)\n",
    "val_length = len(df_val)\n",
    "test_length = len(test)\n",
    "\n",
    "import gc\n",
    "del train\n",
    "del test\n",
    "del df_train\n",
    "del df_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.597382061183453\n",
      "73790469\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(df_all)/ 1024 **3)\n",
    "print(len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['app', 'channel', 'day', 'device', 'hour', 'ip', 'is_attributed',\n",
       "       'minute', 'os', 'second', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(df_history[col].max(),df_all[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n",
    "\n",
    "import gc\n",
    "# del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 1000,\n",
       " 'channel': 1000,\n",
       " 'day': 100,\n",
       " 'device': 10000,\n",
       " 'hour': 100,\n",
       " 'ip': 1000000,\n",
       " 'minute': 100,\n",
       " 'os': 1000,\n",
       " 'second': 100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count\n",
    "plan 1. count from historical data  \n",
    "plan 2. count from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean\n",
    "mean P(target | feature combination)\n",
    "\n",
    "purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer))\n",
    "Get the conditional Probability only from historical data and apply to train data.\n",
    "\n",
    "P(replay | X feature combination) = P( replay & X feature combination) / P (X feature combination)  \n",
    "=(count(replay & X feature combination) / count(total)) / (count(X feature combination) / count(total))  \n",
    "= count(replay & X feature combination) / count(X feature combination)  \n",
    "= sum((replay & X feature combination)) / count(X feature combination)  \n",
    "= sum((replay or not replayed & X feature combination)) / count(X feature combination)# since replay is 1, not replay is 0  \n",
    "= sum( X feature combination) / count(X feature combination)  \n",
    "= mean(X feature combination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaller(num):\n",
    "    sca = 1\n",
    "    while num * sca < 1:\n",
    "        sca *= 10\n",
    "    return sca\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    # mean_map: key - encoding, value - target mean\n",
    "#     ### sca\n",
    "#     m_min = mean_map[mean_map > 0].min()\n",
    "#     sca = scaller(m_min)\n",
    "#     mean_map *= sca\n",
    "#     ###\n",
    "\n",
    "    return group.map(mean_map).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reversemean\n",
    "reverse mean P(feature combination | target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count function\n",
      "all 1:   ip_count   \t\t\t size: 7.147163897752762 G.\n",
      "mean function\n",
      "all 2:   ip_mean   \t\t\t size: 7.696945734322071 G.\n",
      "count function\n",
      "all 3:   ip_app_count   \t\t\t size: 8.24672757089138 G.\n",
      "mean function\n",
      "all 4:   ip_app_mean   \t\t\t size: 8.79650940746069 G.\n",
      "count function\n",
      "all 5:   ip_device_count   \t\t\t size: 9.346291244029999 G.\n",
      "count function\n",
      "all 6:   ip_channel_count   \t\t\t size: 9.896073080599308 G.\n",
      "mean function\n",
      "all 7:   ip_channel_mean   \t\t\t size: 10.445854917168617 G.\n",
      "count function\n",
      "all 8:   ip_day_count   \t\t\t size: 10.995636753737926 G.\n",
      "count function\n",
      "all 9:   ip_hour_count   \t\t\t size: 11.545418590307236 G.\n",
      "count function\n",
      "all 10:   ip_minute_count   \t\t\t size: 12.095200426876545 G.\n",
      "count function\n",
      "all 11:   ip_second_count   \t\t\t size: 12.644982263445854 G.\n",
      "mean function\n",
      "all 12:   ip_second_mean   \t\t\t size: 13.194764100015163 G.\n",
      "count function\n",
      "all 13:   app_channel_count   \t\t\t size: 13.744545936584473 G.\n",
      "mean function\n",
      "all 14:   device_minute_mean   \t\t\t size: 14.294327773153782 G.\n",
      "mean function\n",
      "all 15:   ip_app_device_mean   \t\t\t size: 14.844109609723091 G.\n",
      "count function\n",
      "all 16:   ip_app_os_count   \t\t\t size: 15.3938914462924 G.\n",
      "mean function\n",
      "all 17:   ip_app_channel_mean   \t\t\t size: 15.94367328286171 G.\n",
      "count function\n",
      "all 18:   ip_app_hour_count   \t\t\t size: 16.49345511943102 G.\n",
      "count function\n",
      "all 19:   ip_device_hour_count   \t\t\t size: 17.043236956000328 G.\n",
      "count function\n",
      "all 20:   ip_os_hour_count   \t\t\t size: 17.593018792569637 G.\n",
      "count function\n",
      "all 21:   ip_day_hour_count   \t\t\t size: 18.142800629138947 G.\n",
      "mean function\n",
      "all 22:   app_device_os_mean   \t\t\t size: 18.692582465708256 G.\n",
      "mean function\n",
      "all 23:   app_os_channel_mean   \t\t\t size: 19.242364302277565 G.\n",
      "mean function\n",
      "all 24:   app_os_hour_mean   \t\t\t size: 19.792146138846874 G.\n",
      "count function\n",
      "all 25:   app_channel_day_count   \t\t\t size: 20.341927975416183 G.\n",
      "mean function\n",
      "all 26:   app_channel_hour_mean   \t\t\t size: 20.891709811985493 G.\n",
      "mean function\n",
      "all 27:   device_os_hour_mean   \t\t\t size: 21.441491648554802 G.\n",
      "mean function\n",
      "all 28:   device_minute_second_mean   \t\t\t size: 21.99127348512411 G.\n",
      "mean function\n",
      "all 29:   hour_minute_second_mean   \t\t\t size: 22.54105532169342 G.\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel', \n",
    "              'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# combine_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "exception_list = []\n",
    "for num_col in [1,2,3]:\n",
    "    for cols in combinations(combine_col, num_col):\n",
    "#         for func in [count, mean]:\n",
    "        for func in [count, mean]:\n",
    "            feature_name = col_name(cols, func=func)\n",
    "            if feature_name in added_features:\n",
    "                counter += 1\n",
    "                if func.__name__ == count.__name__:\n",
    "                    print('count function')\n",
    "                    df_all[feature_name] = func(df_all, df_all, cols, target='is_attributed')\n",
    "                else:\n",
    "                    print('mean function')\n",
    "                    df_all[feature_name] = func(df_history, df_all, cols, target='is_attributed')\n",
    "                all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_all)/ 1024 **3)\n",
    "                print(all_str)\n",
    "                with open('feature_all.txt', 'w') as text_file:\n",
    "                    text_file.write(all_str + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18790469\n"
     ]
    }
   ],
   "source": [
    "target='is_attributed'\n",
    "train_col = added_features.copy()\n",
    "train_col.append(target)\n",
    "train = df_all.iloc[:train_length][train_col]\n",
    "val = df_all.iloc[train_length:train_length+val_length][train_col]\n",
    "test = df_all.iloc[train_length+val_length:][added_features]\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training saving done!\n",
      "val saving done!\n",
      "testing saving done!\n"
     ]
    }
   ],
   "source": [
    "train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_countAndmean_index_all_shuffle_0405.csv', index=False)\n",
    "print('training saving done!')\n",
    "val.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/val_countAndmean_index_all_shuffle_0405.csv', index=False)\n",
    "print('val saving done!')\n",
    "test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_countAndmean_index_all_shuffle_0405.csv', index=False)\n",
    "print('testing saving done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18790469\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
