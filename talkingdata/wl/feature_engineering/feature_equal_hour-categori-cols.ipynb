{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train on Day7 Day8 Day9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv(path+'hourdistri.csv', index_col='Unnamed: 0')\n",
    "index = {}\n",
    "for day in ['day7', 'day8','day9']:\n",
    "    index[day] = list(range(df_hour.loc[day,'4start'], df_hour.loc[day,'6end0sec'])) + \\\n",
    "    list(range(df_hour.loc[day,'9start'], df_hour.loc[day,'11end0sec'])) + \\\n",
    "    list(range(df_hour.loc[day,'13start'], df_hour.loc[day,'15end0sec'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_index = list(set(train.index) - set(index['day7']) - set(index['day8']) - set(index['day9']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19534560\n",
      "20446743\n",
      "20898422\n",
      "18790469\n"
     ]
    }
   ],
   "source": [
    "for file in ['day7', 'day8', 'day9','test']: \n",
    "    print(len(df_dict[file]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    group = get_group(df_train, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    return group.map(mean_map).fillna(-0.01)\n",
    "\n",
    "\n",
    "def discre_encode(df_all, df, test,cols, target, scale=10):\n",
    "    group = get_group(df, cols)\n",
    "    group_test = get_group(test, cols)\n",
    "    group_all = get_group(df_all, cols)\n",
    "    mean_map = df_all.groupby(group_all)[target].mean()\n",
    "    # old \n",
    "#     mean_map = (mean_map * scale)\n",
    "    #### updated\n",
    "    mean_map_zero = mean_map[mean_map == 0]\n",
    "    mean_map_p = mean_map[mean_map > 0]\n",
    "    mean_map_p = (mean_map_p * scale) + 1\n",
    "    mean_map = pd.concat([mean_map_zero, mean_map_p])\n",
    "    #end\n",
    "    intersection = list(set(group_all.value_counts().index).intersection(set(group_test.value_counts().index)))\n",
    "    mean_map = mean_map.loc[intersection]\n",
    "    return group.map(mean_map).fillna(-1).astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "    \n",
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing day7\n",
      "processing ip\n",
      "processing channel\n",
      "processing device\n",
      "processing app\n",
      "processing os\n",
      "19534560\n",
      "==================================================\n",
      "processing day8\n",
      "processing ip\n",
      "processing channel\n",
      "processing device\n",
      "processing app\n",
      "processing os\n",
      "20446743\n",
      "==================================================\n",
      "processing day9\n",
      "processing ip\n",
      "processing channel\n",
      "processing device\n",
      "processing app\n",
      "processing os\n",
      "20898422\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "scale = 10\n",
    "target='is_attributed'\n",
    "for day in ['day7', 'day8','day9']:\n",
    "    print('processing {}'.format(day))\n",
    "    df_day = pd.DataFrame()\n",
    "    save_file_name = '{}_category_discrete_scale{}_newhistory.csv'.format(day,scale)\n",
    "    for col in ['ip', 'channel', 'device', 'app', 'os']:\n",
    "        print('processing {}'.format(col))\n",
    "        df_day[col] = discre_encode(train.iloc[history_index], train.iloc[index[day]],test, [col], target, scale)\n",
    "    save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "    df_day.to_csv(save_file_path, index=False)\n",
    "    print(len(df_day))\n",
    "    print('==================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test\n",
      "processing ip\n",
      "processing channel\n",
      "processing device\n",
      "processing app\n",
      "processing os\n",
      "18790469\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "scale = 10\n",
    "\n",
    "print('processing {}'.format('test'))\n",
    "df_day = pd.DataFrame()\n",
    "save_file_name = '{}_category_discrete_scale{}_newhistory.csv'.format('test',scale)\n",
    "\n",
    "for col in ['ip', 'channel', 'device', 'app', 'os']:\n",
    "    print('processing {}'.format(col))\n",
    "    df_day[col] = discre_encode(train, test,test, [col], target, scale)\n",
    "save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "df_day.to_csv(save_file_path, index=False)\n",
    "print(len(df_day))\n",
    "print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day7_category_discrete_scale10_new.csv\n",
      "day8_category_discrete_scale10_new.csv\n",
      "day9_category_discrete_scale10_new.csv\n",
      "test_category_discrete_scale10_new.csv\n"
     ]
    }
   ],
   "source": [
    "## load category col\n",
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/'\n",
    "file_format = '{}_category_discrete_scale10_new.csv'\n",
    "df_dict_cat = {}\n",
    "for file in ['day7', 'day8', 'day9','test']: \n",
    "    df_dict_cat[file] = pd.read_csv(load_path+file_format.format(file))\n",
    "    print(file_format.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1     16704143\n",
       "-1      1527103\n",
       " 0       553812\n",
       " 2         1945\n",
       " 3         1149\n",
       " 11         768\n",
       " 4          639\n",
       " 6          580\n",
       " 5          143\n",
       " 7           76\n",
       " 10          46\n",
       " 8           37\n",
       " 9           28\n",
       "Name: ip, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict_cat['test'].ip.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19534560\n",
      "20446743\n",
      "20898422\n",
      "18790469\n"
     ]
    }
   ],
   "source": [
    "for file in ['day7', 'day8', 'day9','test']: \n",
    "    print(len(df_dict_cat[file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
