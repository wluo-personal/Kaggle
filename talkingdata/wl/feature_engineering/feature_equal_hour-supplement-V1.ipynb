{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_supplement_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train on Day7 Day8 Day9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv(path+'hourdistri.csv', index_col='Unnamed: 0')\n",
    "index = {}\n",
    "for day in ['day7', 'day8','day9']:\n",
    "    index[day] = list(np.load(path+'{}_index.npy'.format(day)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "feature_count =  [\n",
    "                    'ip_day_hour_count',\n",
    "                    'ip_os_day_hour_count',\n",
    "                    'ip_app_day_hour_count',\n",
    "                    'ip_app_os_day_hour_count',\n",
    "                    'app_day_hour_count',\n",
    "                    'ip_device_os_count',\n",
    "                    'ip_app_device_os_count']\n",
    "\n",
    "feature_countself =  [\n",
    "                    'ip_day_hour_countself',\n",
    "                    'ip_os_day_hour_countself',\n",
    "                    'ip_app_day_hour_countself',\n",
    "                    'ip_app_os_day_hour_countself',\n",
    "                    'app_day_hour_countself',\n",
    "                    'ip_device_os_countself',\n",
    "                    'ip_app_device_os_countself']\n",
    "\n",
    "feature_mean = ['ip_device_os_mean',\n",
    "                'ip_app_device_os_mean', 'ip_app_device_mean', 'app_device_os_mean']\n",
    "\n",
    "\n",
    "feature_reversemean = []\n",
    "\n",
    "feature_time2nextclick = ['ip_device_os_time2nextclick',\n",
    "                            'ip_app_device_os_time2nextclick',\n",
    "                          'ip_app_device_time2nextclick']\n",
    "\n",
    "feature_time2previousclick = ['ip_device_os_time2previousclick', \n",
    "                                'ip_app_device_os_time2previousclick', \n",
    "                              'ip_app_device_time2previousclick']\n",
    "    \n",
    "    \n",
    "feature_countfromfuture = ['ip_device_os_countfromfuture',\n",
    "                            'ip_app_device_os_countfromfuture', \n",
    "                           'ip_app_device_countfromfuture',]\n",
    "\n",
    "feature_countfrompast = ['ip_device_os_countfrompast',\n",
    "                            'ip_app_device_os_countfrompast', \n",
    "                         'ip_app_device_countfrompast']\n",
    "    \n",
    "feature_lasttimediff =  ['ip_device_os_lasttimediff',\n",
    "                             'ip_app_device_os_lasttimediff', \n",
    "                         'ip_app_device_lasttimediff']\n",
    "\n",
    "feature_firsttimediff =  ['ip_device_os_firsttimediff',\n",
    "                             'ip_app_device_os_firsttimediff', \n",
    "                         'ip_app_device_firsttimediff']\n",
    "\n",
    "\n",
    "feature_matrixfac = [ 'matrixFact_user_iposdeviceapp_item_app', \n",
    "                     'matrixFact_user_ip_item_appdeviceos',\n",
    "                    'matrixFact_user_ipchannel_item_appdeviceos']\n",
    "\n",
    "\n",
    "\n",
    "feature_var = ['ip_app_os_var_hour', 'ip_app_channel_var_day']\n",
    "feature_var = [] # best result need to add var\n",
    "feature_regression = ['ip_device_os_regression', \n",
    "                      'ip_app_device_os_regression', \n",
    "                      'ip_app_device_regression', 'ip_app_device_os_channel_regression']\n",
    "                         \n",
    "\n",
    "feature_ori = ['app', 'channel', 'device', 'os', 'hour']\n",
    "\n",
    "feature_cols = []\n",
    "added_feature = []\n",
    "\n",
    "added_feature.extend(feature_count)\n",
    "added_feature.extend(feature_countself)\n",
    "added_feature.extend(feature_mean)\n",
    "added_feature.extend(feature_reversemean)\n",
    "added_feature.extend(feature_time2nextclick)\n",
    "added_feature.extend(feature_time2previousclick)\n",
    "added_feature.extend(feature_countfromfuture)\n",
    "added_feature.extend(feature_countfrompast)\n",
    "added_feature.extend(feature_lasttimediff)\n",
    "added_feature.extend(feature_firsttimediff)\n",
    "added_feature.extend(feature_matrixfac)\n",
    "added_feature.extend(feature_var)\n",
    "added_feature.extend(feature_regression)\n",
    "feature_cols.extend(added_feature)\n",
    "feature_cols.extend(feature_ori)\n",
    "\n",
    "train_cols = feature_cols.copy()\n",
    "train_cols.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip_day_hour_count',\n",
       " 'ip_os_day_hour_count',\n",
       " 'ip_app_day_hour_count',\n",
       " 'ip_app_os_day_hour_count',\n",
       " 'app_day_hour_count',\n",
       " 'ip_device_os_count',\n",
       " 'ip_app_device_os_count',\n",
       " 'ip_day_hour_countself',\n",
       " 'ip_os_day_hour_countself',\n",
       " 'ip_app_day_hour_countself',\n",
       " 'ip_app_os_day_hour_countself',\n",
       " 'app_day_hour_countself',\n",
       " 'ip_device_os_countself',\n",
       " 'ip_app_device_os_countself',\n",
       " 'ip_device_os_mean',\n",
       " 'ip_app_device_os_mean',\n",
       " 'ip_app_device_mean',\n",
       " 'app_device_os_mean',\n",
       " 'ip_device_os_time2nextclick',\n",
       " 'ip_app_device_os_time2nextclick',\n",
       " 'ip_app_device_time2nextclick',\n",
       " 'ip_device_os_time2previousclick',\n",
       " 'ip_app_device_os_time2previousclick',\n",
       " 'ip_app_device_time2previousclick',\n",
       " 'ip_device_os_countfromfuture',\n",
       " 'ip_app_device_os_countfromfuture',\n",
       " 'ip_app_device_countfromfuture',\n",
       " 'ip_device_os_countfrompast',\n",
       " 'ip_app_device_os_countfrompast',\n",
       " 'ip_app_device_countfrompast',\n",
       " 'ip_device_os_lasttimediff',\n",
       " 'ip_app_device_os_lasttimediff',\n",
       " 'ip_app_device_lasttimediff',\n",
       " 'ip_device_os_firsttimediff',\n",
       " 'ip_app_device_os_firsttimediff',\n",
       " 'ip_app_device_firsttimediff',\n",
       " 'matrixFact_user_iposdeviceapp_item_app',\n",
       " 'matrixFact_user_ip_item_appdeviceos',\n",
       " 'matrixFact_user_ipchannel_item_appdeviceos',\n",
       " 'ip_device_os_regression',\n",
       " 'ip_app_device_os_regression',\n",
       " 'ip_app_device_regression',\n",
       " 'ip_app_device_os_channel_regression',\n",
       " 'app',\n",
       " 'channel',\n",
       " 'device',\n",
       " 'os',\n",
       " 'hour']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "def countself(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "def countsort(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts().iloc[::-1]\n",
    "    count_map.iloc[:] = list(range(1, len(count_map) + 1))\n",
    "    \n",
    "    return group.map(count_map).fillna(-1)\n",
    "\n",
    "\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    group = get_group(df_train, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    return group.map(mean_map).fillna(-0.01)\n",
    "\n",
    "\n",
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)\n",
    "\n",
    "\n",
    "def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse[timecol]):\n",
    "        if g in next_heard:\n",
    "            result.append(next_heard[g] - t)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    group = get_group(df_train, cols)\n",
    "\n",
    "    last_heard = {}\n",
    "    for t, g in zip(df_train[timecol], group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "# def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "#     # normalization\n",
    "#     group = get_group(df_train, cols)\n",
    "#     result = pd.Series(np.zeros(len(df_train)), index=df_train.index)\n",
    "#     grouping = df_train.groupby(group)\n",
    "#     for each_group in grouping:\n",
    "#         df_each = each_group[1]\n",
    "#         click = moving_diff(df_each[timecol], mode='next', norm=True)\n",
    "#         result.loc[click.index] = click.values\n",
    "#     return result\n",
    "\n",
    "\n",
    "\n",
    "# def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "#     # normalization\n",
    "#     group = get_group(df_train, cols)\n",
    "#     result = pd.Series(np.zeros(len(df_train)), index=df_train.index)\n",
    "#     grouping = df_train.groupby(group)\n",
    "#     for each_group in grouping:\n",
    "#         df_each = each_group[1]\n",
    "#         click = moving_diff(df_each[timecol], mode='previous', norm=True)\n",
    "#         result.loc[click.index] = click.values\n",
    "        \n",
    "    return result\n",
    "\n",
    "def moving_diff(ser, mode='next', norm=False):\n",
    "    tmp = ser.copy()\n",
    "    if mode == 'next':\n",
    "        tmp.iloc[:-1] = ser[1:].values\n",
    "        result = tmp - ser\n",
    "    elif mode == 'previous':\n",
    "        tmp.iloc[1:] = ser[:-1].values\n",
    "        result = ser - tmp\n",
    "    if norm:\n",
    "        ave = np.mean(result)\n",
    "#         std = np.std(result)\n",
    "#         if std != 0:\n",
    "#             result = (result - ave) / std\n",
    "        if ave != 0:\n",
    "            result = result / ave\n",
    "    return result\n",
    "\n",
    "def countfrompast(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfromfuture(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def lasttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    last_time = df_train.groupby(group)[timecol].last()\n",
    "    \n",
    "    return group.map(last_time) - df_train[timecol]\n",
    "\n",
    "def firsttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    first_time = df_train.groupby(group)[timecol].first()\n",
    "    \n",
    "    return  df_train[timecol] - group.map(first_time)\n",
    "\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "    \n",
    "    \n",
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_var(df_history, df, group_col, agg_col):\n",
    "    group = get_group(df, group_col)\n",
    "    group_history = get_group(df_history, group_col)\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp['group'] = group_history.values\n",
    "    df_temp['agg'] = df_history[agg_col].values\n",
    "    group_map =df_temp.groupby('group')['agg'].var()\n",
    "    result = group.map(group_map).fillna(0)\n",
    "    return result\n",
    "\n",
    "def matrix_factorization(df_history, df, target, item_col, userid_col, userraw_col):\n",
    "    \"\"\"\n",
    "    userid_col is unique user id\n",
    "    item_col is unique itme id\n",
    "    userraw_col is used to construct user feature. dim: user_id*userraw\n",
    "    \"\"\"\n",
    "    dff = pd.DataFrame()\n",
    "    dff_history = pd.DataFrame()\n",
    "\n",
    "\n",
    "    #1. process item\n",
    "    if item_col is None:\n",
    "        dff['item'] = np.zeros(len(df))\n",
    "        dff_history['item'] = np.zeros(len(df_history))\n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        group = get_group(df, item_col)\n",
    "        group_history = get_group(df_history, item_col)\n",
    "        encoder.fit(pd.concat([group, group_history]))\n",
    "        dff['item'] = encoder.transform(group)\n",
    "        dff_history['item'] = encoder.transform(group_history)\n",
    "#     print('processing item done!')\n",
    "\n",
    "    #2. user raw\n",
    "    group = get_group(df, userraw_col)\n",
    "    group_history = get_group(df_history, userraw_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['userraw'] = encoder.transform(group)\n",
    "    dff_history['userraw'] = encoder.transform(group_history)\n",
    "#     print('processing user raw done')\n",
    "\n",
    "\n",
    "    #3. user_id\n",
    "    group = get_group(df, userid_col)\n",
    "    group_history = get_group(df_history, userid_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['user_id'] = encoder.transform(group)\n",
    "    dff_history['user_id'] = encoder.transform(group_history)\n",
    "#     print('processing user id done')\n",
    "\n",
    "\n",
    "\n",
    "    num_users = max(dff.user_id.max(), dff_history.user_id.max()) + 1\n",
    "    num_items = max(dff.item.max(), dff_history.item.max()) + 1\n",
    "    num_userraw = max(dff.userraw.max(), dff_history.userraw.max()) + 1\n",
    "\n",
    "    M = coo_matrix(\n",
    "            (df_history[target], ( dff_history.user_id, dff_history.item)),\n",
    "            shape=(num_users, num_items)\n",
    "        )\n",
    "\n",
    "    user_features = pd.concat([dff, dff_history])[['userraw', 'user_id']].drop_duplicates()\n",
    "\n",
    "    user_features = coo_matrix(\n",
    "        (np.ones(len(user_features)), (user_features.user_id, user_features.userraw)),\n",
    "        shape=(num_users, num_userraw)\n",
    "    )\n",
    "\n",
    "    user_features = sp.hstack([sp.eye(num_users), user_features])\n",
    "\n",
    "    model = LightFM(no_components=50, learning_rate=0.1)\n",
    "    print('fitting lightFM')\n",
    "    model.fit(\n",
    "            M, \n",
    "            epochs=2, \n",
    "            num_threads=36, \n",
    "            user_features=user_features,\n",
    "        )\n",
    "    print('predicting lightFM')\n",
    "    result = model.predict(\n",
    "        dff.user_id.values, \n",
    "        dff.item.values, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def regression(df_history, df, cols, target= 'is_attributed', time_col='timestamp', shift=1500000000):\n",
    "    df = df.copy()\n",
    "    df_history = df_history.copy()\n",
    "    df.loc[:,time_col] = df.loc[:,time_col] - shift\n",
    "    df_history.loc[:,time_col] = df_history.loc[:,time_col] - shift\n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "\n",
    "    targets = {}\n",
    "    times = {}\n",
    "    for (y, t), u in zip(df_history[[target, time_col]].values, group_history):\n",
    "        if u not in targets:\n",
    "            targets[u] = [y]\n",
    "            times[u] = [t]\n",
    "        else:\n",
    "            targets[u].append(y)\n",
    "            times[u].append(t)\n",
    "\n",
    "    linal_user = {}\n",
    "    for u in times:\n",
    "        if len(times[u]) > 1:\n",
    "            A = np.vstack([times[u], np.ones(len(times[u]))]).T\n",
    "            linal_user[u] = np.linalg.inv(A.T.dot(A)).dot(A.T).dot(targets[u])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for t, u in zip(df[time_col], group):\n",
    "        if u not in times:\n",
    "            result.append(-0.5)\n",
    "        else:\n",
    "            if len(times[u]) < 2:\n",
    "                result.append(-0.5)\n",
    "            else:\n",
    "                result.append(linal_user[u].dot([t, 1]))\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 6.228248797357082 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 6.673123709857464 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 7.117998622357845 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 7.562873534858227 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 8.007748447358608 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 8.45262335985899 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 8.897498272359371 G.\n",
      "countself function\n",
      "all 8:   ip_device_os_countself   \t\t\t size: 9.342373184859753 G.\n",
      "countself function\n",
      "all 9:   ip_day_hour_countself   \t\t\t size: 9.787248097360134 G.\n",
      "countself function\n",
      "all 10:   app_day_hour_countself   \t\t\t size: 10.232123009860516 G.\n",
      "countself function\n",
      "all 11:   ip_app_device_os_countself   \t\t\t size: 10.676997922360897 G.\n",
      "countself function\n",
      "all 12:   ip_app_day_hour_countself   \t\t\t size: 11.121872834861279 G.\n",
      "countself function\n",
      "all 13:   ip_os_day_hour_countself   \t\t\t size: 11.56674774736166 G.\n",
      "countself function\n",
      "all 14:   ip_app_os_day_hour_countself   \t\t\t size: 12.011622659862041 G.\n",
      "df_all does not exist\n",
      "mean function\n",
      "all 15:   ip_app_device_mean   \t\t\t size: 12.456497572362423 G.\n",
      "mean function\n",
      "all 16:   ip_device_os_mean   \t\t\t size: 12.901372484862804 G.\n",
      "mean function\n",
      "all 17:   app_device_os_mean   \t\t\t size: 13.346247397363186 G.\n",
      "mean function\n",
      "all 18:   ip_app_device_os_mean   \t\t\t size: 13.791122309863567 G.\n",
      "df_all does not exist\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 19:   ip_app_device_time2nextclick   \t\t\t size: 14.235997222363949 G.\n",
      "time related function\n",
      "all 20:   ip_device_os_time2nextclick   \t\t\t size: 14.68087213486433 G.\n",
      "time related function\n",
      "all 21:   ip_app_device_os_time2nextclick   \t\t\t size: 15.125747047364712 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 22:   ip_app_device_time2previousclick   \t\t\t size: 15.570621959865093 G.\n",
      "time related function\n",
      "all 23:   ip_device_os_time2previousclick   \t\t\t size: 16.015496872365475 G.\n",
      "time related function\n",
      "all 24:   ip_app_device_os_time2previousclick   \t\t\t size: 16.460371784865856 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 25:   ip_app_device_countfromfuture   \t\t\t size: 16.905246697366238 G.\n",
      "time related function\n",
      "all 26:   ip_device_os_countfromfuture   \t\t\t size: 17.35012160986662 G.\n",
      "time related function\n",
      "all 27:   ip_app_device_os_countfromfuture   \t\t\t size: 17.794996522367 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 28:   ip_app_device_countfrompast   \t\t\t size: 18.239871434867382 G.\n",
      "time related function\n",
      "all 29:   ip_device_os_countfrompast   \t\t\t size: 18.684746347367764 G.\n",
      "time related function\n",
      "all 30:   ip_app_device_os_countfrompast   \t\t\t size: 19.129621259868145 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 31:   ip_app_device_lasttimediff   \t\t\t size: 19.574496172368526 G.\n",
      "time related function\n",
      "all 32:   ip_device_os_lasttimediff   \t\t\t size: 20.019371084868908 G.\n",
      "time related function\n",
      "all 33:   ip_app_device_os_lasttimediff   \t\t\t size: 20.46424599736929 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 34:   ip_app_device_firsttimediff   \t\t\t size: 20.90912090986967 G.\n",
      "time related function\n",
      "all 35:   ip_device_os_firsttimediff   \t\t\t size: 21.353995822370052 G.\n",
      "time related function\n",
      "all 36:   ip_app_device_os_firsttimediff   \t\t\t size: 21.798870734870434 G.\n",
      "df_all does not exist\n",
      "regression function\n",
      "all 37:   ip_app_device_regression   \t\t\t size: 22.243745647370815 G.\n",
      "regression function\n",
      "all 38:   ip_device_os_regression   \t\t\t size: 22.688620559871197 G.\n",
      "regression function\n",
      "all 39:   ip_app_device_os_regression   \t\t\t size: 23.133495472371578 G.\n",
      "regression function\n",
      "all 40:   ip_app_device_os_channel_regression   \t\t\t size: 23.57837038487196 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 43:   matrixFact_user_ipchannel_item_appdeviceos   \t\t\t size: 24.912995122373104 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_day_hour_countself'\n",
      " 'ip_os_day_hour_countself' 'ip_app_day_hour_countself'\n",
      " 'ip_app_os_day_hour_countself' 'app_day_hour_countself'\n",
      " 'ip_device_os_countself' 'ip_app_device_os_countself' 'ip_device_os_mean'\n",
      " 'ip_app_device_os_mean' 'ip_app_device_mean' 'app_device_os_mean'\n",
      " 'ip_device_os_time2nextclick' 'ip_app_device_os_time2nextclick'\n",
      " 'ip_app_device_time2nextclick' 'ip_device_os_time2previousclick'\n",
      " 'ip_app_device_os_time2previousclick' 'ip_app_device_time2previousclick'\n",
      " 'ip_device_os_countfromfuture' 'ip_app_device_os_countfromfuture'\n",
      " 'ip_app_device_countfromfuture' 'ip_device_os_countfrompast'\n",
      " 'ip_app_device_os_countfrompast' 'ip_app_device_countfrompast'\n",
      " 'ip_device_os_lasttimediff' 'ip_app_device_os_lasttimediff'\n",
      " 'ip_app_device_lasttimediff' 'ip_device_os_firsttimediff'\n",
      " 'ip_app_device_os_firsttimediff' 'ip_app_device_firsttimediff'\n",
      " 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos' 'ip_device_os_regression'\n",
      " 'ip_app_device_os_regression' 'ip_app_device_regression'\n",
      " 'ip_app_device_os_channel_regression' 'app' 'channel' 'device' 'os' 'hour'\n",
      " 'is_attributed']\n",
      "/home/kai/data/kaggle/talkingdata/wl/data/equalhour/day7_features_supplementV1_countALL.csv\n",
      "======================================================\n",
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 6.504759214818478 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 6.9693848714232445 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 7.434010528028011 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 7.898636184632778 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 8.363261841237545 G.\n",
      "count function\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for day in ['day7', 'day8', 'day9']:\n",
    "    counter = 0\n",
    "    df_train = train.iloc[index[day]].copy()\n",
    "    print('got train data')\n",
    "    history_index = list(set(train.index.values) - set(index[day]))\n",
    "    df_history = train.iloc[history_index].copy()\n",
    "    print('got historical data')\n",
    "    \n",
    "    ###########################################################################\n",
    "    for func in [count, countself, mean, reversemean,time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff,regression]:\n",
    "                if func.__name__ == count.__name__:\n",
    "                    df_all = pd.concat([train, test])\n",
    "                else:\n",
    "                    try:\n",
    "                        del df_all\n",
    "                        gc.collect()\n",
    "                    except Exception:\n",
    "                        print('df_all does not exist')\n",
    "               \n",
    "                for num_col in [1,2,3,4,5]:\n",
    "                    for cols in combinations(combine_col, num_col):\n",
    "                        feature_name = col_name(cols, func=func)\n",
    "                        if feature_name not in added_feature:\n",
    "                               continue\n",
    "                        counter += 1\n",
    "                        if func.__name__ == count.__name__:\n",
    "                                print('count function')\n",
    "                                df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "                                \n",
    "                        elif func.__name__ == countself.__name__:\n",
    "                                print('countself function')\n",
    "                                df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "\n",
    "                        elif func.__name__ == mean.__name__:\n",
    "                                print('mean function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                        elif func.__name__ == reversemean.__name__:\n",
    "                                print('reverse mean function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                                \n",
    "                        elif func.__name__ == regression.__name__:\n",
    "                                print('regression function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                        else:\n",
    "                                print('time related function')\n",
    "                                df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "               \n",
    "                        all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                        print(all_str)\n",
    "                        with open('feature_all.txt', 'w') as text_file:\n",
    "                            text_file.write(all_str + '\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "#     ### get val\n",
    "#     print('get val')\n",
    "#     df_all = pd.concat([train, test])\n",
    "#     df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "#     print('ip_app_os_var_hour done!')\n",
    "#     df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "#     print('ip_app_channel_var_day done!')\n",
    "#     del df_all\n",
    "#     gc.collect()\n",
    "    \n",
    "    \n",
    "    ### matrix - factorization\n",
    "    feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "    \n",
    "    feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "    feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "\n",
    "    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "    print(all_str)\n",
    "    with open('feature_all.txt', 'w') as text_file:\n",
    "        text_file.write(all_str + '\\n')\n",
    "               \n",
    "               \n",
    "    save_file_name = '{}_features_supplementV1_countALL.csv'.format(day)\n",
    "    save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "    df_train = df_train[train_cols]\n",
    "    print('------')\n",
    "    print(df_train.columns.values)\n",
    "    df_train.to_csv(save_file_path, index=False)\n",
    "    print(save_file_path)\n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "df_train = test.copy()\n",
    "print('got train data')\n",
    "history_index = list(set(train.index.values) - set(index[day]))\n",
    "df_history = train.copy()\n",
    "print('got historical data')\n",
    "\n",
    "###########################################################################\n",
    "for func in [count, countself, mean,reversemean, time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff, regression]:\n",
    "# for func in [time2nextclick, time2previousclick]:\n",
    "             \n",
    "            if func.__name__ == count.__name__:\n",
    "                df_all = pd.concat([train, test])\n",
    "            else:\n",
    "                try:\n",
    "                    del df_all\n",
    "                    gc.collect()\n",
    "                except Exception:\n",
    "                    print('df_all does not exist')\n",
    "\n",
    "            for num_col in [1,2,3,4,5]:\n",
    "                for cols in combinations(combine_col, num_col):\n",
    "                    feature_name = col_name(cols, func=func)\n",
    "                    if feature_name not in added_feature:\n",
    "                           continue\n",
    "                    counter += 1\n",
    "                    if func.__name__ == count.__name__:\n",
    "                            print('count function')\n",
    "                            df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "                    \n",
    "                    elif func.__name__ == countself.__name__:\n",
    "                                print('countself function')\n",
    "                                df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    elif func.__name__ == mean.__name__:\n",
    "                            print('mean function')\n",
    "                            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                    elif func.__name__ == reversemean.__name__:\n",
    "                            print('mean function')\n",
    "                            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                    elif func.__name__ == regression.__name__:\n",
    "                                print('regression function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    else:\n",
    "                            print('time related function')\n",
    "                            df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                    print(all_str)\n",
    "                    with open('feature_all.txt', 'w') as text_file:\n",
    "                        text_file.write(all_str + '\\n')\n",
    "                        \n",
    "                        \n",
    "# ### get val\n",
    "# print('get val')\n",
    "# df_all = pd.concat([train, test])\n",
    "# df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "# print('ip_app_os_var_hour done!')\n",
    "# df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "# print('ip_app_channel_var_day done!')\n",
    "# del df_all\n",
    "# gc.collect()\n",
    "                        \n",
    "### matrix - factorization\n",
    "feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "\n",
    "all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "print(all_str)\n",
    "with open('feature_all.txt', 'w') as text_file:\n",
    "    text_file.write(all_str + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = '{}_features_supplementV1_countALL.csv'.format('testsupplement')\n",
    "save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "df_train = df_train[feature_cols]\n",
    "print(df_train.columns.values)\n",
    "df_train.to_csv(save_file_path, index=False)\n",
    "print(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
