{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 12\n",
    "# kf = KFold(n_splits=K, shuffle = False)\n",
    "kf = KFold(n_splits=K, shuffle = True, random_state = 233)\n",
    "history_index = []\n",
    "train_index = []\n",
    "for h,t in kf.split(train):\n",
    "    history_index.append(h)\n",
    "    train_index.append(t)\n",
    "    \n",
    "### use last fold as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.154054783284664\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(train)/ 1024 **3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use last fold as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history = train.iloc[history_index[-1]].copy()\n",
    "df_train = train.iloc[train_index[-1]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.377641312777996\n",
      "15408657\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(df_train)/ 1024 **3)\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip', 'app', 'device', 'os', 'channel', 'day', 'hour', 'timestamp',\n",
       "       'minute', 'second', 'is_attributed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n",
    "\n",
    "import gc\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 1000,\n",
       " 'channel': 1000,\n",
       " 'day': 100,\n",
       " 'device': 10000,\n",
       " 'hour': 100,\n",
       " 'ip': 1000000,\n",
       " 'minute': 100,\n",
       " 'os': 1000,\n",
       " 'second': 100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count\n",
    "plan 1. count from historical data  \n",
    "plan 2. count from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean\n",
    "mean P(target | feature combination)\n",
    "\n",
    "purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer))\n",
    "Get the conditional Probability only from historical data and apply to train data.\n",
    "\n",
    "P(replay | X feature combination) = P( replay & X feature combination) / P (X feature combination)  \n",
    "=(count(replay & X feature combination) / count(total)) / (count(X feature combination) / count(total))  \n",
    "= count(replay & X feature combination) / count(X feature combination)  \n",
    "= sum((replay & X feature combination)) / count(X feature combination)  \n",
    "= sum((replay or not replayed & X feature combination)) / count(X feature combination)# since replay is 1, not replay is 0  \n",
    "= sum( X feature combination) / count(X feature combination)  \n",
    "= mean(X feature combination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaller(num):\n",
    "    sca = 1\n",
    "    while num * sca < 1:\n",
    "        sca *= 10\n",
    "    return sca\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    # mean_map: key - encoding, value - target mean\n",
    "#     ### sca\n",
    "#     m_min = mean_map[mean_map > 0].min()\n",
    "#     sca = scaller(m_min)\n",
    "#     mean_map *= sca\n",
    "#     ###\n",
    "\n",
    "    return group.map(mean_map).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reversemean\n",
    "reverse mean P(feature combination | target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1:   ip_reversemean   \t\t\t size: 1.4924447536468506 G.\n",
      "test 1:   ip_reversemean   \t\t\t size: 1.5399990379810333 G.\n",
      "------\n",
      "train 2:   app_reversemean   \t\t\t size: 1.607248194515705 G.\n",
      "test 2:   app_reversemean   \t\t\t size: 1.679998941719532 G.\n",
      "------\n",
      "train 3:   device_reversemean   \t\t\t size: 1.7220516353845596 G.\n",
      "test 3:   device_reversemean   \t\t\t size: 1.8199988454580307 G.\n",
      "------\n",
      "train 4:   os_reversemean   \t\t\t size: 1.8368550762534142 G.\n",
      "test 4:   os_reversemean   \t\t\t size: 1.9599987491965294 G.\n",
      "------\n",
      "train 5:   channel_reversemean   \t\t\t size: 1.9516585171222687 G.\n",
      "test 5:   channel_reversemean   \t\t\t size: 2.099998652935028 G.\n",
      "------\n",
      "train 6:   hour_reversemean   \t\t\t size: 2.066461957991123 G.\n",
      "test 6:   hour_reversemean   \t\t\t size: 2.2399985566735268 G.\n",
      "------\n",
      "train 7:   minute_reversemean   \t\t\t size: 2.1812653988599777 G.\n",
      "test 7:   minute_reversemean   \t\t\t size: 2.3799984604120255 G.\n",
      "------\n",
      "train 8:   second_reversemean   \t\t\t size: 2.2960688397288322 G.\n",
      "test 8:   second_reversemean   \t\t\t size: 2.519998364150524 G.\n",
      "------\n",
      "train 9:   ip_app_reversemean   \t\t\t size: 2.4108722805976868 G.\n",
      "test 9:   ip_app_reversemean   \t\t\t size: 2.659998267889023 G.\n",
      "------\n",
      "train 10:   ip_device_reversemean   \t\t\t size: 2.5256757214665413 G.\n",
      "test 10:   ip_device_reversemean   \t\t\t size: 2.7999981716275215 G.\n",
      "------\n",
      "train 11:   ip_os_reversemean   \t\t\t size: 2.640479162335396 G.\n",
      "test 11:   ip_os_reversemean   \t\t\t size: 2.93999807536602 G.\n",
      "------\n",
      "train 12:   ip_channel_reversemean   \t\t\t size: 2.7552826032042503 G.\n",
      "test 12:   ip_channel_reversemean   \t\t\t size: 3.079997979104519 G.\n",
      "------\n",
      "train 13:   ip_hour_reversemean   \t\t\t size: 2.870086044073105 G.\n",
      "test 13:   ip_hour_reversemean   \t\t\t size: 3.2199978828430176 G.\n",
      "------\n",
      "train 14:   ip_minute_reversemean   \t\t\t size: 2.9848894849419594 G.\n",
      "test 14:   ip_minute_reversemean   \t\t\t size: 3.3599977865815163 G.\n",
      "------\n",
      "train 15:   ip_second_reversemean   \t\t\t size: 3.099692925810814 G.\n",
      "test 15:   ip_second_reversemean   \t\t\t size: 3.499997690320015 G.\n",
      "------\n",
      "train 16:   app_device_reversemean   \t\t\t size: 3.2144963666796684 G.\n",
      "test 16:   app_device_reversemean   \t\t\t size: 3.6399975940585136 G.\n",
      "------\n",
      "train 17:   app_os_reversemean   \t\t\t size: 3.329299807548523 G.\n",
      "test 17:   app_os_reversemean   \t\t\t size: 3.7799974977970123 G.\n",
      "------\n",
      "train 18:   app_channel_reversemean   \t\t\t size: 3.4441032484173775 G.\n",
      "test 18:   app_channel_reversemean   \t\t\t size: 3.919997401535511 G.\n",
      "------\n",
      "train 19:   app_hour_reversemean   \t\t\t size: 3.558906689286232 G.\n",
      "test 19:   app_hour_reversemean   \t\t\t size: 4.05999730527401 G.\n",
      "------\n",
      "train 20:   app_minute_reversemean   \t\t\t size: 3.6737101301550865 G.\n",
      "test 20:   app_minute_reversemean   \t\t\t size: 4.199997209012508 G.\n",
      "------\n",
      "train 21:   app_second_reversemean   \t\t\t size: 3.788513571023941 G.\n",
      "test 21:   app_second_reversemean   \t\t\t size: 4.339997112751007 G.\n",
      "------\n",
      "train 22:   device_os_reversemean   \t\t\t size: 3.9033170118927956 G.\n",
      "test 22:   device_os_reversemean   \t\t\t size: 4.479997016489506 G.\n",
      "------\n",
      "train 23:   device_channel_reversemean   \t\t\t size: 4.01812045276165 G.\n",
      "test 23:   device_channel_reversemean   \t\t\t size: 4.6199969202280045 G.\n",
      "------\n",
      "train 24:   device_hour_reversemean   \t\t\t size: 4.132923893630505 G.\n",
      "test 24:   device_hour_reversemean   \t\t\t size: 4.759996823966503 G.\n",
      "------\n",
      "train 25:   device_minute_reversemean   \t\t\t size: 4.247727334499359 G.\n",
      "test 25:   device_minute_reversemean   \t\t\t size: 4.899996727705002 G.\n",
      "------\n",
      "train 26:   device_second_reversemean   \t\t\t size: 4.362530775368214 G.\n",
      "test 26:   device_second_reversemean   \t\t\t size: 5.0399966314435005 G.\n",
      "------\n",
      "train 27:   os_channel_reversemean   \t\t\t size: 4.477334216237068 G.\n",
      "test 27:   os_channel_reversemean   \t\t\t size: 5.179996535181999 G.\n",
      "------\n",
      "train 28:   os_hour_reversemean   \t\t\t size: 4.592137657105923 G.\n",
      "test 28:   os_hour_reversemean   \t\t\t size: 5.319996438920498 G.\n",
      "------\n",
      "train 29:   os_minute_reversemean   \t\t\t size: 4.706941097974777 G.\n",
      "test 29:   os_minute_reversemean   \t\t\t size: 5.459996342658997 G.\n",
      "------\n",
      "train 30:   os_second_reversemean   \t\t\t size: 4.821744538843632 G.\n",
      "test 30:   os_second_reversemean   \t\t\t size: 5.599996246397495 G.\n",
      "------\n",
      "train 31:   channel_hour_reversemean   \t\t\t size: 4.936547979712486 G.\n",
      "test 31:   channel_hour_reversemean   \t\t\t size: 5.739996150135994 G.\n",
      "------\n",
      "train 32:   channel_minute_reversemean   \t\t\t size: 5.051351420581341 G.\n",
      "test 32:   channel_minute_reversemean   \t\t\t size: 5.879996053874493 G.\n",
      "------\n",
      "train 33:   channel_second_reversemean   \t\t\t size: 5.166154861450195 G.\n",
      "test 33:   channel_second_reversemean   \t\t\t size: 6.019995957612991 G.\n",
      "------\n",
      "train 34:   hour_minute_reversemean   \t\t\t size: 5.28095830231905 G.\n",
      "test 34:   hour_minute_reversemean   \t\t\t size: 6.15999586135149 G.\n",
      "------\n",
      "train 35:   hour_second_reversemean   \t\t\t size: 5.395761743187904 G.\n",
      "test 35:   hour_second_reversemean   \t\t\t size: 6.299995765089989 G.\n",
      "------\n",
      "train 36:   minute_second_reversemean   \t\t\t size: 5.510565184056759 G.\n",
      "test 36:   minute_second_reversemean   \t\t\t size: 6.439995668828487 G.\n",
      "------\n",
      "train 37:   ip_app_device_reversemean   \t\t\t size: 5.625368624925613 G.\n",
      "test 37:   ip_app_device_reversemean   \t\t\t size: 6.579995572566986 G.\n",
      "------\n",
      "train 38:   ip_app_os_reversemean   \t\t\t size: 5.740172065794468 G.\n",
      "test 38:   ip_app_os_reversemean   \t\t\t size: 6.719995476305485 G.\n",
      "------\n",
      "train 39:   ip_app_channel_reversemean   \t\t\t size: 5.8549755066633224 G.\n",
      "test 39:   ip_app_channel_reversemean   \t\t\t size: 6.8599953800439835 G.\n",
      "------\n",
      "train 40:   ip_app_hour_reversemean   \t\t\t size: 5.969778947532177 G.\n",
      "test 40:   ip_app_hour_reversemean   \t\t\t size: 6.999995283782482 G.\n",
      "------\n",
      "train 41:   ip_app_minute_reversemean   \t\t\t size: 6.0845823884010315 G.\n",
      "test 41:   ip_app_minute_reversemean   \t\t\t size: 7.139995187520981 G.\n",
      "------\n",
      "train 42:   ip_app_second_reversemean   \t\t\t size: 6.199385829269886 G.\n",
      "test 42:   ip_app_second_reversemean   \t\t\t size: 7.2799950912594795 G.\n",
      "------\n",
      "train 43:   ip_device_os_reversemean   \t\t\t size: 6.3141892701387405 G.\n",
      "test 43:   ip_device_os_reversemean   \t\t\t size: 7.419994994997978 G.\n",
      "------\n",
      "train 44:   ip_device_channel_reversemean   \t\t\t size: 6.428992711007595 G.\n",
      "test 44:   ip_device_channel_reversemean   \t\t\t size: 7.559994898736477 G.\n",
      "------\n",
      "train 45:   ip_device_hour_reversemean   \t\t\t size: 6.54379615187645 G.\n",
      "test 45:   ip_device_hour_reversemean   \t\t\t size: 7.699994802474976 G.\n",
      "------\n",
      "train 46:   ip_device_minute_reversemean   \t\t\t size: 6.658599592745304 G.\n",
      "test 46:   ip_device_minute_reversemean   \t\t\t size: 7.839994706213474 G.\n",
      "------\n",
      "train 47:   ip_device_second_reversemean   \t\t\t size: 6.773403033614159 G.\n",
      "test 47:   ip_device_second_reversemean   \t\t\t size: 7.979994609951973 G.\n",
      "------\n",
      "train 48:   ip_os_channel_reversemean   \t\t\t size: 6.888206474483013 G.\n",
      "test 48:   ip_os_channel_reversemean   \t\t\t size: 8.119994513690472 G.\n",
      "------\n",
      "train 49:   ip_os_hour_reversemean   \t\t\t size: 7.003009915351868 G.\n",
      "test 49:   ip_os_hour_reversemean   \t\t\t size: 8.25999441742897 G.\n",
      "------\n",
      "train 50:   ip_os_minute_reversemean   \t\t\t size: 7.117813356220722 G.\n",
      "test 50:   ip_os_minute_reversemean   \t\t\t size: 8.399994321167469 G.\n",
      "------\n",
      "train 51:   ip_os_second_reversemean   \t\t\t size: 7.232616797089577 G.\n",
      "test 51:   ip_os_second_reversemean   \t\t\t size: 8.539994224905968 G.\n",
      "------\n",
      "train 52:   ip_channel_hour_reversemean   \t\t\t size: 7.347420237958431 G.\n",
      "test 52:   ip_channel_hour_reversemean   \t\t\t size: 8.679994128644466 G.\n",
      "------\n",
      "train 53:   ip_channel_minute_reversemean   \t\t\t size: 7.462223678827286 G.\n",
      "test 53:   ip_channel_minute_reversemean   \t\t\t size: 8.819994032382965 G.\n",
      "------\n",
      "train 54:   ip_channel_second_reversemean   \t\t\t size: 7.57702711969614 G.\n",
      "test 54:   ip_channel_second_reversemean   \t\t\t size: 8.959993936121464 G.\n",
      "------\n",
      "train 55:   ip_hour_minute_reversemean   \t\t\t size: 7.691830560564995 G.\n",
      "test 55:   ip_hour_minute_reversemean   \t\t\t size: 9.099993839859962 G.\n",
      "------\n",
      "train 56:   ip_hour_second_reversemean   \t\t\t size: 7.806634001433849 G.\n",
      "test 56:   ip_hour_second_reversemean   \t\t\t size: 9.239993743598461 G.\n",
      "------\n",
      "train 57:   ip_minute_second_reversemean   \t\t\t size: 7.921437442302704 G.\n",
      "test 57:   ip_minute_second_reversemean   \t\t\t size: 9.37999364733696 G.\n",
      "------\n",
      "train 58:   app_device_os_reversemean   \t\t\t size: 8.036240883171558 G.\n",
      "test 58:   app_device_os_reversemean   \t\t\t size: 9.519993551075459 G.\n",
      "------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 59:   app_device_channel_reversemean   \t\t\t size: 8.151044324040413 G.\n",
      "test 59:   app_device_channel_reversemean   \t\t\t size: 9.659993454813957 G.\n",
      "------\n",
      "train 60:   app_device_hour_reversemean   \t\t\t size: 8.265847764909267 G.\n",
      "test 60:   app_device_hour_reversemean   \t\t\t size: 9.799993358552456 G.\n",
      "------\n",
      "train 61:   app_device_minute_reversemean   \t\t\t size: 8.380651205778122 G.\n",
      "test 61:   app_device_minute_reversemean   \t\t\t size: 9.939993262290955 G.\n",
      "------\n",
      "train 62:   app_device_second_reversemean   \t\t\t size: 8.495454646646976 G.\n",
      "test 62:   app_device_second_reversemean   \t\t\t size: 10.079993166029453 G.\n",
      "------\n",
      "train 63:   app_os_channel_reversemean   \t\t\t size: 8.610258087515831 G.\n",
      "test 63:   app_os_channel_reversemean   \t\t\t size: 10.219993069767952 G.\n",
      "------\n",
      "train 64:   app_os_hour_reversemean   \t\t\t size: 8.725061528384686 G.\n",
      "test 64:   app_os_hour_reversemean   \t\t\t size: 10.35999297350645 G.\n",
      "------\n",
      "train 65:   app_os_minute_reversemean   \t\t\t size: 8.83986496925354 G.\n",
      "test 65:   app_os_minute_reversemean   \t\t\t size: 10.49999287724495 G.\n",
      "------\n",
      "train 66:   app_os_second_reversemean   \t\t\t size: 8.954668410122395 G.\n",
      "test 66:   app_os_second_reversemean   \t\t\t size: 10.639992780983448 G.\n",
      "------\n",
      "train 67:   app_channel_hour_reversemean   \t\t\t size: 9.069471850991249 G.\n",
      "test 67:   app_channel_hour_reversemean   \t\t\t size: 10.779992684721947 G.\n",
      "------\n",
      "train 68:   app_channel_minute_reversemean   \t\t\t size: 9.184275291860104 G.\n",
      "test 68:   app_channel_minute_reversemean   \t\t\t size: 10.919992588460445 G.\n",
      "------\n",
      "train 69:   app_channel_second_reversemean   \t\t\t size: 9.299078732728958 G.\n",
      "test 69:   app_channel_second_reversemean   \t\t\t size: 11.059992492198944 G.\n",
      "------\n",
      "train 70:   app_hour_minute_reversemean   \t\t\t size: 9.413882173597813 G.\n",
      "test 70:   app_hour_minute_reversemean   \t\t\t size: 11.199992395937443 G.\n",
      "------\n",
      "train 71:   app_hour_second_reversemean   \t\t\t size: 9.528685614466667 G.\n",
      "test 71:   app_hour_second_reversemean   \t\t\t size: 11.339992299675941 G.\n",
      "------\n",
      "train 72:   app_minute_second_reversemean   \t\t\t size: 9.643489055335522 G.\n",
      "test 72:   app_minute_second_reversemean   \t\t\t size: 11.47999220341444 G.\n",
      "------\n",
      "train 73:   device_os_channel_reversemean   \t\t\t size: 9.758292496204376 G.\n",
      "test 73:   device_os_channel_reversemean   \t\t\t size: 11.619992107152939 G.\n",
      "------\n",
      "train 74:   device_os_hour_reversemean   \t\t\t size: 9.87309593707323 G.\n",
      "test 74:   device_os_hour_reversemean   \t\t\t size: 11.759992010891438 G.\n",
      "------\n",
      "train 75:   device_os_minute_reversemean   \t\t\t size: 9.987899377942085 G.\n",
      "test 75:   device_os_minute_reversemean   \t\t\t size: 11.899991914629936 G.\n",
      "------\n",
      "train 76:   device_os_second_reversemean   \t\t\t size: 10.10270281881094 G.\n",
      "test 76:   device_os_second_reversemean   \t\t\t size: 12.039991818368435 G.\n",
      "------\n",
      "train 77:   device_channel_hour_reversemean   \t\t\t size: 10.217506259679794 G.\n",
      "test 77:   device_channel_hour_reversemean   \t\t\t size: 12.179991722106934 G.\n",
      "------\n",
      "train 78:   device_channel_minute_reversemean   \t\t\t size: 10.332309700548649 G.\n",
      "test 78:   device_channel_minute_reversemean   \t\t\t size: 12.319991625845432 G.\n",
      "------\n",
      "train 79:   device_channel_second_reversemean   \t\t\t size: 10.447113141417503 G.\n",
      "test 79:   device_channel_second_reversemean   \t\t\t size: 12.459991529583931 G.\n",
      "------\n",
      "train 80:   device_hour_minute_reversemean   \t\t\t size: 10.561916582286358 G.\n",
      "test 80:   device_hour_minute_reversemean   \t\t\t size: 12.59999143332243 G.\n",
      "------\n",
      "train 81:   device_hour_second_reversemean   \t\t\t size: 10.676720023155212 G.\n",
      "test 81:   device_hour_second_reversemean   \t\t\t size: 12.739991337060928 G.\n",
      "------\n",
      "train 82:   device_minute_second_reversemean   \t\t\t size: 10.791523464024067 G.\n",
      "test 82:   device_minute_second_reversemean   \t\t\t size: 12.879991240799427 G.\n",
      "------\n",
      "train 83:   os_channel_hour_reversemean   \t\t\t size: 10.906326904892921 G.\n",
      "test 83:   os_channel_hour_reversemean   \t\t\t size: 13.019991144537926 G.\n",
      "------\n",
      "train 84:   os_channel_minute_reversemean   \t\t\t size: 11.021130345761776 G.\n",
      "test 84:   os_channel_minute_reversemean   \t\t\t size: 13.159991048276424 G.\n",
      "------\n",
      "train 85:   os_channel_second_reversemean   \t\t\t size: 11.13593378663063 G.\n",
      "test 85:   os_channel_second_reversemean   \t\t\t size: 13.299990952014923 G.\n",
      "------\n",
      "train 86:   os_hour_minute_reversemean   \t\t\t size: 11.250737227499485 G.\n",
      "test 86:   os_hour_minute_reversemean   \t\t\t size: 13.439990855753422 G.\n",
      "------\n",
      "train 87:   os_hour_second_reversemean   \t\t\t size: 11.36554066836834 G.\n",
      "test 87:   os_hour_second_reversemean   \t\t\t size: 13.57999075949192 G.\n",
      "------\n",
      "train 88:   os_minute_second_reversemean   \t\t\t size: 11.480344109237194 G.\n",
      "test 88:   os_minute_second_reversemean   \t\t\t size: 13.71999066323042 G.\n",
      "------\n",
      "train 89:   channel_hour_minute_reversemean   \t\t\t size: 11.595147550106049 G.\n",
      "test 89:   channel_hour_minute_reversemean   \t\t\t size: 13.859990566968918 G.\n",
      "------\n",
      "train 90:   channel_hour_second_reversemean   \t\t\t size: 11.709950990974903 G.\n",
      "test 90:   channel_hour_second_reversemean   \t\t\t size: 13.999990470707417 G.\n",
      "------\n",
      "train 91:   channel_minute_second_reversemean   \t\t\t size: 11.824754431843758 G.\n",
      "test 91:   channel_minute_second_reversemean   \t\t\t size: 14.139990374445915 G.\n",
      "------\n",
      "train 92:   hour_minute_second_reversemean   \t\t\t size: 11.939557872712612 G.\n",
      "test 92:   hour_minute_second_reversemean   \t\t\t size: 14.279990278184414 G.\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel', \n",
    "#               'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# combine_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "exception_list = []\n",
    "for num_col in [1,2,3]:\n",
    "    for cols in combinations(combine_col, num_col):\n",
    "#         for func in [count, mean]:\n",
    "        for func in [reversemean]:\n",
    "            counter += 1\n",
    "            feature_name = col_name(cols, func=func)\n",
    "            if feature_name in exception_list:\n",
    "                continue\n",
    "            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "            test[feature_name] = func(df_history, test, cols, target='is_attributed')\n",
    "            gc.collect()\n",
    "            train_str = 'train {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "            test_str = 'test {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(test)/ 1024 **3)\n",
    "            print(train_str)\n",
    "            print(test_str)\n",
    "            print('------')\n",
    "            with open('feature_all.txt', 'w') as text_file:\n",
    "                text_file.write(train_str + '\\n')\n",
    "                text_file.write(test_str + '\\n')\n",
    "                text_file.write('------' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-processing version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build kwargs done!\n",
      "thread start !!!!!!!\n",
      "thread start !!!!!!!\n",
      "thread start !!!!!!!\n",
      "ip_count\n",
      "app_channel_minute_count\n",
      "hour_second_count\n",
      "hour_second_mean\n",
      "app_channel_minute_mean\n",
      "ip_mean\n",
      "minute_second_count\n",
      "app_channel_second_count\n",
      "minute_second_mean\n",
      "app_channel_second_mean\n",
      "app_count\n",
      "ip_app_device_count\n",
      "app_mean\n",
      "app_day_hour_count\n",
      "device_count\n",
      "app_day_hour_mean\n",
      "device_mean\n",
      "app_day_minute_count\n",
      "ip_app_device_mean\n",
      "os_count\n",
      "app_day_minute_mean\n",
      "os_mean\n",
      "channel_count\n",
      "app_day_second_count\n",
      "channel_mean\n",
      "app_day_second_mean\n",
      "ip_app_os_count\n",
      "day_count\n",
      "app_hour_minute_count\n",
      "day_mean\n",
      "app_hour_minute_mean\n",
      "hour_count\n",
      "hour_mean\n",
      "app_hour_second_count\n",
      "ip_app_os_mean\n",
      "minute_count\n",
      "app_hour_second_mean\n",
      "minute_mean\n",
      "second_count\n",
      "app_minute_second_count\n",
      "second_mean\n",
      "app_minute_second_mean\n",
      "ip_app_count\n",
      "device_os_channel_count\n",
      "ip_app_channel_count\n",
      "device_os_channel_mean\n",
      "ip_app_mean\n",
      "device_os_day_count\n",
      "device_os_day_mean\n",
      "ip_app_channel_mean\n",
      "device_os_hour_count\n",
      "ip_device_count\n",
      "device_os_hour_mean\n",
      "ip_device_mean\n",
      "device_os_minute_count\n",
      "device_os_minute_mean\n",
      "ip_os_count\n",
      "ip_app_day_count\n",
      "device_os_second_count\n",
      "device_os_second_mean\n",
      "ip_os_mean\n",
      "device_channel_day_count\n",
      "ip_app_day_mean\n",
      "device_channel_day_mean\n",
      "device_channel_hour_count\n",
      "ip_channel_count\n",
      "device_channel_hour_mean\n",
      "device_channel_minute_count\n",
      "ip_app_hour_count\n",
      "device_channel_minute_mean\n",
      "ip_channel_mean\n",
      "device_channel_second_count\n",
      "ip_app_hour_mean\n",
      "device_channel_second_mean\n",
      "device_day_hour_count\n",
      "ip_day_count\n",
      "device_day_hour_mean\n",
      "device_day_minute_count\n",
      "ip_day_mean\n",
      "device_day_minute_mean\n",
      "ip_app_minute_count\n",
      "ip_hour_count\n",
      "device_day_second_count\n",
      "device_day_second_mean\n",
      "ip_hour_mean\n",
      "device_hour_minute_count\n",
      "ip_app_minute_mean\n",
      "device_hour_minute_mean\n",
      "ip_minute_count\n",
      "device_hour_second_count\n",
      "device_hour_second_mean\n",
      "ip_minute_mean\n",
      "device_minute_second_count\n",
      "device_minute_second_mean\n",
      "os_channel_day_count\n",
      "ip_second_count\n",
      "ip_app_second_count\n",
      "os_channel_day_mean\n",
      "os_channel_hour_count\n",
      "ip_second_mean\n",
      "os_channel_hour_mean\n",
      "ip_app_second_mean\n",
      "os_channel_minute_count\n",
      "os_channel_minute_mean\n",
      "app_device_count\n",
      "app_device_mean\n",
      "os_channel_second_count\n",
      "app_os_count\n",
      "app_os_mean\n",
      "os_channel_second_mean\n",
      "app_channel_count\n",
      "ip_device_os_count\n",
      "app_channel_mean\n",
      "os_day_hour_count\n",
      "app_day_count\n",
      "os_day_hour_mean\n",
      "app_day_mean\n",
      "ip_device_os_mean\n",
      "os_day_minute_count\n",
      "app_hour_count\n",
      "app_hour_mean\n",
      "os_day_minute_mean\n",
      "ip_device_channel_count\n",
      "app_minute_count\n",
      "os_day_second_count\n",
      "app_minute_mean\n",
      "os_day_second_mean\n",
      "app_second_count\n",
      "os_hour_minute_count\n",
      "ip_device_channel_mean\n",
      "app_second_mean\n",
      "os_hour_minute_mean\n",
      "device_os_count\n",
      "os_hour_second_count\n",
      "device_os_mean\n",
      "os_hour_second_mean\n",
      "device_channel_count\n",
      "os_minute_second_count\n",
      "device_channel_mean\n",
      "ip_device_day_count\n",
      "os_minute_second_mean\n",
      "device_day_count\n",
      "ip_device_day_mean\n",
      "device_day_mean\n",
      "channel_day_hour_count\n",
      "device_hour_count\n",
      "device_hour_mean\n",
      "channel_day_hour_mean\n",
      "ip_device_hour_count\n",
      "device_minute_count\n",
      "channel_day_minute_count\n",
      "device_minute_mean\n",
      "ip_device_hour_mean\n",
      "channel_day_minute_mean\n",
      "device_second_count\n",
      "device_second_mean\n",
      "channel_day_second_count\n",
      "os_channel_count\n",
      "channel_day_second_mean\n",
      "ip_device_minute_count\n",
      "os_channel_mean\n",
      "channel_hour_minute_count\n",
      "os_day_count\n",
      "channel_hour_minute_mean\n",
      "ip_device_minute_mean\n",
      "os_day_mean\n",
      "channel_hour_second_count\n",
      "os_hour_count\n",
      "channel_hour_second_mean\n",
      "os_hour_mean\n",
      "ip_device_second_count\n",
      "channel_minute_second_count\n",
      "os_minute_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 7, in count\n",
      "    group_all = get_group(df_history, cols)\n",
      "  File \"<ipython-input-8-6613b36fca9d>\", line 18, in get_group\n",
      "    group = df[cols[0]].copy()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3432, in copy\n",
      "    data = self._data.copy(deep=deep)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3436, in copy\n",
      "    do_integrity_check=False)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3091, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 629, in copy\n",
      "    values = values.copy()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 7, in count\n",
      "    group_all = get_group(df_history, cols)\n",
      "  File \"<ipython-input-8-6613b36fca9d>\", line 18, in get_group\n",
      "    group = df[cols[0]].copy()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3432, in copy\n",
      "    data = self._data.copy(deep=deep)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3436, in copy\n",
      "    do_integrity_check=False)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3091, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 629, in copy\n",
      "    values = values.copy()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c973b4268b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-c973b4268b5b>\u001b[0m in \u001b[0;36mmultiprocessing_features\u001b[0;34m(df_history, df_train, target, combine_col, func_pool, comb_total, workers, mode)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'build kwargs done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_process_each_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature processing done!!!!!!!!!!!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 9, in count\n",
      "    count_map = group_all.value_counts()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\", line 938, in value_counts\n",
      "    normalize=normalize, bins=bins, dropna=dropna)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 640, in value_counts\n",
      "    keys, counts = _value_counts_arraylike(values, dropna)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 685, in _value_counts_arraylike\n",
      "    keys, counts = f(values, dropna)\n",
      "  File \"pandas/_libs/hashtable_func_helper.pxi\", line 504, in pandas._libs.hashtable.value_count_int64\n",
      "  File \"pandas/_libs/hashtable_func_helper.pxi\", line 529, in pandas._libs.hashtable.value_count_int64\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\", line 463, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "\n",
    "# ####################\n",
    "# from itertools import combinations\n",
    "\n",
    "\n",
    "# combine_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel', \n",
    "#               'day',\n",
    "#               'hour',\n",
    "#               'minute',\n",
    "#               'second']\n",
    "\n",
    "# func_pool = [count, mean]\n",
    "\n",
    "# target = 'is_attributed'\n",
    "\n",
    "# def col_name(cols, func=None):\n",
    "#     if func is None:\n",
    "#         return '_'.join(cols)\n",
    "#     else:\n",
    "#         return '_'.join(cols) + '_' + func.__name__\n",
    "# ###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def _process_each_col(kwargs_list):\n",
    "#     print('thread start !!!!!!!')\n",
    "#     result_dict = {}\n",
    "    \n",
    "#     for kwargs in kwargs_list:\n",
    "# #         df_train = kwargs.get('df_train')\n",
    "# #         df_history = kwargs.get('df_history')\n",
    "# #         target = kwargs.get('target')\n",
    "# #         df_train = df_train\n",
    "# #         df_history = df_history\n",
    "# #         target = target\n",
    "#         cols = kwargs.get('cols')\n",
    "#         func = kwargs.get('func')\n",
    "#         mode = kwargs.get('mode')\n",
    "#         feature_name = col_name(cols, func=func)\n",
    "#         print(feature_name)\n",
    "#         if mode.lower() == 'train_history':\n",
    "#             result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
    "#         elif mode.lower() == 'train_all':\n",
    "#             result_dict[feature_name] = func(train, df_train, cols, target=target)\n",
    "#         elif mode.lower() == 'test_history':\n",
    "#             result_dict[feature_name] = func(df_history, test, cols, target=target)\n",
    "#         elif mode.lower() == 'test_all':\n",
    "#             result_dict[feature_name] = func(train, test, cols, target=target)\n",
    "#         else:\n",
    "#             print('known mode !!!!')\n",
    "#     return result_dict\n",
    "\n",
    "\n",
    "# # def build_kwargs(df_history, df_train, target, combine_col, func_pool, comb_total=3):\n",
    "# #     kwargs_pool = []\n",
    "# #     for num_col in range(1, comb_total + 1):\n",
    "# #         for cols in combinations(combine_col, num_col):\n",
    "# #             for func in func_pool:\n",
    "# #                 kwargs = {}\n",
    "# #                 kwargs['df_history'] = df_history\n",
    "# #                 kwargs['df_train'] = df_train\n",
    "# #                 kwargs['target'] = target\n",
    "# #                 kwargs['cols'] = cols\n",
    "# #                 kwargs['func'] = func\n",
    "# #                 kwargs_pool.append(kwargs)\n",
    "# #     return kwargs_pool\n",
    "\n",
    "# def build_kwargs( combine_col, func_pool, mode='train',comb_total=3):\n",
    "#     kwargs_pool = []\n",
    "#     for num_col in range(1, comb_total + 1):\n",
    "#         for cols in combinations(combine_col, num_col):\n",
    "#             for func in func_pool:\n",
    "#                 kwargs = {}\n",
    "#                 kwargs['cols'] = cols\n",
    "#                 kwargs['func'] = func\n",
    "#                 kwargs['mode'] = mode\n",
    "#                 kwargs_pool.append(kwargs)\n",
    "#     return kwargs_pool\n",
    "\n",
    "# def multiprocessing_features(df_history, df_train, target, combine_col, func_pool, comb_total=3, workers=3, mode='train_history'):\n",
    "#     kwargs_pool = build_kwargs(combine_col, func_pool, mode, comb_total=3)\n",
    "#     print('build kwargs done!')\n",
    "#     pool = multiprocessing.Pool(processes=workers)\n",
    "#     result = pool.map(_process_each_col, [kwargs for kwargs in np.array_split(kwargs_pool, workers)])\n",
    "#     pool.close()\n",
    "#     print('feature processing done!!!!!!!!!!!!!!')\n",
    "#     for each_thread in result:\n",
    "#         for key in each_thread:\n",
    "#             df_train[key] = each_thread[key]\n",
    "#     return df_train\n",
    "\n",
    "\n",
    "# df_train = multiprocessing_features(df_history, df_train, target, combine_col, func_pool, comb_total=3, workers=3, mode='train_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training saving done!\n",
      "testing saving done!\n"
     ]
    }
   ],
   "source": [
    "df_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_fold_last_in_12_reversemean.csv', index=False)\n",
    "print('training saving done!')\n",
    "test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_fold_last_in_12_reversemean.csv', index=False)\n",
    "print('testing saving done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training saving done!\n",
      "testing saving done!\n"
     ]
    }
   ],
   "source": [
    "#For float saving\n",
    "\n",
    "\n",
    "# df_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_fold_last_in_12_mean_1float.csv', index=False, float_format='%.1f')\n",
    "# print('training saving done!')\n",
    "# test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_fold_last_in_12_mean_1float.csv', index=False, float_format='%.1f')\n",
    "# print('testing saving done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
