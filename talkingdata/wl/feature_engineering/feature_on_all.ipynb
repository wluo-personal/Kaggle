{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 12\n",
    "# kf = KFold(n_splits=K, shuffle = False)\n",
    "kf = KFold(n_splits=K, shuffle = True, random_state = 233)\n",
    "history_index = []\n",
    "train_index = []\n",
    "for h,t in kf.split(train):\n",
    "    history_index.append(h)\n",
    "    train_index.append(t)\n",
    "    \n",
    "### use last fold as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.154054783284664\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(train)/ 1024 **3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use last fold as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_history = train.iloc[history_index[-1]].copy()\n",
    "df_train = train.iloc[train_index[-1]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.377641312777996\n",
      "15408657\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(df_train)/ 1024 **3)\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip', 'app', 'device', 'os', 'channel', 'day', 'hour', 'timestamp',\n",
       "       'minute', 'second', 'is_attributed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n",
    "\n",
    "import gc\n",
    "# del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 1000,\n",
       " 'channel': 1000,\n",
       " 'day': 100,\n",
       " 'device': 10000,\n",
       " 'hour': 100,\n",
       " 'ip': 1000000,\n",
       " 'minute': 100,\n",
       " 'os': 1000,\n",
       " 'second': 100}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count\n",
    "plan 1. count from historical data  \n",
    "plan 2. count from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean\n",
    "mean P(target | feature combination)\n",
    "\n",
    "purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer))\n",
    "Get the conditional Probability only from historical data and apply to train data.\n",
    "\n",
    "P(replay | X feature combination) = P( replay & X feature combination) / P (X feature combination)  \n",
    "=(count(replay & X feature combination) / count(total)) / (count(X feature combination) / count(total))  \n",
    "= count(replay & X feature combination) / count(X feature combination)  \n",
    "= sum((replay & X feature combination)) / count(X feature combination)  \n",
    "= sum((replay or not replayed & X feature combination)) / count(X feature combination)# since replay is 1, not replay is 0  \n",
    "= sum( X feature combination) / count(X feature combination)  \n",
    "= mean(X feature combination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaller(num):\n",
    "    sca = 1\n",
    "    while num * sca < 1:\n",
    "        sca *= 10\n",
    "    return sca\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    # mean_map: key - encoding, value - target mean\n",
    "#     ### sca\n",
    "#     m_min = mean_map[mean_map > 0].min()\n",
    "#     sca = scaller(m_min)\n",
    "#     mean_map *= sca\n",
    "#     ###\n",
    "\n",
    "    return group.map(mean_map).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reversemean\n",
    "reverse mean P(feature combination | target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1:   ip_reversemean   \t\t\t size: 1.4924447536468506 G.\n",
      "test 1:   ip_reversemean   \t\t\t size: 1.5399990379810333 G.\n",
      "------\n",
      "train 2:   app_reversemean   \t\t\t size: 1.607248194515705 G.\n",
      "test 2:   app_reversemean   \t\t\t size: 1.679998941719532 G.\n",
      "------\n",
      "train 3:   device_reversemean   \t\t\t size: 1.7220516353845596 G.\n",
      "test 3:   device_reversemean   \t\t\t size: 1.8199988454580307 G.\n",
      "------\n",
      "train 4:   os_reversemean   \t\t\t size: 1.8368550762534142 G.\n",
      "test 4:   os_reversemean   \t\t\t size: 1.9599987491965294 G.\n",
      "------\n",
      "train 5:   channel_reversemean   \t\t\t size: 1.9516585171222687 G.\n",
      "test 5:   channel_reversemean   \t\t\t size: 2.099998652935028 G.\n",
      "------\n",
      "train 6:   hour_reversemean   \t\t\t size: 2.066461957991123 G.\n",
      "test 6:   hour_reversemean   \t\t\t size: 2.2399985566735268 G.\n",
      "------\n",
      "train 7:   minute_reversemean   \t\t\t size: 2.1812653988599777 G.\n",
      "test 7:   minute_reversemean   \t\t\t size: 2.3799984604120255 G.\n",
      "------\n",
      "train 8:   second_reversemean   \t\t\t size: 2.2960688397288322 G.\n",
      "test 8:   second_reversemean   \t\t\t size: 2.519998364150524 G.\n",
      "------\n",
      "train 9:   ip_app_reversemean   \t\t\t size: 2.4108722805976868 G.\n",
      "test 9:   ip_app_reversemean   \t\t\t size: 2.659998267889023 G.\n",
      "------\n",
      "train 10:   ip_device_reversemean   \t\t\t size: 2.5256757214665413 G.\n",
      "test 10:   ip_device_reversemean   \t\t\t size: 2.7999981716275215 G.\n",
      "------\n",
      "train 11:   ip_os_reversemean   \t\t\t size: 2.640479162335396 G.\n",
      "test 11:   ip_os_reversemean   \t\t\t size: 2.93999807536602 G.\n",
      "------\n",
      "train 12:   ip_channel_reversemean   \t\t\t size: 2.7552826032042503 G.\n",
      "test 12:   ip_channel_reversemean   \t\t\t size: 3.079997979104519 G.\n",
      "------\n",
      "train 13:   ip_hour_reversemean   \t\t\t size: 2.870086044073105 G.\n",
      "test 13:   ip_hour_reversemean   \t\t\t size: 3.2199978828430176 G.\n",
      "------\n",
      "train 14:   ip_minute_reversemean   \t\t\t size: 2.9848894849419594 G.\n",
      "test 14:   ip_minute_reversemean   \t\t\t size: 3.3599977865815163 G.\n",
      "------\n",
      "train 15:   ip_second_reversemean   \t\t\t size: 3.099692925810814 G.\n",
      "test 15:   ip_second_reversemean   \t\t\t size: 3.499997690320015 G.\n",
      "------\n",
      "train 16:   app_device_reversemean   \t\t\t size: 3.2144963666796684 G.\n",
      "test 16:   app_device_reversemean   \t\t\t size: 3.6399975940585136 G.\n",
      "------\n",
      "train 17:   app_os_reversemean   \t\t\t size: 3.329299807548523 G.\n",
      "test 17:   app_os_reversemean   \t\t\t size: 3.7799974977970123 G.\n",
      "------\n",
      "train 18:   app_channel_reversemean   \t\t\t size: 3.4441032484173775 G.\n",
      "test 18:   app_channel_reversemean   \t\t\t size: 3.919997401535511 G.\n",
      "------\n",
      "train 19:   app_hour_reversemean   \t\t\t size: 3.558906689286232 G.\n",
      "test 19:   app_hour_reversemean   \t\t\t size: 4.05999730527401 G.\n",
      "------\n",
      "train 20:   app_minute_reversemean   \t\t\t size: 3.6737101301550865 G.\n",
      "test 20:   app_minute_reversemean   \t\t\t size: 4.199997209012508 G.\n",
      "------\n",
      "train 21:   app_second_reversemean   \t\t\t size: 3.788513571023941 G.\n",
      "test 21:   app_second_reversemean   \t\t\t size: 4.339997112751007 G.\n",
      "------\n",
      "train 22:   device_os_reversemean   \t\t\t size: 3.9033170118927956 G.\n",
      "test 22:   device_os_reversemean   \t\t\t size: 4.479997016489506 G.\n",
      "------\n",
      "train 23:   device_channel_reversemean   \t\t\t size: 4.01812045276165 G.\n",
      "test 23:   device_channel_reversemean   \t\t\t size: 4.6199969202280045 G.\n",
      "------\n",
      "train 24:   device_hour_reversemean   \t\t\t size: 4.132923893630505 G.\n",
      "test 24:   device_hour_reversemean   \t\t\t size: 4.759996823966503 G.\n",
      "------\n",
      "train 25:   device_minute_reversemean   \t\t\t size: 4.247727334499359 G.\n",
      "test 25:   device_minute_reversemean   \t\t\t size: 4.899996727705002 G.\n",
      "------\n",
      "train 26:   device_second_reversemean   \t\t\t size: 4.362530775368214 G.\n",
      "test 26:   device_second_reversemean   \t\t\t size: 5.0399966314435005 G.\n",
      "------\n",
      "train 27:   os_channel_reversemean   \t\t\t size: 4.477334216237068 G.\n",
      "test 27:   os_channel_reversemean   \t\t\t size: 5.179996535181999 G.\n",
      "------\n",
      "train 28:   os_hour_reversemean   \t\t\t size: 4.592137657105923 G.\n",
      "test 28:   os_hour_reversemean   \t\t\t size: 5.319996438920498 G.\n",
      "------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2fd04b1e3254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#             df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#             test[feature_name] = func(df_history, test, cols, target='is_attributed')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'is_attributed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'is_attributed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-06436470b287>\u001b[0m in \u001b[0;36mreversemean\u001b[0;34m(df_history, df_train, cols, target)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# get the conditional probability p(target| feature combination. eg, artist_name_composer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mindex_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mindex_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             return self._constructor(self._data.get_slice(indexer),\n\u001b[0m\u001b[1;32m    710\u001b[0m                                      fastpath=True).__finalize__(self)\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4180\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requested axis not found in manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m         return self.__class__(self._block._slice(slobj),\n\u001b[0m\u001b[1;32m   4183\u001b[0m                               self.index[slobj], fastpath=True)\n\u001b[1;32m   4184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslicer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"\"\" return a slice of my values \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshape_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel', \n",
    "#               'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "# combine_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "exception_list = []\n",
    "for num_col in [1,2,3]:\n",
    "    for cols in combinations(combine_col, num_col):\n",
    "#         for func in [count, mean]:\n",
    "        for func in [reversemean]:\n",
    "            counter += 1\n",
    "            feature_name = col_name(cols, func=func)\n",
    "            if feature_name in exception_list:\n",
    "                continue\n",
    "#             df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "#             test[feature_name] = func(df_history, test, cols, target='is_attributed')\n",
    "            df_train[feature_name] = func(train, df_train, cols, target='is_attributed')\n",
    "            test[feature_name] = func(train, test, cols, target='is_attributed')\n",
    "            gc.collect()\n",
    "            train_str = 'train {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "            test_str = 'test {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(test)/ 1024 **3)\n",
    "            print(train_str)\n",
    "            print(test_str)\n",
    "            print('------')\n",
    "            with open('feature_all.txt', 'w') as text_file:\n",
    "                text_file.write(train_str + '\\n')\n",
    "                text_file.write(test_str + '\\n')\n",
    "                text_file.write('------' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-processing version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build kwargs done!\n",
      "thread start !!!!!!!\n",
      "thread start !!!!!!!\n",
      "thread start !!!!!!!\n",
      "ip_count\n",
      "app_channel_minute_count\n",
      "hour_second_count\n",
      "hour_second_mean\n",
      "app_channel_minute_mean\n",
      "ip_mean\n",
      "minute_second_count\n",
      "app_channel_second_count\n",
      "minute_second_mean\n",
      "app_channel_second_mean\n",
      "app_count\n",
      "ip_app_device_count\n",
      "app_mean\n",
      "app_day_hour_count\n",
      "device_count\n",
      "app_day_hour_mean\n",
      "device_mean\n",
      "app_day_minute_count\n",
      "ip_app_device_mean\n",
      "os_count\n",
      "app_day_minute_mean\n",
      "os_mean\n",
      "channel_count\n",
      "app_day_second_count\n",
      "channel_mean\n",
      "app_day_second_mean\n",
      "ip_app_os_count\n",
      "day_count\n",
      "app_hour_minute_count\n",
      "day_mean\n",
      "app_hour_minute_mean\n",
      "hour_count\n",
      "hour_mean\n",
      "app_hour_second_count\n",
      "ip_app_os_mean\n",
      "minute_count\n",
      "app_hour_second_mean\n",
      "minute_mean\n",
      "second_count\n",
      "app_minute_second_count\n",
      "second_mean\n",
      "app_minute_second_mean\n",
      "ip_app_count\n",
      "device_os_channel_count\n",
      "ip_app_channel_count\n",
      "device_os_channel_mean\n",
      "ip_app_mean\n",
      "device_os_day_count\n",
      "device_os_day_mean\n",
      "ip_app_channel_mean\n",
      "device_os_hour_count\n",
      "ip_device_count\n",
      "device_os_hour_mean\n",
      "ip_device_mean\n",
      "device_os_minute_count\n",
      "device_os_minute_mean\n",
      "ip_os_count\n",
      "ip_app_day_count\n",
      "device_os_second_count\n",
      "device_os_second_mean\n",
      "ip_os_mean\n",
      "device_channel_day_count\n",
      "ip_app_day_mean\n",
      "device_channel_day_mean\n",
      "device_channel_hour_count\n",
      "ip_channel_count\n",
      "device_channel_hour_mean\n",
      "device_channel_minute_count\n",
      "ip_app_hour_count\n",
      "device_channel_minute_mean\n",
      "ip_channel_mean\n",
      "device_channel_second_count\n",
      "ip_app_hour_mean\n",
      "device_channel_second_mean\n",
      "device_day_hour_count\n",
      "ip_day_count\n",
      "device_day_hour_mean\n",
      "device_day_minute_count\n",
      "ip_day_mean\n",
      "device_day_minute_mean\n",
      "ip_app_minute_count\n",
      "ip_hour_count\n",
      "device_day_second_count\n",
      "device_day_second_mean\n",
      "ip_hour_mean\n",
      "device_hour_minute_count\n",
      "ip_app_minute_mean\n",
      "device_hour_minute_mean\n",
      "ip_minute_count\n",
      "device_hour_second_count\n",
      "device_hour_second_mean\n",
      "ip_minute_mean\n",
      "device_minute_second_count\n",
      "device_minute_second_mean\n",
      "os_channel_day_count\n",
      "ip_second_count\n",
      "ip_app_second_count\n",
      "os_channel_day_mean\n",
      "os_channel_hour_count\n",
      "ip_second_mean\n",
      "os_channel_hour_mean\n",
      "ip_app_second_mean\n",
      "os_channel_minute_count\n",
      "os_channel_minute_mean\n",
      "app_device_count\n",
      "app_device_mean\n",
      "os_channel_second_count\n",
      "app_os_count\n",
      "app_os_mean\n",
      "os_channel_second_mean\n",
      "app_channel_count\n",
      "ip_device_os_count\n",
      "app_channel_mean\n",
      "os_day_hour_count\n",
      "app_day_count\n",
      "os_day_hour_mean\n",
      "app_day_mean\n",
      "ip_device_os_mean\n",
      "os_day_minute_count\n",
      "app_hour_count\n",
      "app_hour_mean\n",
      "os_day_minute_mean\n",
      "ip_device_channel_count\n",
      "app_minute_count\n",
      "os_day_second_count\n",
      "app_minute_mean\n",
      "os_day_second_mean\n",
      "app_second_count\n",
      "os_hour_minute_count\n",
      "ip_device_channel_mean\n",
      "app_second_mean\n",
      "os_hour_minute_mean\n",
      "device_os_count\n",
      "os_hour_second_count\n",
      "device_os_mean\n",
      "os_hour_second_mean\n",
      "device_channel_count\n",
      "os_minute_second_count\n",
      "device_channel_mean\n",
      "ip_device_day_count\n",
      "os_minute_second_mean\n",
      "device_day_count\n",
      "ip_device_day_mean\n",
      "device_day_mean\n",
      "channel_day_hour_count\n",
      "device_hour_count\n",
      "device_hour_mean\n",
      "channel_day_hour_mean\n",
      "ip_device_hour_count\n",
      "device_minute_count\n",
      "channel_day_minute_count\n",
      "device_minute_mean\n",
      "ip_device_hour_mean\n",
      "channel_day_minute_mean\n",
      "device_second_count\n",
      "device_second_mean\n",
      "channel_day_second_count\n",
      "os_channel_count\n",
      "channel_day_second_mean\n",
      "ip_device_minute_count\n",
      "os_channel_mean\n",
      "channel_hour_minute_count\n",
      "os_day_count\n",
      "channel_hour_minute_mean\n",
      "ip_device_minute_mean\n",
      "os_day_mean\n",
      "channel_hour_second_count\n",
      "os_hour_count\n",
      "channel_hour_second_mean\n",
      "os_hour_mean\n",
      "ip_device_second_count\n",
      "channel_minute_second_count\n",
      "os_minute_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 7, in count\n",
      "    group_all = get_group(df_history, cols)\n",
      "  File \"<ipython-input-8-6613b36fca9d>\", line 18, in get_group\n",
      "    group = df[cols[0]].copy()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3432, in copy\n",
      "    data = self._data.copy(deep=deep)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3436, in copy\n",
      "    do_integrity_check=False)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3091, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 629, in copy\n",
      "    values = values.copy()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 7, in count\n",
      "    group_all = get_group(df_history, cols)\n",
      "  File \"<ipython-input-8-6613b36fca9d>\", line 18, in get_group\n",
      "    group = df[cols[0]].copy()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 3432, in copy\n",
      "    data = self._data.copy(deep=deep)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3436, in copy\n",
      "    do_integrity_check=False)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 3091, in apply\n",
      "    applied = getattr(b, f)(**kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 629, in copy\n",
      "    values = values.copy()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c973b4268b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-c973b4268b5b>\u001b[0m in \u001b[0;36mmultiprocessing_features\u001b[0;34m(df_history, df_train, target, combine_col, func_pool, comb_total, workers, mode)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'build kwargs done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_process_each_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature processing done!!!!!!!!!!!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-14-c973b4268b5b>\", line 49, in _process_each_col\n",
      "    result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
      "  File \"<ipython-input-10-4fbe1539f76c>\", line 9, in count\n",
      "    count_map = group_all.value_counts()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/base.py\", line 938, in value_counts\n",
      "    normalize=normalize, bins=bins, dropna=dropna)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 640, in value_counts\n",
      "    keys, counts = _value_counts_arraylike(values, dropna)\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 685, in _value_counts_arraylike\n",
      "    keys, counts = f(values, dropna)\n",
      "  File \"pandas/_libs/hashtable_func_helper.pxi\", line 504, in pandas._libs.hashtable.value_count_int64\n",
      "  File \"pandas/_libs/hashtable_func_helper.pxi\", line 529, in pandas._libs.hashtable.value_count_int64\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\", line 463, in asarray\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "\n",
    "# ####################\n",
    "# from itertools import combinations\n",
    "\n",
    "\n",
    "# combine_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel', \n",
    "#               'day',\n",
    "#               'hour',\n",
    "#               'minute',\n",
    "#               'second']\n",
    "\n",
    "# func_pool = [count, mean]\n",
    "\n",
    "# target = 'is_attributed'\n",
    "\n",
    "# def col_name(cols, func=None):\n",
    "#     if func is None:\n",
    "#         return '_'.join(cols)\n",
    "#     else:\n",
    "#         return '_'.join(cols) + '_' + func.__name__\n",
    "# ###################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def _process_each_col(kwargs_list):\n",
    "#     print('thread start !!!!!!!')\n",
    "#     result_dict = {}\n",
    "    \n",
    "#     for kwargs in kwargs_list:\n",
    "# #         df_train = kwargs.get('df_train')\n",
    "# #         df_history = kwargs.get('df_history')\n",
    "# #         target = kwargs.get('target')\n",
    "# #         df_train = df_train\n",
    "# #         df_history = df_history\n",
    "# #         target = target\n",
    "#         cols = kwargs.get('cols')\n",
    "#         func = kwargs.get('func')\n",
    "#         mode = kwargs.get('mode')\n",
    "#         feature_name = col_name(cols, func=func)\n",
    "#         print(feature_name)\n",
    "#         if mode.lower() == 'train_history':\n",
    "#             result_dict[feature_name] = func(df_history, df_train, cols, target=target)\n",
    "#         elif mode.lower() == 'train_all':\n",
    "#             result_dict[feature_name] = func(train, df_train, cols, target=target)\n",
    "#         elif mode.lower() == 'test_history':\n",
    "#             result_dict[feature_name] = func(df_history, test, cols, target=target)\n",
    "#         elif mode.lower() == 'test_all':\n",
    "#             result_dict[feature_name] = func(train, test, cols, target=target)\n",
    "#         else:\n",
    "#             print('known mode !!!!')\n",
    "#     return result_dict\n",
    "\n",
    "\n",
    "# # def build_kwargs(df_history, df_train, target, combine_col, func_pool, comb_total=3):\n",
    "# #     kwargs_pool = []\n",
    "# #     for num_col in range(1, comb_total + 1):\n",
    "# #         for cols in combinations(combine_col, num_col):\n",
    "# #             for func in func_pool:\n",
    "# #                 kwargs = {}\n",
    "# #                 kwargs['df_history'] = df_history\n",
    "# #                 kwargs['df_train'] = df_train\n",
    "# #                 kwargs['target'] = target\n",
    "# #                 kwargs['cols'] = cols\n",
    "# #                 kwargs['func'] = func\n",
    "# #                 kwargs_pool.append(kwargs)\n",
    "# #     return kwargs_pool\n",
    "\n",
    "# def build_kwargs( combine_col, func_pool, mode='train',comb_total=3):\n",
    "#     kwargs_pool = []\n",
    "#     for num_col in range(1, comb_total + 1):\n",
    "#         for cols in combinations(combine_col, num_col):\n",
    "#             for func in func_pool:\n",
    "#                 kwargs = {}\n",
    "#                 kwargs['cols'] = cols\n",
    "#                 kwargs['func'] = func\n",
    "#                 kwargs['mode'] = mode\n",
    "#                 kwargs_pool.append(kwargs)\n",
    "#     return kwargs_pool\n",
    "\n",
    "# def multiprocessing_features(df_history, df_train, target, combine_col, func_pool, comb_total=3, workers=3, mode='train_history'):\n",
    "#     kwargs_pool = build_kwargs(combine_col, func_pool, mode, comb_total=3)\n",
    "#     print('build kwargs done!')\n",
    "#     pool = multiprocessing.Pool(processes=workers)\n",
    "#     result = pool.map(_process_each_col, [kwargs for kwargs in np.array_split(kwargs_pool, workers)])\n",
    "#     pool.close()\n",
    "#     print('feature processing done!!!!!!!!!!!!!!')\n",
    "#     for each_thread in result:\n",
    "#         for key in each_thread:\n",
    "#             df_train[key] = each_thread[key]\n",
    "#     return df_train\n",
    "\n",
    "\n",
    "# df_train = multiprocessing_features(df_history, df_train, target, combine_col, func_pool, comb_total=3, workers=3, mode='train_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training saving done!\n",
      "testing saving done!\n"
     ]
    }
   ],
   "source": [
    "df_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_fold_last_in_12_reversemean.csv', index=False)\n",
    "print('training saving done!')\n",
    "test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_fold_last_in_12_reversemean.csv', index=False)\n",
    "print('testing saving done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training saving done!\n",
      "testing saving done!\n"
     ]
    }
   ],
   "source": [
    "#For float saving\n",
    "\n",
    "\n",
    "# df_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_fold_last_in_12_mean_1float.csv', index=False, float_format='%.1f')\n",
    "# print('training saving done!')\n",
    "# test.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_fold_last_in_12_mean_1float.csv', index=False, float_format='%.1f')\n",
    "# print('testing saving done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
