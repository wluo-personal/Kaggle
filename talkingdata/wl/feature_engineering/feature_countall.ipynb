{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get K Fold and use last fold as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K = 18\n",
    "# # kf = KFold(n_splits=K, shuffle = False)\n",
    "# kf = KFold(n_splits=K, shuffle = True, random_state = 233)\n",
    "# history_index = []\n",
    "# train_index = []\n",
    "# for h,t in kf.split(train):\n",
    "#     history_index.append(h)\n",
    "#     train_index.append(t)\n",
    "\n",
    "# ### use last fold as example\n",
    "\n",
    "# import sys\n",
    "# print(sys.getsizeof(train)/ 1024 **3)\n",
    "\n",
    "\n",
    "# #use last fold as example\n",
    "# length_train = len(train)\n",
    "# df_history = train.iloc[history_index[-1]].copy()\n",
    "# df_train = train.iloc[train_index[-1]].copy()\n",
    "\n",
    "\n",
    "# print(sys.getsizeof(df_train)/ 1024 **3)\n",
    "# print(len(df_train))\n",
    "# print(sys.getsizeof(df_history)/ 1024 **3)\n",
    "# print(len(df_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use last 10 million data as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_train = len(train)\n",
    "sample_length = 50 * 1000000\n",
    "df_history = train.iloc[: length_train - sample_length].copy()\n",
    "df_train = train.iloc[length_train - sample_length :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip', 'app', 'device', 'os', 'channel', 'day', 'hour', 'timestamp',\n",
       "       'minute', 'second', 'is_attributed', 'intesthh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'minute',\n",
    "              'second',\n",
    "              'intesthh']\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(train[col].max() + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group\n",
    "\n",
    "import gc\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 1000,\n",
       " 'channel': 1000,\n",
       " 'day': 100,\n",
       " 'device': 10000,\n",
       " 'hour': 100,\n",
       " 'intesthh': 10,\n",
       " 'ip': 1000000,\n",
       " 'minute': 100,\n",
       " 'os': 1000,\n",
       " 'second': 100}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count\n",
    "plan 1. count from historical data  \n",
    "plan 2. count from all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean\n",
    "mean P(target | feature combination)\n",
    "\n",
    "purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer))\n",
    "Get the conditional Probability only from historical data and apply to train data.\n",
    "\n",
    "P(replay | X feature combination) = P( replay & X feature combination) / P (X feature combination)  \n",
    "=(count(replay & X feature combination) / count(total)) / (count(X feature combination) / count(total))  \n",
    "= count(replay & X feature combination) / count(X feature combination)  \n",
    "= sum((replay & X feature combination)) / count(X feature combination)  \n",
    "= sum((replay or not replayed & X feature combination)) / count(X feature combination)# since replay is 1, not replay is 0  \n",
    "= sum( X feature combination) / count(X feature combination)  \n",
    "= mean(X feature combination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaller(num):\n",
    "    sca = 1\n",
    "    while num * sca < 1:\n",
    "        sca *= 10\n",
    "    return sca\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    # mean_map: key - encoding, value - target mean\n",
    "#     ### sca\n",
    "#     m_min = mean_map[mean_map > 0].min()\n",
    "#     sca = scaller(m_min)\n",
    "#     mean_map *= sca\n",
    "#     ###\n",
    "\n",
    "    return group.map(mean_map).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reversemean\n",
    "reverse mean P(feature combination | target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time related\n",
    "get pattern on train and test respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    df_reverse = df_train.sort_values([timecol], ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse[timecol]):\n",
    "        if g in next_heard:\n",
    "            result.append(next_heard[g] - t)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    group = get_group(df_train, cols)\n",
    "\n",
    "    last_heard = {}\n",
    "    for t, g in zip(df_train[timecol], group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfrompast(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfromfuture(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_values([timecol], ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def lasttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    last_time = df_train.groupby(group)[timecol].last()\n",
    "    \n",
    "    return group.map(last_time) - df_train[timecol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 1:   ip_lasttimediff   \t\t\t size: 4.842877488583326 G.\n",
      "all 2:   app_lasttimediff   \t\t\t size: 5.215406518429518 G.\n",
      "all 3:   device_lasttimediff   \t\t\t size: 5.587935548275709 G.\n",
      "all 4:   os_lasttimediff   \t\t\t size: 5.960464578121901 G.\n",
      "all 5:   channel_lasttimediff   \t\t\t size: 6.332993607968092 G.\n",
      "all 6:   ip_app_lasttimediff   \t\t\t size: 6.705522637814283 G.\n",
      "all 7:   ip_device_lasttimediff   \t\t\t size: 7.078051667660475 G.\n",
      "all 8:   ip_os_lasttimediff   \t\t\t size: 7.450580697506666 G.\n",
      "all 9:   ip_channel_lasttimediff   \t\t\t size: 7.823109727352858 G.\n",
      "all 10:   app_device_lasttimediff   \t\t\t size: 8.195638757199049 G.\n",
      "all 11:   app_os_lasttimediff   \t\t\t size: 8.56816778704524 G.\n",
      "all 12:   app_channel_lasttimediff   \t\t\t size: 8.940696816891432 G.\n",
      "all 13:   device_os_lasttimediff   \t\t\t size: 9.313225846737623 G.\n",
      "all 14:   device_channel_lasttimediff   \t\t\t size: 9.685754876583815 G.\n",
      "all 15:   os_channel_lasttimediff   \t\t\t size: 10.058283906430006 G.\n",
      "all 16:   ip_app_device_lasttimediff   \t\t\t size: 10.430812936276197 G.\n",
      "all 17:   ip_app_os_lasttimediff   \t\t\t size: 10.803341966122389 G.\n",
      "all 18:   ip_app_channel_lasttimediff   \t\t\t size: 11.17587099596858 G.\n",
      "all 19:   ip_device_os_lasttimediff   \t\t\t size: 11.548400025814772 G.\n",
      "all 20:   ip_device_channel_lasttimediff   \t\t\t size: 11.920929055660963 G.\n",
      "all 21:   ip_os_channel_lasttimediff   \t\t\t size: 12.293458085507154 G.\n",
      "all 22:   app_device_os_lasttimediff   \t\t\t size: 12.665987115353346 G.\n",
      "all 23:   app_device_channel_lasttimediff   \t\t\t size: 13.038516145199537 G.\n",
      "all 24:   app_os_channel_lasttimediff   \t\t\t size: 13.411045175045729 G.\n",
      "all 25:   device_os_channel_lasttimediff   \t\t\t size: 13.78357420489192 G.\n",
      "all 26:   ip_app_device_os_lasttimediff   \t\t\t size: 14.156103234738111 G.\n",
      "all 27:   ip_app_device_channel_lasttimediff   \t\t\t size: 14.528632264584303 G.\n",
      "all 28:   ip_app_os_channel_lasttimediff   \t\t\t size: 14.901161294430494 G.\n",
      "all 29:   ip_device_os_channel_lasttimediff   \t\t\t size: 15.273690324276686 G.\n",
      "all 30:   app_device_os_channel_lasttimediff   \t\t\t size: 15.646219354122877 G.\n",
      "all 31:   ip_app_device_os_channel_lasttimediff   \t\t\t size: 16.01874838396907 G.\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import sys\n",
    "\n",
    "\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel', \n",
    "              'day',\n",
    "              'hour',\n",
    "              'intesthh']\n",
    "\n",
    "combine_col_time = ['ip', \n",
    "                    'app', \n",
    "                    'device', \n",
    "                    'os', \n",
    "                    'channel']\n",
    "\n",
    "\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "exception_list = []\n",
    "for num_col in [1,2,3,4,5]:\n",
    "    # below for count and mean\n",
    "    \n",
    "#     for cols in combinations(combine_col, num_col):\n",
    "# #         for func in [count, mean]:\n",
    "#         for func in [reversemean]:\n",
    "#             feature_name = col_name(cols, func=func)\n",
    "#             counter += 1\n",
    "#             if func.__name__ == count.__name__:\n",
    "#                 print('count function')\n",
    "#                 df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "#             else:\n",
    "#                 print('mean function')\n",
    "#                 df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "#             all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "#             print(all_str)\n",
    "#             with open('feature_all.txt', 'w') as text_file:\n",
    "#                 text_file.write(all_str + '\\n')\n",
    "                \n",
    "    # below for time related\n",
    "    for cols in combinations(combine_col_time, num_col):\n",
    "#         for func in [time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff]:\n",
    "        for func in [lasttimediff]:\n",
    "            feature_name = col_name(cols, func=func)\n",
    "            counter += 1\n",
    "            df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "            all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "            print(all_str)\n",
    "            with open('feature_all.txt', 'w') as text_file:\n",
    "                text_file.write(all_str + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000000\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_lasttimediff_combine5_0409.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>intesthh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978741</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978814</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978852</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978892</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978908</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18787</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509978986</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509979064</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114221</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509979079</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165970</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509979090</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74544</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>459</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1509979103</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel  day  hour   timestamp  minute  second  \\\n",
       "0   83230    3       1  13      379    6    14  1509978741      32      21   \n",
       "1   17357    3       1  19      379    6    14  1509978814      33      34   \n",
       "2   35810    3       1  13      379    6    14  1509978852      34      12   \n",
       "3   45745   14       1  13      478    6    14  1509978892      34      52   \n",
       "4  161007    3       1  13      379    6    14  1509978908      35       8   \n",
       "5   18787    3       1  16      379    6    14  1509978986      36      26   \n",
       "6  103022    3       1  23      379    6    14  1509979064      37      44   \n",
       "7  114221    3       1  19      379    6    14  1509979079      37      59   \n",
       "8  165970    3       1  13      379    6    14  1509979090      38      10   \n",
       "9   74544   64       1  22      459    6    14  1509979103      38      23   \n",
       "\n",
       "   is_attributed  intesthh  \n",
       "0              0         1  \n",
       "1              0         1  \n",
       "2              0         1  \n",
       "3              0         1  \n",
       "4              0         1  \n",
       "5              0         1  \n",
       "6              0         1  \n",
       "7              0         1  \n",
       "8              0         1  \n",
       "9              0         1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
