{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "train = pd.read_csv(path + 'train_cleaned_final.csv')\n",
    "test = pd.read_csv(path + 'test_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train on Day7 Day8 Day9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "feature_count =  [\n",
    "                    'ip_day_hour_count',\n",
    "                    'ip_os_day_hour_count',\n",
    "                    'ip_app_day_hour_count',\n",
    "                    'ip_app_os_day_hour_count',\n",
    "                    'app_day_hour_count',\n",
    "                    'ip_device_os_count',\n",
    "                    'ip_app_device_os_count']\n",
    "\n",
    "feature_mean = ['ip_device_os_mean',\n",
    "                'ip_app_device_os_mean', 'ip_app_device_mean', 'app_device_os_mean']\n",
    "\n",
    "\n",
    "feature_reversemean = []\n",
    "\n",
    "feature_time2nextclick = ['ip_device_os_time2nextclick',\n",
    "                            'ip_app_device_os_time2nextclick',\n",
    "                          'ip_app_device_time2nextclick', 'ip_app_device_os_channel_time2nextclick']\n",
    "\n",
    "feature_time2previousclick = ['ip_device_os_time2previousclick', \n",
    "                                'ip_app_device_os_time2previousclick', \n",
    "                              'ip_app_device_time2previousclick', 'ip_app_device_os_channel_time2previousclick']\n",
    "    \n",
    "    \n",
    "feature_countfromfuture = ['ip_device_os_countfromfuture',\n",
    "                            'ip_app_device_os_countfromfuture', \n",
    "                           'ip_app_device_countfromfuture', 'ip_app_device_os_channel_countfromfuture']\n",
    "\n",
    "feature_countfrompast = ['ip_device_os_countfrompast',\n",
    "                            'ip_app_device_os_countfrompast', \n",
    "                         'ip_app_device_countfrompast', 'ip_app_device_os_channel_countfrompast']\n",
    "    \n",
    "feature_lasttimediff =  ['ip_device_os_lasttimediff',\n",
    "                             'ip_app_device_os_lasttimediff', \n",
    "                         'ip_app_device_lasttimediff', 'ip_app_device_os_channel_lasttimediff']\n",
    "\n",
    "feature_firsttimediff =  ['ip_device_os_firsttimediff',\n",
    "                             'ip_app_device_os_firsttimediff', \n",
    "                         'ip_app_device_firsttimediff', 'ip_app_device_os_channel_firsttimediff']\n",
    "\n",
    "\n",
    "feature_matrixfac = [ 'matrixFact_user_iposdeviceapp_item_app', \n",
    "                     'matrixFact_user_ip_item_appdeviceos',\n",
    "                    'matrixFact_user_ipchannel_item_appdeviceos']\n",
    "\n",
    "\n",
    "\n",
    "feature_var = ['ip_app_os_var_hour', 'ip_app_channel_var_day']\n",
    "feature_var = [] # best result need to add var\n",
    "feature_regression = ['ip_device_os_regression', \n",
    "                      'ip_app_device_os_regression', \n",
    "                      'ip_app_device_regression', 'ip_app_device_os_channel_regression']\n",
    "                         \n",
    "\n",
    "feature_ori = ['app', 'channel', 'device', 'os', 'hour']\n",
    "\n",
    "feature_cols = []\n",
    "added_feature = []\n",
    "\n",
    "added_feature.extend(feature_count)\n",
    "added_feature.extend(feature_mean)\n",
    "added_feature.extend(feature_reversemean)\n",
    "added_feature.extend(feature_time2nextclick)\n",
    "added_feature.extend(feature_time2previousclick)\n",
    "added_feature.extend(feature_countfromfuture)\n",
    "added_feature.extend(feature_countfrompast)\n",
    "added_feature.extend(feature_lasttimediff)\n",
    "added_feature.extend(feature_firsttimediff)\n",
    "added_feature.extend(feature_matrixfac)\n",
    "added_feature.extend(feature_var)\n",
    "added_feature.extend(feature_regression)\n",
    "feature_cols.extend(added_feature)\n",
    "feature_cols.extend(feature_ori)\n",
    "\n",
    "train_cols = feature_cols.copy()\n",
    "train_cols.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip_day_hour_count',\n",
       " 'ip_os_day_hour_count',\n",
       " 'ip_app_day_hour_count',\n",
       " 'ip_app_os_day_hour_count',\n",
       " 'app_day_hour_count',\n",
       " 'ip_device_os_count',\n",
       " 'ip_app_device_os_count',\n",
       " 'ip_device_os_mean',\n",
       " 'ip_app_device_os_mean',\n",
       " 'ip_app_device_mean',\n",
       " 'app_device_os_mean',\n",
       " 'ip_device_os_time2nextclick',\n",
       " 'ip_app_device_os_time2nextclick',\n",
       " 'ip_app_device_time2nextclick',\n",
       " 'ip_app_device_os_channel_time2nextclick',\n",
       " 'ip_device_os_time2previousclick',\n",
       " 'ip_app_device_os_time2previousclick',\n",
       " 'ip_app_device_time2previousclick',\n",
       " 'ip_app_device_os_channel_time2previousclick',\n",
       " 'ip_device_os_countfromfuture',\n",
       " 'ip_app_device_os_countfromfuture',\n",
       " 'ip_app_device_countfromfuture',\n",
       " 'ip_app_device_os_channel_countfromfuture',\n",
       " 'ip_device_os_countfrompast',\n",
       " 'ip_app_device_os_countfrompast',\n",
       " 'ip_app_device_countfrompast',\n",
       " 'ip_app_device_os_channel_countfrompast',\n",
       " 'ip_device_os_lasttimediff',\n",
       " 'ip_app_device_os_lasttimediff',\n",
       " 'ip_app_device_lasttimediff',\n",
       " 'ip_app_device_os_channel_lasttimediff',\n",
       " 'ip_device_os_firsttimediff',\n",
       " 'ip_app_device_os_firsttimediff',\n",
       " 'ip_app_device_firsttimediff',\n",
       " 'ip_app_device_os_channel_firsttimediff',\n",
       " 'matrixFact_user_iposdeviceapp_item_app',\n",
       " 'matrixFact_user_ip_item_appdeviceos',\n",
       " 'matrixFact_user_ipchannel_item_appdeviceos',\n",
       " 'ip_device_os_regression',\n",
       " 'ip_app_device_os_regression',\n",
       " 'ip_app_device_regression',\n",
       " 'ip_app_device_os_channel_regression',\n",
       " 'app',\n",
       " 'channel',\n",
       " 'device',\n",
       " 'os',\n",
       " 'hour']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "def countsort(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts().iloc[::-1]\n",
    "    count_map.iloc[:] = list(range(1, len(count_map) + 1))\n",
    "    \n",
    "    return group.map(count_map).fillna(-1)\n",
    "\n",
    "\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    group = get_group(df_train, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    return group.map(mean_map).fillna(-0.01)\n",
    "\n",
    "\n",
    "def reversemean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "    # encoding df's cols into a new series\n",
    "    group = get_group(df_train, cols)\n",
    "    # encoding df_history's cols into a new series\n",
    "    group_history = get_group(df_history, cols)\n",
    "    # get the conditional probability p(target| feature combination. eg, artist_name_composer) \n",
    "    positive = group_history[df_history[target] == 1]\n",
    "    negative = group_history[df_history[target] == 0]\n",
    "    index_p = set(positive.unique())\n",
    "    index_n = set(negative.unique())\n",
    "    index_n.difference_update(index_p)\n",
    "    map_reverse_p = positive.groupby(positive).count() / len(positive)\n",
    "    map_reverse_n = pd.Series(np.zeros(len(index_n)), index=index_n)\n",
    "    map_reverse = pd.concat([map_reverse_p, map_reverse_n])\n",
    "    return group.map(map_reverse).fillna(-1)\n",
    "\n",
    "\n",
    "def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse[timecol]):\n",
    "        if g in next_heard:\n",
    "            result.append(next_heard[g] - t)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    group = get_group(df_train, cols)\n",
    "\n",
    "    last_heard = {}\n",
    "    for t, g in zip(df_train[timecol], group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "# def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "#     # normalization\n",
    "#     group = get_group(df_train, cols)\n",
    "#     result = pd.Series(np.zeros(len(df_train)), index=df_train.index)\n",
    "#     grouping = df_train.groupby(group)\n",
    "#     for each_group in grouping:\n",
    "#         df_each = each_group[1]\n",
    "#         click = moving_diff(df_each[timecol], mode='next', norm=True)\n",
    "#         result.loc[click.index] = click.values\n",
    "#     return result\n",
    "\n",
    "\n",
    "\n",
    "# def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "#     # normalization\n",
    "#     group = get_group(df_train, cols)\n",
    "#     result = pd.Series(np.zeros(len(df_train)), index=df_train.index)\n",
    "#     grouping = df_train.groupby(group)\n",
    "#     for each_group in grouping:\n",
    "#         df_each = each_group[1]\n",
    "#         click = moving_diff(df_each[timecol], mode='previous', norm=True)\n",
    "#         result.loc[click.index] = click.values\n",
    "        \n",
    "    return result\n",
    "\n",
    "def moving_diff(ser, mode='next', norm=False):\n",
    "    tmp = ser.copy()\n",
    "    if mode == 'next':\n",
    "        tmp.iloc[:-1] = ser[1:].values\n",
    "        result = tmp - ser\n",
    "    elif mode == 'previous':\n",
    "        tmp.iloc[1:] = ser[:-1].values\n",
    "        result = ser - tmp\n",
    "    if norm:\n",
    "        ave = np.mean(result)\n",
    "#         std = np.std(result)\n",
    "#         if std != 0:\n",
    "#             result = (result - ave) / std\n",
    "        if ave != 0:\n",
    "            result = result / ave\n",
    "    return result\n",
    "\n",
    "def countfrompast(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfromfuture(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def lasttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    last_time = df_train.groupby(group)[timecol].last()\n",
    "    \n",
    "    return group.map(last_time) - df_train[timecol]\n",
    "\n",
    "def firsttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    first_time = df_train.groupby(group)[timecol].first()\n",
    "    \n",
    "    return  df_train[timecol] - group.map(first_time)\n",
    "\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "    \n",
    "    \n",
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_var(df_history, df, group_col, agg_col):\n",
    "    group = get_group(df, group_col)\n",
    "    group_history = get_group(df_history, group_col)\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp['group'] = group_history.values\n",
    "    df_temp['agg'] = df_history[agg_col].values\n",
    "    group_map =df_temp.groupby('group')['agg'].var()\n",
    "    result = group.map(group_map).fillna(0)\n",
    "    return result\n",
    "\n",
    "def matrix_factorization(df_history, df, target, item_col, userid_col, userraw_col):\n",
    "    \"\"\"\n",
    "    userid_col is unique user id\n",
    "    item_col is unique itme id\n",
    "    userraw_col is used to construct user feature. dim: user_id*userraw\n",
    "    \"\"\"\n",
    "    dff = pd.DataFrame()\n",
    "    dff_history = pd.DataFrame()\n",
    "\n",
    "\n",
    "    #1. process item\n",
    "    if item_col is None:\n",
    "        dff['item'] = np.zeros(len(df))\n",
    "        dff_history['item'] = np.zeros(len(df_history))\n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        group = get_group(df, item_col)\n",
    "        group_history = get_group(df_history, item_col)\n",
    "        encoder.fit(pd.concat([group, group_history]))\n",
    "        dff['item'] = encoder.transform(group)\n",
    "        dff_history['item'] = encoder.transform(group_history)\n",
    "#     print('processing item done!')\n",
    "\n",
    "    #2. user raw\n",
    "    group = get_group(df, userraw_col)\n",
    "    group_history = get_group(df_history, userraw_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['userraw'] = encoder.transform(group)\n",
    "    dff_history['userraw'] = encoder.transform(group_history)\n",
    "#     print('processing user raw done')\n",
    "\n",
    "\n",
    "    #3. user_id\n",
    "    group = get_group(df, userid_col)\n",
    "    group_history = get_group(df_history, userid_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['user_id'] = encoder.transform(group)\n",
    "    dff_history['user_id'] = encoder.transform(group_history)\n",
    "#     print('processing user id done')\n",
    "\n",
    "\n",
    "\n",
    "    num_users = max(dff.user_id.max(), dff_history.user_id.max()) + 1\n",
    "    num_items = max(dff.item.max(), dff_history.item.max()) + 1\n",
    "    num_userraw = max(dff.userraw.max(), dff_history.userraw.max()) + 1\n",
    "\n",
    "    M = coo_matrix(\n",
    "            (df_history[target], ( dff_history.user_id, dff_history.item)),\n",
    "            shape=(num_users, num_items)\n",
    "        )\n",
    "\n",
    "    user_features = pd.concat([dff, dff_history])[['userraw', 'user_id']].drop_duplicates()\n",
    "\n",
    "    user_features = coo_matrix(\n",
    "        (np.ones(len(user_features)), (user_features.user_id, user_features.userraw)),\n",
    "        shape=(num_users, num_userraw)\n",
    "    )\n",
    "\n",
    "    user_features = sp.hstack([sp.eye(num_users), user_features])\n",
    "\n",
    "    model = LightFM(no_components=50, learning_rate=0.1)\n",
    "    print('fitting lightFM')\n",
    "    model.fit(\n",
    "            M, \n",
    "            epochs=2, \n",
    "            num_threads=36, \n",
    "            user_features=user_features,\n",
    "        )\n",
    "    print('predicting lightFM')\n",
    "    result = model.predict(\n",
    "        dff.user_id.values, \n",
    "        dff.item.values, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def regression(df_history, df, cols, target= 'is_attributed', time_col='timestamp', shift=1500000000):\n",
    "    df = df.copy()\n",
    "    df_history = df_history.copy()\n",
    "    df.loc[:,time_col] = df.loc[:,time_col] - shift\n",
    "    df_history.loc[:,time_col] = df_history.loc[:,time_col] - shift\n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "\n",
    "    targets = {}\n",
    "    times = {}\n",
    "    for (y, t), u in zip(df_history[[target, time_col]].values, group_history):\n",
    "        if u not in targets:\n",
    "            targets[u] = [y]\n",
    "            times[u] = [t]\n",
    "        else:\n",
    "            targets[u].append(y)\n",
    "            times[u].append(t)\n",
    "\n",
    "    linal_user = {}\n",
    "    for u in times:\n",
    "        if len(times[u]) > 1:\n",
    "            A = np.vstack([times[u], np.ones(len(times[u]))]).T\n",
    "            linal_user[u] = np.linalg.inv(A.T.dot(A)).dot(A.T).dot(targets[u])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for t, u in zip(df[time_col], group):\n",
    "        if u not in times:\n",
    "            result.append(-0.5)\n",
    "        else:\n",
    "            if len(times[u]) < 2:\n",
    "                result.append(-0.5)\n",
    "            else:\n",
    "                result.append(linal_user[u].dot([t, 1]))\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 2.0376134142279625 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 2.183157227933407 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 2.328701041638851 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 2.4742448553442955 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 2.61978866904974 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 2.765332482755184 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 2.9108762964606285 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 3.056420110166073 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 3.201963923871517 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 3.3475077375769615 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 3.493051551282406 G.\n",
      "df_all does not exist\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 3.63859536498785 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 3.7841391786932945 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 3.929682992398739 G.\n",
      "time related function\n",
      "all 15:   ip_app_device_os_channel_time2nextclick   \t\t\t size: 4.075226806104183 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 16:   ip_app_device_time2previousclick   \t\t\t size: 4.2207706198096275 G.\n",
      "time related function\n",
      "all 17:   ip_device_os_time2previousclick   \t\t\t size: 4.366314433515072 G.\n",
      "time related function\n",
      "all 18:   ip_app_device_os_time2previousclick   \t\t\t size: 4.511858247220516 G.\n",
      "time related function\n",
      "all 19:   ip_app_device_os_channel_time2previousclick   \t\t\t size: 4.6574020609259605 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 20:   ip_app_device_countfromfuture   \t\t\t size: 4.802945874631405 G.\n",
      "time related function\n",
      "all 21:   ip_device_os_countfromfuture   \t\t\t size: 4.948489688336849 G.\n",
      "time related function\n",
      "all 22:   ip_app_device_os_countfromfuture   \t\t\t size: 5.0940335020422935 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_channel_countfromfuture   \t\t\t size: 5.239577315747738 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_countfrompast   \t\t\t size: 5.385121129453182 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_countfrompast   \t\t\t size: 5.530664943158627 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_countfrompast   \t\t\t size: 5.676208756864071 G.\n",
      "time related function\n",
      "all 27:   ip_app_device_os_channel_countfrompast   \t\t\t size: 5.821752570569515 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 28:   ip_app_device_lasttimediff   \t\t\t size: 5.96729638427496 G.\n",
      "time related function\n",
      "all 29:   ip_device_os_lasttimediff   \t\t\t size: 6.112840197980404 G.\n",
      "time related function\n",
      "all 30:   ip_app_device_os_lasttimediff   \t\t\t size: 6.258384011685848 G.\n",
      "time related function\n",
      "all 31:   ip_app_device_os_channel_lasttimediff   \t\t\t size: 6.403927825391293 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 32:   ip_app_device_firsttimediff   \t\t\t size: 6.549471639096737 G.\n",
      "time related function\n",
      "all 33:   ip_device_os_firsttimediff   \t\t\t size: 6.695015452802181 G.\n",
      "time related function\n",
      "all 34:   ip_app_device_os_firsttimediff   \t\t\t size: 6.840559266507626 G.\n",
      "time related function\n",
      "all 35:   ip_app_device_os_channel_firsttimediff   \t\t\t size: 6.98610308021307 G.\n",
      "df_all does not exist\n",
      "regression function\n",
      "all 36:   ip_app_device_regression   \t\t\t size: 7.131646893918514 G.\n",
      "regression function\n",
      "all 37:   ip_device_os_regression   \t\t\t size: 7.277190707623959 G.\n",
      "regression function\n",
      "all 38:   ip_app_device_os_regression   \t\t\t size: 7.422734521329403 G.\n",
      "regression function\n",
      "all 39:   ip_app_device_os_channel_regression   \t\t\t size: 7.568278335034847 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 42:   matrixFact_user_ipchannel_item_appdeviceos   \t\t\t size: 8.00490977615118 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_app_device_os_channel_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick'\n",
      " 'ip_app_device_os_channel_time2previousclick'\n",
      " 'ip_device_os_countfromfuture' 'ip_app_device_os_countfromfuture'\n",
      " 'ip_app_device_countfromfuture' 'ip_app_device_os_channel_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_app_device_os_channel_countfrompast'\n",
      " 'ip_device_os_lasttimediff' 'ip_app_device_os_lasttimediff'\n",
      " 'ip_app_device_lasttimediff' 'ip_app_device_os_channel_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'ip_app_device_os_channel_firsttimediff'\n",
      " 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos' 'ip_device_os_regression'\n",
      " 'ip_app_device_os_regression' 'ip_app_device_regression'\n",
      " 'ip_app_device_os_channel_regression' 'app' 'channel' 'device' 'os' 'hour'\n",
      " 'is_attributed']\n",
      "/home/kai/data/kaggle/talkingdata/wl/data/equalhour/day7_features_matrixregV5_firsttime.csv\n",
      "======================================================\n",
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 2.1327615156769753 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 2.2851016223430634 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 2.4374417290091515 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 2.5897818356752396 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 2.7421219423413277 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 2.8944620490074158 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 3.046802155673504 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 3.199142262339592 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 3.35148236900568 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 3.503822475671768 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 3.6561625823378563 G.\n",
      "df_all does not exist\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 3.8085026890039444 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 3.9608427956700325 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 4.113182902336121 G.\n",
      "time related function\n",
      "all 15:   ip_app_device_os_channel_time2nextclick   \t\t\t size: 4.265523009002209 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 16:   ip_app_device_time2previousclick   \t\t\t size: 4.417863115668297 G.\n",
      "time related function\n",
      "all 17:   ip_device_os_time2previousclick   \t\t\t size: 4.570203222334385 G.\n",
      "time related function\n",
      "all 18:   ip_app_device_os_time2previousclick   \t\t\t size: 4.722543329000473 G.\n",
      "time related function\n",
      "all 19:   ip_app_device_os_channel_time2previousclick   \t\t\t size: 4.874883435666561 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 20:   ip_app_device_countfromfuture   \t\t\t size: 5.027223542332649 G.\n",
      "time related function\n",
      "all 21:   ip_device_os_countfromfuture   \t\t\t size: 5.179563648998737 G.\n",
      "time related function\n",
      "all 22:   ip_app_device_os_countfromfuture   \t\t\t size: 5.331903755664825 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_channel_countfromfuture   \t\t\t size: 5.4842438623309135 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_countfrompast   \t\t\t size: 5.636583968997002 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_countfrompast   \t\t\t size: 5.78892407566309 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_countfrompast   \t\t\t size: 5.941264182329178 G.\n",
      "time related function\n",
      "all 27:   ip_app_device_os_channel_countfrompast   \t\t\t size: 6.093604288995266 G.\n",
      "df_all does not exist\n",
      "time related function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 28:   ip_app_device_lasttimediff   \t\t\t size: 6.245944395661354 G.\n",
      "time related function\n",
      "all 29:   ip_device_os_lasttimediff   \t\t\t size: 6.398284502327442 G.\n",
      "time related function\n",
      "all 30:   ip_app_device_os_lasttimediff   \t\t\t size: 6.55062460899353 G.\n",
      "time related function\n",
      "all 31:   ip_app_device_os_channel_lasttimediff   \t\t\t size: 6.702964715659618 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 32:   ip_app_device_firsttimediff   \t\t\t size: 6.8553048223257065 G.\n",
      "time related function\n",
      "all 33:   ip_device_os_firsttimediff   \t\t\t size: 7.007644928991795 G.\n",
      "time related function\n",
      "all 34:   ip_app_device_os_firsttimediff   \t\t\t size: 7.159985035657883 G.\n",
      "time related function\n",
      "all 35:   ip_app_device_os_channel_firsttimediff   \t\t\t size: 7.312325142323971 G.\n",
      "df_all does not exist\n",
      "regression function\n",
      "all 36:   ip_app_device_regression   \t\t\t size: 7.464665248990059 G.\n",
      "regression function\n",
      "all 37:   ip_device_os_regression   \t\t\t size: 7.617005355656147 G.\n",
      "regression function\n",
      "all 38:   ip_app_device_os_regression   \t\t\t size: 7.769345462322235 G.\n",
      "regression function\n",
      "all 39:   ip_app_device_os_channel_regression   \t\t\t size: 7.921685568988323 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 42:   matrixFact_user_ipchannel_item_appdeviceos   \t\t\t size: 8.378705888986588 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_app_device_os_channel_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick'\n",
      " 'ip_app_device_os_channel_time2previousclick'\n",
      " 'ip_device_os_countfromfuture' 'ip_app_device_os_countfromfuture'\n",
      " 'ip_app_device_countfromfuture' 'ip_app_device_os_channel_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_app_device_os_channel_countfrompast'\n",
      " 'ip_device_os_lasttimediff' 'ip_app_device_os_lasttimediff'\n",
      " 'ip_app_device_lasttimediff' 'ip_app_device_os_channel_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'ip_app_device_os_channel_firsttimediff'\n",
      " 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos' 'ip_device_os_regression'\n",
      " 'ip_app_device_os_regression' 'ip_app_device_regression'\n",
      " 'ip_app_device_os_channel_regression' 'app' 'channel' 'device' 'os' 'hour'\n",
      " 'is_attributed']\n",
      "/home/kai/data/kaggle/talkingdata/wl/data/equalhour/day8_features_matrixregV5_firsttime.csv\n",
      "======================================================\n",
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 2.1798753067851067 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 2.3355806842446327 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 2.491286061704159 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 2.646991439163685 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 2.802696816623211 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 2.958402194082737 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 3.114107571542263 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 3.269812949001789 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 3.425518326461315 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 3.581223703920841 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 3.7369290813803673 G.\n",
      "df_all does not exist\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 3.8926344588398933 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 4.048339836299419 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 4.2040452137589455 G.\n",
      "time related function\n",
      "all 15:   ip_app_device_os_channel_time2nextclick   \t\t\t size: 4.3597505912184715 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 16:   ip_app_device_time2previousclick   \t\t\t size: 4.515455968677998 G.\n",
      "time related function\n",
      "all 17:   ip_device_os_time2previousclick   \t\t\t size: 4.671161346137524 G.\n",
      "time related function\n",
      "all 18:   ip_app_device_os_time2previousclick   \t\t\t size: 4.82686672359705 G.\n",
      "time related function\n",
      "all 19:   ip_app_device_os_channel_time2previousclick   \t\t\t size: 4.982572101056576 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 20:   ip_app_device_countfromfuture   \t\t\t size: 5.138277478516102 G.\n",
      "time related function\n",
      "all 21:   ip_device_os_countfromfuture   \t\t\t size: 5.293982855975628 G.\n",
      "time related function\n",
      "all 22:   ip_app_device_os_countfromfuture   \t\t\t size: 5.449688233435154 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_channel_countfromfuture   \t\t\t size: 5.60539361089468 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_countfrompast   \t\t\t size: 5.761098988354206 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_countfrompast   \t\t\t size: 5.916804365813732 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_countfrompast   \t\t\t size: 6.072509743273258 G.\n",
      "time related function\n",
      "all 27:   ip_app_device_os_channel_countfrompast   \t\t\t size: 6.228215120732784 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 28:   ip_app_device_lasttimediff   \t\t\t size: 6.38392049819231 G.\n",
      "time related function\n",
      "all 29:   ip_device_os_lasttimediff   \t\t\t size: 6.539625875651836 G.\n",
      "time related function\n",
      "all 30:   ip_app_device_os_lasttimediff   \t\t\t size: 6.6953312531113625 G.\n",
      "time related function\n",
      "all 31:   ip_app_device_os_channel_lasttimediff   \t\t\t size: 6.8510366305708885 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 32:   ip_app_device_firsttimediff   \t\t\t size: 7.006742008030415 G.\n",
      "time related function\n",
      "all 33:   ip_device_os_firsttimediff   \t\t\t size: 7.162447385489941 G.\n",
      "time related function\n",
      "all 34:   ip_app_device_os_firsttimediff   \t\t\t size: 7.318152762949467 G.\n",
      "time related function\n",
      "all 35:   ip_app_device_os_channel_firsttimediff   \t\t\t size: 7.473858140408993 G.\n",
      "df_all does not exist\n",
      "regression function\n",
      "all 36:   ip_app_device_regression   \t\t\t size: 7.629563517868519 G.\n",
      "regression function\n",
      "all 37:   ip_device_os_regression   \t\t\t size: 7.785268895328045 G.\n",
      "regression function\n",
      "all 38:   ip_app_device_os_regression   \t\t\t size: 7.940974272787571 G.\n",
      "regression function\n",
      "all 39:   ip_app_device_os_channel_regression   \t\t\t size: 8.096679650247097 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 42:   matrixFact_user_ipchannel_item_appdeviceos   \t\t\t size: 8.563795782625675 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_app_device_os_channel_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick'\n",
      " 'ip_app_device_os_channel_time2previousclick'\n",
      " 'ip_device_os_countfromfuture' 'ip_app_device_os_countfromfuture'\n",
      " 'ip_app_device_countfromfuture' 'ip_app_device_os_channel_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_app_device_os_channel_countfrompast'\n",
      " 'ip_device_os_lasttimediff' 'ip_app_device_os_lasttimediff'\n",
      " 'ip_app_device_lasttimediff' 'ip_app_device_os_channel_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'ip_app_device_os_channel_firsttimediff'\n",
      " 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos' 'ip_device_os_regression'\n",
      " 'ip_app_device_os_regression' 'ip_app_device_regression'\n",
      " 'ip_app_device_os_channel_regression' 'app' 'channel' 'device' 'os' 'hour'\n",
      " 'is_attributed']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/kaggle/talkingdata/wl/data/equalhour/day9_features_matrixregV5_firsttime.csv\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for day in ['day7', 'day8', 'day9']:\n",
    "    counter = 0\n",
    "    df_train = train.iloc[index[day]].copy()\n",
    "    print('got train data')\n",
    "    history_index = list(set(train.index.values) - set(index[day]))\n",
    "    df_history = train.iloc[history_index].copy()\n",
    "    print('got historical data')\n",
    "    \n",
    "    ###########################################################################\n",
    "    for func in [count, mean, reversemean,time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff,regression]:\n",
    "                if func.__name__ == count.__name__:\n",
    "                    df_all = pd.concat([train, test])\n",
    "                else:\n",
    "                    try:\n",
    "                        del df_all\n",
    "                        gc.collect()\n",
    "                    except Exception:\n",
    "                        print('df_all does not exist')\n",
    "               \n",
    "                for num_col in [1,2,3,4,5]:\n",
    "                    for cols in combinations(combine_col, num_col):\n",
    "                        feature_name = col_name(cols, func=func)\n",
    "                        if feature_name not in added_feature:\n",
    "                               continue\n",
    "                        counter += 1\n",
    "                        if func.__name__ == count.__name__:\n",
    "                                print('count function')\n",
    "                                df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "\n",
    "                        elif func.__name__ == mean.__name__:\n",
    "                                print('mean function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                        elif func.__name__ == reversemean.__name__:\n",
    "                                print('reverse mean function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                                \n",
    "                        elif func.__name__ == regression.__name__:\n",
    "                                print('regression function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                        else:\n",
    "                                print('time related function')\n",
    "                                df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "               \n",
    "                        all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                        print(all_str)\n",
    "                        with open('feature_all.txt', 'w') as text_file:\n",
    "                            text_file.write(all_str + '\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "#     ### get val\n",
    "#     print('get val')\n",
    "#     df_all = pd.concat([train, test])\n",
    "#     df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "#     print('ip_app_os_var_hour done!')\n",
    "#     df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "#     print('ip_app_channel_var_day done!')\n",
    "#     del df_all\n",
    "#     gc.collect()\n",
    "    \n",
    "    \n",
    "    ### matrix - factorization\n",
    "    feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "    \n",
    "    feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "    feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "\n",
    "    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "    print(all_str)\n",
    "    with open('feature_all.txt', 'w') as text_file:\n",
    "        text_file.write(all_str + '\\n')\n",
    "               \n",
    "               \n",
    "    save_file_name = '{}_features_matrixregV5_firsttime.csv'.format(day)\n",
    "    save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "    df_train = df_train[train_cols]\n",
    "    print('------')\n",
    "    print(df_train.columns.values)\n",
    "    df_train.to_csv(save_file_path, index=False)\n",
    "    print(save_file_path)\n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 1.679998941719532 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 1.8199988454580307 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 1.9599987491965294 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 2.099998652935028 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 2.2399985566735268 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 2.3799984604120255 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 2.519998364150524 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 2.659998267889023 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 2.7999981716275215 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 2.93999807536602 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 3.079997979104519 G.\n",
      "df_all does not exist\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 3.2199978828430176 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 3.3599977865815163 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 3.499997690320015 G.\n",
      "time related function\n",
      "all 15:   ip_app_device_os_channel_time2nextclick   \t\t\t size: 3.6399975940585136 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 16:   ip_app_device_time2previousclick   \t\t\t size: 3.7799974977970123 G.\n",
      "time related function\n",
      "all 17:   ip_device_os_time2previousclick   \t\t\t size: 3.919997401535511 G.\n",
      "time related function\n",
      "all 18:   ip_app_device_os_time2previousclick   \t\t\t size: 4.05999730527401 G.\n",
      "time related function\n",
      "all 19:   ip_app_device_os_channel_time2previousclick   \t\t\t size: 4.199997209012508 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 20:   ip_app_device_countfromfuture   \t\t\t size: 4.339997112751007 G.\n",
      "time related function\n",
      "all 21:   ip_device_os_countfromfuture   \t\t\t size: 4.479997016489506 G.\n",
      "time related function\n",
      "all 22:   ip_app_device_os_countfromfuture   \t\t\t size: 4.6199969202280045 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_channel_countfromfuture   \t\t\t size: 4.759996823966503 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_countfrompast   \t\t\t size: 4.899996727705002 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_countfrompast   \t\t\t size: 5.0399966314435005 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_countfrompast   \t\t\t size: 5.179996535181999 G.\n",
      "time related function\n",
      "all 27:   ip_app_device_os_channel_countfrompast   \t\t\t size: 5.319996438920498 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 28:   ip_app_device_lasttimediff   \t\t\t size: 5.459996342658997 G.\n",
      "time related function\n",
      "all 29:   ip_device_os_lasttimediff   \t\t\t size: 5.599996246397495 G.\n",
      "time related function\n",
      "all 30:   ip_app_device_os_lasttimediff   \t\t\t size: 5.739996150135994 G.\n",
      "time related function\n",
      "all 31:   ip_app_device_os_channel_lasttimediff   \t\t\t size: 5.879996053874493 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 32:   ip_app_device_firsttimediff   \t\t\t size: 6.019995957612991 G.\n",
      "time related function\n",
      "all 33:   ip_device_os_firsttimediff   \t\t\t size: 6.15999586135149 G.\n",
      "time related function\n",
      "all 34:   ip_app_device_os_firsttimediff   \t\t\t size: 6.299995765089989 G.\n",
      "time related function\n",
      "all 35:   ip_app_device_os_channel_firsttimediff   \t\t\t size: 6.439995668828487 G.\n",
      "df_all does not exist\n",
      "regression function\n",
      "all 36:   ip_app_device_regression   \t\t\t size: 6.579995572566986 G.\n",
      "regression function\n",
      "all 37:   ip_device_os_regression   \t\t\t size: 6.719995476305485 G.\n",
      "regression function\n",
      "all 38:   ip_app_device_os_regression   \t\t\t size: 6.8599953800439835 G.\n",
      "regression function\n",
      "all 39:   ip_app_device_os_channel_regression   \t\t\t size: 6.999995283782482 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 42:   matrixFact_user_ipchannel_item_appdeviceos   \t\t\t size: 7.419994994997978 G.\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_app_device_os_channel_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick'\n",
      " 'ip_app_device_os_channel_time2previousclick'\n",
      " 'ip_device_os_countfromfuture' 'ip_app_device_os_countfromfuture'\n",
      " 'ip_app_device_countfromfuture' 'ip_app_device_os_channel_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_app_device_os_channel_countfrompast'\n",
      " 'ip_device_os_lasttimediff' 'ip_app_device_os_lasttimediff'\n",
      " 'ip_app_device_lasttimediff' 'ip_app_device_os_channel_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'ip_app_device_os_channel_firsttimediff'\n",
      " 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos' 'ip_device_os_regression'\n",
      " 'ip_app_device_os_regression' 'ip_app_device_regression'\n",
      " 'ip_app_device_os_channel_regression' 'app' 'channel' 'device' 'os' 'hour']\n",
      "/home/kai/data/kaggle/talkingdata/wl/data/equalhour/test_features_matrixregV5_firsttime.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "df_train = test.copy()\n",
    "print('got train data')\n",
    "history_index = list(set(train.index.values) - set(index[day]))\n",
    "df_history = train.copy()\n",
    "print('got historical data')\n",
    "\n",
    "###########################################################################\n",
    "for func in [count, mean,reversemean, time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff, regression]:\n",
    "# for func in [time2nextclick, time2previousclick]:\n",
    "             \n",
    "            if func.__name__ == count.__name__:\n",
    "                df_all = pd.concat([train, test])\n",
    "            else:\n",
    "                try:\n",
    "                    del df_all\n",
    "                    gc.collect()\n",
    "                except Exception:\n",
    "                    print('df_all does not exist')\n",
    "\n",
    "            for num_col in [1,2,3,4,5]:\n",
    "                for cols in combinations(combine_col, num_col):\n",
    "                    feature_name = col_name(cols, func=func)\n",
    "                    if feature_name not in added_feature:\n",
    "                           continue\n",
    "                    counter += 1\n",
    "                    if func.__name__ == count.__name__:\n",
    "                            print('count function')\n",
    "                            df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    elif func.__name__ == mean.__name__:\n",
    "                            print('mean function')\n",
    "                            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                    elif func.__name__ == reversemean.__name__:\n",
    "                            print('mean function')\n",
    "                            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "                    elif func.__name__ == regression.__name__:\n",
    "                                print('regression function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    else:\n",
    "                            print('time related function')\n",
    "                            df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                    print(all_str)\n",
    "                    with open('feature_all.txt', 'w') as text_file:\n",
    "                        text_file.write(all_str + '\\n')\n",
    "                        \n",
    "                        \n",
    "# ### get val\n",
    "# print('get val')\n",
    "# df_all = pd.concat([train, test])\n",
    "# df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "# print('ip_app_os_var_hour done!')\n",
    "# df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "# print('ip_app_channel_var_day done!')\n",
    "# del df_all\n",
    "# gc.collect()\n",
    "                        \n",
    "### matrix - factorization\n",
    "feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "\n",
    "all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "print(all_str)\n",
    "with open('feature_all.txt', 'w') as text_file:\n",
    "    text_file.write(all_str + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = '{}_features_matrixregV5_firsttime.csv'.format('test')\n",
    "save_file_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/' + save_file_name\n",
    "df_train = df_train[feature_cols]\n",
    "print(df_train.columns.values)\n",
    "df_train.to_csv(save_file_path, index=False)\n",
    "print(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
