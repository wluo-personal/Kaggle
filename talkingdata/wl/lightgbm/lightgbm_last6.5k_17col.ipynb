{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loading done! Time: 182.99911332130432\n",
      "size is: 12.107193566858768\n",
      "length is 65000000\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "df_train = pd.read_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_last6.5k.csv')\n",
    "df_test = pd.read_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_last6.5k.csv')\n",
    "t2 = time.time()\n",
    "print('training loading done! Time: {}'.format(t2 - t1))\n",
    "print('size is: {}'.format(sys.getsizeof(df_train) / 1024 ** 3))\n",
    "print('length is {}'.format(len(df_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical_col = ['app','os', 'channel', 'ip']\n",
    "categorical_col = ['app','os', 'channel']\n",
    "target = 'is_attributed'\n",
    "feature_cols = list(set(df_train.columns) - set([target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app',\n",
       " 'second',\n",
       " 'channel',\n",
       " 'os',\n",
       " 'device_minute_second_mean',\n",
       " 'app_os_hour_mean',\n",
       " 'hour_minute_second_mean',\n",
       " 'hour',\n",
       " 'ip_app_mean',\n",
       " 'ip_channel_count',\n",
       " 'ip_os_hour_count',\n",
       " 'device_minute_mean',\n",
       " 'minute',\n",
       " 'ip_mean',\n",
       " 'app_channel_hour_mean',\n",
       " 'ip_minute_count',\n",
       " 'ip_app_device_mean',\n",
       " 'day',\n",
       " 'app_os_channel_mean',\n",
       " 'ip',\n",
       " 'ip_channel_mean',\n",
       " 'timestamp',\n",
       " 'device',\n",
       " 'ip_second_mean']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.332333110272884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainset, valset = train_test_split(df_train,test_size=0.1, random_state=31)\n",
    "print(sys.getsizeof(trainset)/ 1024 **3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = trainset[target].values\n",
    "y_val = valset[target].values\n",
    "\n",
    "lgb_train = lgb.Dataset(trainset[feature_cols], y_train, categorical_feature = categorical_col)\n",
    "lgb_val = lgb.Dataset(valset[feature_cols], y_val, categorical_feature = categorical_col)\n",
    "\n",
    "zeros = len(y_train[y_train == 0])\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "import gc\n",
    "# del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's auc: 0.963692\tvalid_0's binary_logloss: 0.386506\n",
      "[20]\tvalid_0's auc: 0.966248\tvalid_0's binary_logloss: 0.242008\n",
      "[30]\tvalid_0's auc: 0.967445\tvalid_0's binary_logloss: 0.165128\n",
      "[40]\tvalid_0's auc: 0.968135\tvalid_0's binary_logloss: 0.121927\n",
      "[50]\tvalid_0's auc: 0.968654\tvalid_0's binary_logloss: 0.0969461\n",
      "[60]\tvalid_0's auc: 0.969147\tvalid_0's binary_logloss: 0.0823357\n",
      "[70]\tvalid_0's auc: 0.969762\tvalid_0's binary_logloss: 0.0736235\n",
      "[80]\tvalid_0's auc: 0.970306\tvalid_0's binary_logloss: 0.0683908\n",
      "[90]\tvalid_0's auc: 0.970704\tvalid_0's binary_logloss: 0.0652209\n",
      "[100]\tvalid_0's auc: 0.97108\tvalid_0's binary_logloss: 0.0632824\n",
      "[110]\tvalid_0's auc: 0.97147\tvalid_0's binary_logloss: 0.0619961\n",
      "[120]\tvalid_0's auc: 0.971776\tvalid_0's binary_logloss: 0.0612041\n",
      "[130]\tvalid_0's auc: 0.972014\tvalid_0's binary_logloss: 0.0606777\n",
      "[140]\tvalid_0's auc: 0.972162\tvalid_0's binary_logloss: 0.0603617\n",
      "[150]\tvalid_0's auc: 0.972262\tvalid_0's binary_logloss: 0.0601297\n",
      "[160]\tvalid_0's auc: 0.972372\tvalid_0's binary_logloss: 0.0599488\n",
      "[170]\tvalid_0's auc: 0.972428\tvalid_0's binary_logloss: 0.0598379\n",
      "[180]\tvalid_0's auc: 0.97251\tvalid_0's binary_logloss: 0.0597378\n",
      "[190]\tvalid_0's auc: 0.972567\tvalid_0's binary_logloss: 0.0596699\n",
      "[200]\tvalid_0's auc: 0.972596\tvalid_0's binary_logloss: 0.0595551\n",
      "[210]\tvalid_0's auc: 0.972617\tvalid_0's binary_logloss: 0.0594978\n",
      "[220]\tvalid_0's auc: 0.972652\tvalid_0's binary_logloss: 0.059422\n",
      "[230]\tvalid_0's auc: 0.972662\tvalid_0's binary_logloss: 0.0593579\n",
      "[240]\tvalid_0's auc: 0.972674\tvalid_0's binary_logloss: 0.0593242\n",
      "[250]\tvalid_0's auc: 0.972677\tvalid_0's binary_logloss: 0.059269\n",
      "[260]\tvalid_0's auc: 0.972713\tvalid_0's binary_logloss: 0.0592316\n",
      "[270]\tvalid_0's auc: 0.972714\tvalid_0's binary_logloss: 0.0591855\n",
      "[280]\tvalid_0's auc: 0.972725\tvalid_0's binary_logloss: 0.0591661\n",
      "[290]\tvalid_0's auc: 0.972748\tvalid_0's binary_logloss: 0.059084\n",
      "[300]\tvalid_0's auc: 0.972771\tvalid_0's binary_logloss: 0.0590637\n",
      "[310]\tvalid_0's auc: 0.972797\tvalid_0's binary_logloss: 0.0590222\n",
      "[320]\tvalid_0's auc: 0.972795\tvalid_0's binary_logloss: 0.0589786\n",
      "[330]\tvalid_0's auc: 0.972798\tvalid_0's binary_logloss: 0.0589479\n",
      "[340]\tvalid_0's auc: 0.972797\tvalid_0's binary_logloss: 0.0588982\n",
      "[350]\tvalid_0's auc: 0.972785\tvalid_0's binary_logloss: 0.0588929\n",
      "[360]\tvalid_0's auc: 0.972781\tvalid_0's binary_logloss: 0.0588603\n",
      "[370]\tvalid_0's auc: 0.972769\tvalid_0's binary_logloss: 0.0588304\n",
      "[380]\tvalid_0's auc: 0.972762\tvalid_0's binary_logloss: 0.0588032\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's auc: 0.972801\tvalid_0's binary_logloss: 0.0589102\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_rounds': 2000,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'num_threads': 16, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "        'device': 'cpu',\n",
    "        'max_depth': -1, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "        'min_data_in_leaf': 100,  #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.85, #For example, if set to 0.8, will select 80% features before training each tree.  speed up training / deal with over-fitting\n",
    "        'feature_fraction_seed': 1,\n",
    "        'early_stopping_round':50,\n",
    "        'bagging_fraction': 0.8, #Randomly select part of data without resampling\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration. to enable bagging, bagging_fraction should be set as well\n",
    "        'bagging_seed': 1,\n",
    "        #'max_bin': 255,\n",
    "        'verbose': 0,\n",
    "        'scale_pos_weight': 99,\n",
    "        'metric' : ['binary_logloss', 'auc']\n",
    "    }\n",
    "\n",
    "model = lgb.train(params, train_set=lgb_train, valid_sets=lgb_val, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97280073085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "pred_val = model.predict(valset[feature_cols])\n",
    "print(roc_auc_score(y_val,pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.Series(model.feature_importance(), index=feature_cols)\n",
    "importance = importance.sort_values(ascending=False)\n",
    "if len(model.feature_importance()) != len(feature_cols):\n",
    "    raise ValueError('Feature importance has length: {}, \\n while feature number is {}'.\n",
    "                     format(len(model.feature_importance()), len(feature_cols)))\n",
    "importance.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/output/importance_6500k_col17_scale99.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel                      2130\n",
       "os                           1237\n",
       "app                          1118\n",
       "timestamp                     624\n",
       "ip_minute_count               582\n",
       "app_os_channel_mean           551\n",
       "ip                            455\n",
       "ip_mean                       405\n",
       "app_os_hour_mean              326\n",
       "ip_channel_count              319\n",
       "app_channel_hour_mean         293\n",
       "ip_os_hour_count              251\n",
       "device_minute_second_mean     229\n",
       "device_minute_mean            229\n",
       "ip_app_device_mean            209\n",
       "hour_minute_second_mean       204\n",
       "ip_app_mean                   182\n",
       "second                        166\n",
       "hour                          159\n",
       "minute                        159\n",
       "ip_second_mean                136\n",
       "ip_channel_mean                67\n",
       "device                         49\n",
       "day                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "df_test_raw = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv')\n",
    "df_test = df_test[list(valset[feature_cols].columns)]\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['click_id'] = df_test_raw['click_id']\n",
    "df_sub['is_attributed'] = model.predict(df_test)\n",
    "df_sub.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/submission/train_all_6500k_col17_scale99.csv.gz', compression='gzip', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sub[df_sub['is_attributed'] > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997829750816757\n",
      "0.9797950226787846\n",
      "0.997596649573\n"
     ]
    }
   ],
   "source": [
    "a1 = 1 - 4078/len(df_sub)\n",
    "print(a1)\n",
    "\n",
    "a2 = 1 - 379661/len(df_sub)\n",
    "print(a2)\n",
    "\n",
    "a3 = 1- y_train.sum()/len(y_train)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
