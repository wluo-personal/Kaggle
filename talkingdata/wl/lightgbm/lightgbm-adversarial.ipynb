{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train done!\n",
      "loading test done!\n",
      "training loading done! Time: 203.82083177566528\n",
      "size is: 12.740492917597294\n",
      "length is 45000000\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "trainset = pd.read_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/train_countAndmean_index_all_shuffle_0405.csv')\n",
    "print('loading train done!')\n",
    "valset = pd.read_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/val_countAndmean_index_all_shuffle_0405.csv')\n",
    "print('loading test done!')\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "print('training loading done! Time: {}'.format(t2 - t1))\n",
    "print('size is: {}'.format(sys.getsizeof(trainset) / 1024 ** 3))\n",
    "print('length is {}'.format(len(trainset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = ['ip', 'app', 'device', 'os', 'channel', 'hour', 'minute', 'second']\n",
    "target = 'is_attributed'\n",
    "feature_cols = list(set(trainset.columns) - set([target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train negative rate: 99.72957555555556\n",
      "val negative rate: 99.73499\n"
     ]
    }
   ],
   "source": [
    "y_train = trainset[target].values\n",
    "y_val = valset[target].values\n",
    "\n",
    "lgb_train = lgb.Dataset(trainset[feature_cols], y_train, categorical_feature = categorical_col)\n",
    "lgb_val = lgb.Dataset(valset[feature_cols], y_val, categorical_feature = categorical_col)\n",
    "\n",
    "zeros = len(y_train[y_train == 0])\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train) * 100\n",
    "import gc\n",
    "# del df_train\n",
    "gc.collect()\n",
    "\n",
    "print('train negative rate: {}'.format(scale_pos_weight))\n",
    "print('val negative rate: {}'.format(len(y_val[y_val == 0]) / len(y_val) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\tvalid_0's auc: 0.969273\tvalid_0's binary_logloss: 0.23867\n",
      "[20]\tvalid_0's auc: 0.970535\tvalid_0's binary_logloss: 0.119948\n",
      "[30]\tvalid_0's auc: 0.973288\tvalid_0's binary_logloss: 0.0807544\n",
      "[40]\tvalid_0's auc: 0.974276\tvalid_0's binary_logloss: 0.0669475\n",
      "[50]\tvalid_0's auc: 0.974622\tvalid_0's binary_logloss: 0.0619284\n",
      "[60]\tvalid_0's auc: 0.975342\tvalid_0's binary_logloss: 0.0596413\n",
      "[70]\tvalid_0's auc: 0.975904\tvalid_0's binary_logloss: 0.058458\n",
      "[80]\tvalid_0's auc: 0.976171\tvalid_0's binary_logloss: 0.0577492\n",
      "[90]\tvalid_0's auc: 0.976406\tvalid_0's binary_logloss: 0.0573921\n",
      "[100]\tvalid_0's auc: 0.976679\tvalid_0's binary_logloss: 0.0569997\n",
      "[110]\tvalid_0's auc: 0.976793\tvalid_0's binary_logloss: 0.0567822\n",
      "[120]\tvalid_0's auc: 0.976835\tvalid_0's binary_logloss: 0.0565162\n",
      "[130]\tvalid_0's auc: 0.976941\tvalid_0's binary_logloss: 0.0563142\n",
      "[140]\tvalid_0's auc: 0.977001\tvalid_0's binary_logloss: 0.0561102\n",
      "[150]\tvalid_0's auc: 0.97712\tvalid_0's binary_logloss: 0.0559508\n",
      "[160]\tvalid_0's auc: 0.977184\tvalid_0's binary_logloss: 0.0557867\n",
      "[170]\tvalid_0's auc: 0.977218\tvalid_0's binary_logloss: 0.0556491\n",
      "[180]\tvalid_0's auc: 0.977254\tvalid_0's binary_logloss: 0.055506\n",
      "[190]\tvalid_0's auc: 0.977282\tvalid_0's binary_logloss: 0.0553695\n",
      "[200]\tvalid_0's auc: 0.977315\tvalid_0's binary_logloss: 0.0552412\n",
      "[210]\tvalid_0's auc: 0.977306\tvalid_0's binary_logloss: 0.0551343\n",
      "[220]\tvalid_0's auc: 0.977282\tvalid_0's binary_logloss: 0.0550392\n",
      "[230]\tvalid_0's auc: 0.977276\tvalid_0's binary_logloss: 0.0549515\n",
      "[240]\tvalid_0's auc: 0.97731\tvalid_0's binary_logloss: 0.0549182\n",
      "[250]\tvalid_0's auc: 0.977359\tvalid_0's binary_logloss: 0.0548199\n",
      "[260]\tvalid_0's auc: 0.977334\tvalid_0's binary_logloss: 0.0547358\n",
      "[270]\tvalid_0's auc: 0.977334\tvalid_0's binary_logloss: 0.0545838\n",
      "[280]\tvalid_0's auc: 0.977388\tvalid_0's binary_logloss: 0.0545623\n",
      "[290]\tvalid_0's auc: 0.977441\tvalid_0's binary_logloss: 0.0544336\n",
      "[300]\tvalid_0's auc: 0.977435\tvalid_0's binary_logloss: 0.0543362\n",
      "[310]\tvalid_0's auc: 0.977427\tvalid_0's binary_logloss: 0.0542719\n",
      "[320]\tvalid_0's auc: 0.97746\tvalid_0's binary_logloss: 0.054181\n",
      "[330]\tvalid_0's auc: 0.97745\tvalid_0's binary_logloss: 0.0541554\n",
      "[340]\tvalid_0's auc: 0.977415\tvalid_0's binary_logloss: 0.0541066\n",
      "[350]\tvalid_0's auc: 0.977425\tvalid_0's binary_logloss: 0.0540512\n",
      "[360]\tvalid_0's auc: 0.97739\tvalid_0's binary_logloss: 0.0539892\n",
      "[370]\tvalid_0's auc: 0.977369\tvalid_0's binary_logloss: 0.0539193\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's auc: 0.977462\tvalid_0's binary_logloss: 0.0541571\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_rounds': 2000,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 11,\n",
    "        'num_threads': 4, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "        'device': 'cpu',\n",
    "        'max_depth': 5, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "        'min_data_in_leaf': 200,  #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.6, #For example, if set to 0.8, will select 80% features before training each tree.  speed up training / deal with over-fitting\n",
    "        'feature_fraction_seed': 1,\n",
    "        'early_stopping_round':50,\n",
    "        'bagging_fraction': 0.9, #Randomly select part of data without resampling\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration. to enable bagging, bagging_fraction should be set as well\n",
    "        'bagging_seed': 1,\n",
    "        #'max_bin': 255,\n",
    "        'verbose': 0,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'metric' : ['binary_logloss', 'auc']\n",
    "    }\n",
    "\n",
    "model = lgb.train(params, train_set=lgb_train, valid_sets=lgb_val, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97746189202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "pred_val = model.predict(valset[feature_cols])\n",
    "print(roc_auc_score(y_val,pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.Series(model.feature_importance(), index=feature_cols)\n",
    "importance = importance.sort_values(ascending=False)\n",
    "if len(model.feature_importance()) != len(feature_cols):\n",
    "    raise ValueError('Feature importance has length: {}, \\n while feature number is {}'.\n",
    "                     format(len(model.feature_importance()), len(feature_cols)))\n",
    "importance.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/output/importance__countAndmean75m_0405_index_all_shuffle_11leaf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip                           904\n",
       "channel                      385\n",
       "minute                       255\n",
       "second                       234\n",
       "app_os_channel_mean          212\n",
       "app                          175\n",
       "os                           117\n",
       "app_device_os_mean           108\n",
       "ip_mean                       96\n",
       "ip_app_os_count               82\n",
       "ip_count                      74\n",
       "ip_device_count               73\n",
       "ip_device_hour_count          46\n",
       "ip_day_count                  45\n",
       "hour                          40\n",
       "ip_app_mean                   39\n",
       "app_channel_hour_mean         37\n",
       "ip_app_device_mean            37\n",
       "device_os_hour_mean           31\n",
       "ip_os_hour_count              30\n",
       "ip_second_count               25\n",
       "ip_app_count                  25\n",
       "app_os_hour_mean              24\n",
       "ip_app_hour_count             24\n",
       "ip_minute_count               22\n",
       "app_channel_day_count         18\n",
       "app_channel_count             18\n",
       "device                        13\n",
       "ip_hour_count                 13\n",
       "device_minute_mean            11\n",
       "ip_day_hour_count             10\n",
       "ip_channel_count              10\n",
       "device_minute_second_mean      9\n",
       "ip_second_mean                 6\n",
       "ip_app_channel_mean            5\n",
       "ip_channel_mean                5\n",
       "hour_minute_second_mean        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test done!\n",
      "predicting done!\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('/home/kai/data/kaggle/talkingdata/wl/data/features/test_countAndmean_index_all_shuffle_0405.csv')\n",
    "print('loading test done!')\n",
    "# prediction\n",
    "df_test_raw = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv')\n",
    "df_test = df_test[list(valset[feature_cols].columns)]\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['click_id'] = df_test_raw['click_id']\n",
    "df_sub['is_attributed'] = model.predict(df_test)\n",
    "print('predicting done!')\n",
    "df_sub.to_csv('/home/kai/data/kaggle/talkingdata/wl/data/submission/train_countAndmean_0405_index_all_shuffle_11leaf.csv.gz', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_day_hour_count</th>\n",
       "      <th>ip</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>143414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>173096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>8210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>5746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>31475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>251465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>164</td>\n",
       "      <td>163593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>158</td>\n",
       "      <td>58288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>134</td>\n",
       "      <td>27038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>414</td>\n",
       "      <td>67682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>134</td>\n",
       "      <td>17130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>158</td>\n",
       "      <td>100339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1214</td>\n",
       "      <td>36213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>247140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2291</td>\n",
       "      <td>45745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>842</td>\n",
       "      <td>59395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>131535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14389</td>\n",
       "      <td>5348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>42</td>\n",
       "      <td>177386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>282374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>232874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ip_day_hour_count      ip  day  hour\n",
       "0                  43  143414  NaN    12\n",
       "1                  18  173096  NaN    12\n",
       "2                  42    8210  NaN    12\n",
       "3                  19    5746  NaN    12\n",
       "4                  65   31475  NaN    12\n",
       "5                  11  251465  NaN    12\n",
       "6                 164  163593  NaN    12\n",
       "7                 158   58288  NaN    12\n",
       "8                 134   27038  NaN    12\n",
       "9                 414   67682  NaN    12\n",
       "10                134   17130  NaN    12\n",
       "11                158  100339  NaN    12\n",
       "12               1214   36213  NaN    12\n",
       "13                  3  247140  NaN    12\n",
       "14               2291   45745  NaN    12\n",
       "15                842   59395  NaN    12\n",
       "16                 24  131535  NaN    12\n",
       "17              14389    5348  NaN    12\n",
       "18                 42  177386  NaN    12\n",
       "19                 19  282374  NaN    12\n",
       "20                 50  232874  NaN    12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['ip_day_hour_count', 'ip', 'day', 'hour']\n",
    "df_train.loc[:20,a ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
