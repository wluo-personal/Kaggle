{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "leng = 10000\n",
    "df['f1'] = np.concatenate([np.random.normal(0.2, 0.5, leng), np.random.normal(1, 0.5, leng)])\n",
    "df['f2'] = np.concatenate([np.random.normal(0.2, 0.5, leng), np.random.normal(1, 0.5, leng)])\n",
    "df['f3'] = np.concatenate([np.random.normal(0.2, 0.5, leng), np.random.normal(1, 0.5, leng)])\n",
    "df['f4'] = np.concatenate([np.random.normal(0.2, 0.5, leng), np.random.normal(1, 0.5, leng)])\n",
    "df['label'] = np.concatenate([ np.zeros(leng), np.ones(leng),])\n",
    "\n",
    "dff = df.sample(len(df))\n",
    "ratio =0.8\n",
    "length = int(len(dff) * ratio)\n",
    "trainset = dff.iloc[length:]\n",
    "valset = dff.iloc[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainset['label'].values\n",
    "y_val = valset['label'].values\n",
    "\n",
    "lgb_train = lgb.Dataset(trainset[['f1', 'f2', 'f3', 'f4']], y_train)\n",
    "lgb_val = lgb.Dataset(valset[['f1', 'f2', 'f3', 'f4']], y_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's auc: 0.918942\n",
      "[20]\tvalid_0's auc: 0.926289\n",
      "[30]\tvalid_0's auc: 0.933644\n",
      "[40]\tvalid_0's auc: 0.957821\n",
      "[50]\tvalid_0's auc: 0.962787\n",
      "[60]\tvalid_0's auc: 0.969829\n",
      "[70]\tvalid_0's auc: 0.977126\n",
      "[80]\tvalid_0's auc: 0.980102\n",
      "[90]\tvalid_0's auc: 0.98179\n",
      "[100]\tvalid_0's auc: 0.983122\n",
      "[110]\tvalid_0's auc: 0.984093\n",
      "[120]\tvalid_0's auc: 0.984388\n",
      "[130]\tvalid_0's auc: 0.984927\n",
      "[140]\tvalid_0's auc: 0.984974\n",
      "[150]\tvalid_0's auc: 0.98509\n",
      "[160]\tvalid_0's auc: 0.985229\n",
      "[170]\tvalid_0's auc: 0.985209\n",
      "[180]\tvalid_0's auc: 0.9854\n",
      "[190]\tvalid_0's auc: 0.985542\n",
      "[200]\tvalid_0's auc: 0.985512\n",
      "[210]\tvalid_0's auc: 0.985507\n",
      "[220]\tvalid_0's auc: 0.985599\n",
      "[230]\tvalid_0's auc: 0.985628\n",
      "[240]\tvalid_0's auc: 0.985578\n",
      "[250]\tvalid_0's auc: 0.98564\n",
      "[260]\tvalid_0's auc: 0.985662\n",
      "[270]\tvalid_0's auc: 0.985556\n",
      "[280]\tvalid_0's auc: 0.985645\n",
      "[290]\tvalid_0's auc: 0.98557\n",
      "[300]\tvalid_0's auc: 0.985544\n",
      "[310]\tvalid_0's auc: 0.985541\n",
      "[320]\tvalid_0's auc: 0.985593\n",
      "[330]\tvalid_0's auc: 0.985464\n",
      "[340]\tvalid_0's auc: 0.985417\n",
      "[350]\tvalid_0's auc: 0.985496\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's auc: 0.98569\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_rounds': 2000,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 3,\n",
    "        'num_threads': 6, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "        'device': 'cpu',\n",
    "        'max_depth': -1, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "        'min_data_in_leaf': 390,  #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.7, #For example, if set to 0.8, will select 80% features before training each tree.  speed up training / deal with over-fitting\n",
    "        'feature_fraction_seed': 1,\n",
    "        'early_stopping_round':100,\n",
    "        'bagging_fraction': 0.7, #Randomly select part of data without resampling\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration. to enable bagging, bagging_fraction should be set as well\n",
    "        'bagging_seed': 1,\n",
    "        #'max_bin': 255,\n",
    "        'verbose': 0,\n",
    "        'scale_pos_weight': 400,\n",
    "        'metric' : [ 'auc']\n",
    "    }\n",
    "\n",
    "model = lgb.train(params, train_set=lgb_train, valid_sets=lgb_val, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
