{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint64',\n",
    "        'app'           : 'uint64',\n",
    "        'device'        : 'uint64',\n",
    "        'os'            : 'uint64',\n",
    "        'channel'       : 'uint64',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv',dtype=dtypes)\n",
    "print('train done!')\n",
    "# test = pd.read_csv(path + 'test.csv',dtype=dtypes)\n",
    "# print('test done!')\n",
    "# test_supplement = pd.read_csv(path + 'test_supplement.csv',dtype=dtypes)\n",
    "# print('supplement done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get clicks\n",
      "timestamping is done\n",
      "get clicks\n",
      "timestamping is done\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "workers = 20\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "def get_timestamp(x):\n",
    "    return x.timestamp()\n",
    "\n",
    "for df in [test_supplement,test]:\n",
    "    clicks = pd.to_datetime(df.click_time)\n",
    "    print('get clicks')\n",
    "    df['timestamp'] = apply_by_multiprocessing(clicks, get_timestamp, workers=workers)\n",
    "    #     df['timestamp'] = clicks.apply(lambda t: t.timestamp())\n",
    "    df['timestamp'] = df['timestamp'].astype('uint64')\n",
    "    print('timestamping is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'timestamp']\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(test_supplement[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        print(col)\n",
    "        group = group * orders[col] + df[col]\n",
    "        print(group.iloc[0])\n",
    "        \n",
    "    return group\n",
    "\n",
    "def get_group_new(df, cols):\n",
    "    group = df[cols[0]].copy().apply(str)\n",
    "    for col in cols[1:]:\n",
    "        group = group + df[col].apply(str)      \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 1000,\n",
       " 'channel': 1000,\n",
       " 'device': 10000,\n",
       " 'ip': 1000000,\n",
       " 'os': 1000,\n",
       " 'timestamp': 10000000000}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_group = get_group_new(test,['ip', 'app', 'device', 'channel','os','timestamp'])\n",
    "test_supplement_group = get_group_new(test_supplement,['ip', 'app', 'device', 'channel','os','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['encoding'] = test_group\n",
    "test_supplement['encoding'] = test_supplement_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts1 = 0\n",
    "ts2 = 6202933  \n",
    "ts3 = 12316147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start1 = 21290878\n",
    "start2 = 35678696\n",
    "start3 = 48109937\n",
    "end1 = 27493808\n",
    "end2 = 41791909\n",
    "end3 = 54584258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6202933\n",
      "6202933\n"
     ]
    }
   ],
   "source": [
    "# part1 = test.merge(test_supplement.iloc[start1-2: end1+2], on=['ip', 'app', 'device', 'channel','os', 'click_time'], how='inner')\n",
    "part1 = test.merge(test_supplement.iloc[start1-2: end1+2], on=['encoding'], how='inner')\n",
    "\n",
    "\n",
    "print(len(part1.click_id_x.value_counts()))\n",
    "print(len(part1.click_id_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouping = part1.groupby('encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n",
      "2440000\n",
      "2450000\n",
      "2460000\n",
      "2470000\n",
      "2480000\n",
      "2490000\n",
      "2500000\n",
      "2510000\n",
      "2520000\n",
      "2530000\n",
      "2540000\n",
      "2550000\n",
      "2560000\n",
      "2570000\n",
      "2580000\n",
      "2590000\n",
      "2600000\n",
      "2610000\n",
      "2620000\n",
      "2630000\n",
      "2640000\n",
      "2650000\n",
      "2660000\n",
      "2670000\n",
      "2680000\n",
      "2690000\n",
      "2700000\n",
      "2710000\n",
      "2720000\n",
      "2730000\n",
      "2740000\n",
      "2750000\n",
      "2760000\n",
      "2770000\n",
      "2780000\n",
      "2790000\n",
      "2800000\n",
      "2810000\n",
      "2820000\n",
      "2830000\n",
      "2840000\n",
      "2850000\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "count = 0\n",
    "for group in grouping:\n",
    "    x.extend(sorted(list(set(group[1].click_id_x.values))))\n",
    "    y.extend(sorted(list(set(group[1].click_id_y.values))))\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6113214\n",
      "6113214\n"
     ]
    }
   ],
   "source": [
    "part2 = test.merge(test_supplement.iloc[start2-2: end2+2], on=['encoding'], how='inner')\n",
    "\n",
    "print(len(part2.click_id_x.value_counts()))\n",
    "print(len(part2.click_id_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouping = part2.groupby('encoding')\n",
    "count = 0\n",
    "for group in grouping:\n",
    "    x.extend(sorted(list(set(group[1].click_id_x.values))))\n",
    "    y.extend(sorted(list(set(group[1].click_id_y.values))))\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6474322\n",
      "6474322\n"
     ]
    }
   ],
   "source": [
    "part3 = test.merge(test_supplement.iloc[start3-2: end3+2], on=['encoding'], how='inner')\n",
    "\n",
    "print(len(part3.click_id_x.value_counts()))\n",
    "print(len(part3.click_id_y.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouping = part3.groupby('encoding')\n",
    "count = 0\n",
    "for group in grouping:\n",
    "    x.extend(sorted(list(set(group[1].click_id_x.values))))\n",
    "    y.extend(sorted(list(set(group[1].click_id_y.values))))\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length is 184903890\n",
      "testing length is 18790469\n",
      "test_supplement length is 57537505\n",
      "ip                         0\n",
      "app                        0\n",
      "device                     0\n",
      "os                         0\n",
      "channel                    0\n",
      "click_time                 0\n",
      "attributed_time    184447044\n",
      "is_attributed              0\n",
      "dtype: int64\n",
      "-------------------\n",
      "click_id      0\n",
      "ip            0\n",
      "app           0\n",
      "device        0\n",
      "os            0\n",
      "channel       0\n",
      "click_time    0\n",
      "dtype: int64\n",
      "-------------------\n",
      "click_id      0\n",
      "ip            0\n",
      "app           0\n",
      "device        0\n",
      "os            0\n",
      "channel       0\n",
      "click_time    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('training length is {}'.format(len(train)))\n",
    "print('testing length is {}'.format(len(test)))\n",
    "print('test_supplement length is {}'.format(len(test_supplement)))\n",
    "\n",
    "n_train = pd.isnull(train).sum()\n",
    "n_test = pd.isnull(test).sum()\n",
    "n_test_supplement = pd.isnull(test_supplement).sum()\n",
    "\n",
    "print(n_train)\n",
    "print('-------------------')\n",
    "print(n_test)\n",
    "print('-------------------')\n",
    "print(n_test_supplement)\n",
    "\n",
    "### there is no N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get clicks\n",
      "timestamping is done\n",
      "year is done\n",
      "month is done\n",
      "week is done\n",
      "day is done\n",
      "hour is done\n",
      "minute is done\n",
      "second is done\n",
      "================================================================\n",
      "get clicks\n",
      "timestamping is done\n",
      "year is done\n",
      "month is done\n",
      "week is done\n",
      "day is done\n",
      "hour is done\n",
      "minute is done\n",
      "second is done\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "# get timestamp\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "def get_timestamp(x):\n",
    "    return x.timestamp()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "workers = 30\n",
    "\n",
    "for df in [train, test]:\n",
    "    clicks = pd.to_datetime(df.click_time)\n",
    "    print('get clicks')\n",
    "    df['timestamp'] = apply_by_multiprocessing(clicks, get_timestamp, workers=workers)\n",
    "#     df['timestamp'] = clicks.apply(lambda t: t.timestamp())\n",
    "    df['timestamp'] = df['timestamp'].astype('uint32')\n",
    "    print('timestamping is done')\n",
    "    \n",
    "    dt = clicks.dt\n",
    "\n",
    "    df['year'] = dt.year.astype('uint16')\n",
    "    print('year is done')\n",
    "    \n",
    "    df['month'] = dt.month.astype('uint8')\n",
    "    print('month is done')\n",
    "        \n",
    "    df['week'] = dt.week.astype('uint8')\n",
    "    print('week is done')\n",
    "    \n",
    "    df['day'] = dt.day.astype('uint8')\n",
    "    print('day is done')\n",
    "    \n",
    "    df['hour'] = dt.hour.astype('uint8')\n",
    "    print('hour is done')\n",
    "    \n",
    "    df['minute'] = dt.minute.astype('uint8')\n",
    "    print('minute is done')\n",
    "    \n",
    "    df['second'] = dt.second.astype('uint8')\n",
    "    print('second is done')\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "training done\n",
      "testing done\n"
     ]
    }
   ],
   "source": [
    "target = 'is_attributed'\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'year', \n",
    "              'month',\n",
    "              'week',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'timestamp',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "final_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',\n",
    "              'timestamp',\n",
    "              'minute',\n",
    "              'second']\n",
    "\n",
    "train_cols =  feature_col.copy()\n",
    "train_cols_final =  final_col.copy()\n",
    "train_cols.append(target)\n",
    "train_cols_final.append(target)\n",
    "\n",
    "df_train = train[train_cols]\n",
    "df_test = test[feature_col]\n",
    "df_train_final = train[train_cols_final]\n",
    "df_test_final = test[final_col]\n",
    "\n",
    "print('saving')\n",
    "df_train.to_csv(path+'train_cleaned.csv', index=False)\n",
    "df_train_final.to_csv(path+'train_cleaned_final.csv', index=False)\n",
    "print('training done')\n",
    "df_test.to_csv(path+'test_cleaned.csv', index=False)\n",
    "df_test_final.to_csv(path+'test_cleaned_final.csv', index=False)\n",
    "print('testing done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get clicks\n",
      "timestamping is done\n",
      "year is done\n",
      "month is done\n",
      "week is done\n",
      "day is done\n",
      "hour is done\n",
      "minute is done\n",
      "second is done\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(path + 'train_sample.csv',dtype=dtypes)\n",
    "\n",
    "for df in [train_sample]:\n",
    "    clicks = pd.to_datetime(df.click_time)\n",
    "    print('get clicks')\n",
    "    df['timestamp'] = apply_by_multiprocessing(clicks, get_timestamp, workers=workers)\n",
    "#     df['timestamp'] = clicks.apply(lambda t: t.timestamp())\n",
    "    df['timestamp'] = df['timestamp'].astype('uint32')\n",
    "    print('timestamping is done')\n",
    "    \n",
    "    dt = clicks.dt\n",
    "\n",
    "    df['year'] = dt.year.astype('uint16')\n",
    "    print('year is done')\n",
    "    \n",
    "    df['month'] = dt.month.astype('uint8')\n",
    "    print('month is done')\n",
    "        \n",
    "    df['week'] = dt.week.astype('uint8')\n",
    "    print('week is done')\n",
    "    \n",
    "    df['day'] = dt.day.astype('uint8')\n",
    "    print('day is done')\n",
    "    \n",
    "    df['hour'] = dt.hour.astype('uint8')\n",
    "    print('hour is done')\n",
    "    \n",
    "    df['minute'] = dt.minute.astype('uint8')\n",
    "    print('minute is done')\n",
    "    \n",
    "    df['second'] = dt.second.astype('uint8')\n",
    "    print('second is done')\n",
    "    print('================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_sample = train_sample[train_cols]\n",
    "df_train_sample.to_csv(path+'train_sample_cleaned.csv', index=False)\n",
    "df_train_sample_final = df_train_sample[train_cols_final].copy()\n",
    "df_train_sample_final.to_csv(path+'train_sample_cleaned_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
