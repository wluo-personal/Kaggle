{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Flatten\n",
    "from keras.layers.merge import concatenate, dot, add, multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nn_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data loaded.\n",
      "Member/Song data loaded.\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## Data Loading\n",
    "######################################################\n",
    "\n",
    "folder = 'training'\n",
    "\n",
    "## load train data\n",
    "if folder == 'training':\n",
    "    train = pd.read_csv('./input/%s/train_part.csv'%folder)\n",
    "    train_add = pd.read_csv('./input/%s/train_part_add.csv'%folder)\n",
    "elif folder == 'validation':\n",
    "    train = pd.read_csv('./input/%s/train.csv'%folder)\n",
    "    train_add = pd.read_csv('./input/%s/train_add.csv'%folder)\n",
    "train_y = train['target']\n",
    "train.drop(['target'], inplace=True, axis=1)\n",
    "\n",
    "test = pd.read_csv('./input/%s/test.csv'%folder)\n",
    "test_add = pd.read_csv('./input/%s/test_add.csv'%folder)\n",
    "test_id = test['id']\n",
    "test.drop(['id'], inplace=True, axis=1)\n",
    "\n",
    "for col in train_add.columns:\n",
    "    train[col] = train_add[col].values\n",
    "    test[col] = test_add[col].values\n",
    "\n",
    "print('Train data loaded.')\n",
    "\n",
    "## load other data\n",
    "member = pd.read_csv('./input/%s/members_nn.csv'%folder).sort_values('msno')\n",
    "song = pd.read_csv('./input/%s/songs_nn.csv'%folder).sort_values('song_id')\n",
    "\n",
    "member_add = pd.read_csv('./input/%s/members_add.csv'%folder).sort_values('msno')\n",
    "member_add.fillna(0, inplace=True)\n",
    "member = member.merge(member_add, on='msno', how='left')\n",
    "\n",
    "print('Member/Song data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(member.columns))\n",
    "print(len(song.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation done.\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## Feature Preparation\n",
    "######################################################\n",
    "\n",
    "## data preparation\n",
    "train = train.merge(member[['msno', 'city', 'gender', 'registered_via', \\\n",
    "        'registration_init_time', 'expiration_date']], on='msno', how='left')\n",
    "test = test.merge(member[['msno', 'city', 'gender', 'registered_via', \\\n",
    "        'registration_init_time', 'expiration_date']], on='msno', how='left')\n",
    "\n",
    "train = train.merge(song[['song_id', 'artist_name', 'composer', 'lyricist', \\\n",
    "        'language', 'first_genre_id', 'second_genre_id', 'third_genre_id', \\\n",
    "        'cc', 'xxx']], on='song_id', how='left')\n",
    "test = test.merge(song[['song_id', 'artist_name', 'composer', 'lyricist', \\\n",
    "        'language', 'first_genre_id', 'second_genre_id', 'third_genre_id', \\\n",
    "        'cc', 'xxx']], on='song_id', how='left')\n",
    "\n",
    "cols = ['song_id', 'artist_name', 'language', 'first_genre_id', 'song_rec_cnt']\n",
    "tmp = song[cols]\n",
    "\n",
    "tmp.columns = ['before_'+i for i in cols]\n",
    "train = train.merge(tmp, on='before_song_id', how='left')\n",
    "test = test.merge(tmp, on='before_song_id', how='left')\n",
    "\n",
    "tmp.columns = ['after_'+i for i in cols]\n",
    "train = train.merge(tmp, on='after_song_id', how='left')\n",
    "test = test.merge(tmp, on='after_song_id', how='left')\n",
    "\n",
    "train['before_type_same'] = (train['source_type'] == train['before_source_type']).astype(int)\n",
    "test['before_type_same'] = (test['source_type'] == test['before_source_type']).astype(int)\n",
    "\n",
    "train['after_type_same'] = (train['source_type'] == train['after_source_type']).astype(int)\n",
    "test['after_type_same'] = (test['source_type'] == test['after_source_type']).astype(int)\n",
    "\n",
    "train['before_artist_same'] = (train['artist_name'] == train['before_artist_name']).astype(int)\n",
    "test['before_artist_same'] = (test['artist_name'] == test['before_artist_name']).astype(int)\n",
    "\n",
    "train['after_artist_same'] = (train['artist_name'] == train['after_artist_name']).astype(int)\n",
    "test['after_artist_same'] = (test['artist_name'] == test['after_artist_name']).astype(int)\n",
    "\n",
    "train['before_genre_same'] = (train['first_genre_id'] == train['before_first_genre_id']).astype(int)\n",
    "test['before_genre_same'] = (test['first_genre_id'] == test['before_first_genre_id']).astype(int)\n",
    "\n",
    "train['after_genre_same'] = (train['first_genre_id'] == train['after_first_genre_id']).astype(int)\n",
    "test['after_genre_same'] = (test['first_genre_id'] == test['after_first_genre_id']).astype(int)\n",
    "\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "print('Data preparation done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## generate data for training\n",
    "embedding_features = ['msno', 'city', 'gender', 'registered_via', \\\n",
    "        'artist_name', 'language', 'cc', \\\n",
    "        'source_type', 'source_screen_name', 'source_system_tab', \\\n",
    "        'before_source_type', 'after_source_type', 'before_source_screen_name', \\\n",
    "        'after_source_screen_name', 'before_language', 'after_language', \\\n",
    "        'song_id', 'before_song_id', 'after_song_id']\n",
    "\n",
    "train_embeddings = []\n",
    "test_embeddings = []\n",
    "for feat in embedding_features:\n",
    "    train_embeddings.append(train[feat].values)\n",
    "    test_embeddings.append(test[feat].values)\n",
    "\n",
    "genre_features = ['first_genre_id', 'second_genre_id']\n",
    "\n",
    "train_genre = []\n",
    "test_genre = []\n",
    "for feat in genre_features:\n",
    "    train_genre.append(train[feat].values)\n",
    "    test_genre.append(test[feat].values)\n",
    "\n",
    "context_features = ['after_artist_same', 'after_song_rec_cnt', 'after_timestamp', \\\n",
    "        'after_type_same', 'before_artist_same', 'before_song_rec_cnt', \\\n",
    "        'before_timestamp', 'before_type_same', 'msno_10000_after_cnt', \\\n",
    "        'msno_10000_before_cnt', 'msno_10_after_cnt', 'msno_10_before_cnt', \\\n",
    "        'msno_25_after_cnt', 'msno_25_before_cnt', 'msno_50000_after_cnt', \\\n",
    "        'msno_50000_before_cnt', 'msno_5000_after_cnt', 'msno_5000_before_cnt', \\\n",
    "        'msno_500_after_cnt', 'msno_500_before_cnt', 'msno_source_screen_name_prob', \\\n",
    "        'msno_source_system_tab_prob', 'msno_source_type_prob', 'msno_till_now_cnt', \\\n",
    "        'registration_init_time', 'song_50000_after_cnt', 'song_50000_before_cnt', \\\n",
    "        'song_till_now_cnt', 'timestamp', 'msno_artist_name_prob', 'msno_first_genre_id_prob', \\\n",
    "        'msno_xxx_prob', 'msno_language_prob', 'msno_yy_prob', 'msno_source_prob', \\\n",
    "        'song_source_system_tab_prob', 'song_source_screen_name_prob', 'song_source_type_prob']\n",
    "\n",
    "train_context = train[context_features].values\n",
    "test_context = test[context_features].values\n",
    "\n",
    "ss_context = StandardScaler()\n",
    "train_context = ss_context.fit_transform(train_context)\n",
    "test_context = ss_context.transform(test_context)\n",
    "\n",
    "del train\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_features = ['bd', 'expiration_date', 'msno_rec_cnt', 'msno_source_screen_name_0', \\\n",
    "        'msno_source_screen_name_1', 'msno_source_screen_name_10', 'msno_source_screen_name_11', \\\n",
    "        'msno_source_screen_name_12', 'msno_source_screen_name_13', 'msno_source_screen_name_14', \\\n",
    "        'msno_source_screen_name_17', \\\n",
    "        'msno_source_screen_name_18', 'msno_source_screen_name_19', 'msno_source_screen_name_2', \\\n",
    "        'msno_source_screen_name_20', 'msno_source_screen_name_21', 'msno_source_screen_name_3', 'msno_source_screen_name_4', \\\n",
    "        'msno_source_screen_name_5', 'msno_source_screen_name_6', 'msno_source_screen_name_7', \\\n",
    "        'msno_source_screen_name_8', 'msno_source_screen_name_9', 'msno_source_system_tab_0', \\\n",
    "        'msno_source_system_tab_1', 'msno_source_system_tab_2', 'msno_source_system_tab_3', \\\n",
    "        'msno_source_system_tab_4', 'msno_source_system_tab_5', 'msno_source_system_tab_6', \\\n",
    "        'msno_source_system_tab_7', 'msno_source_system_tab_8', \\\n",
    "        'msno_source_type_0', 'msno_source_type_1', 'msno_source_type_10', \\\n",
    "        'msno_source_type_11', 'msno_source_type_2', \\\n",
    "        'msno_source_type_3', 'msno_source_type_4', 'msno_source_type_5', \\\n",
    "        'msno_source_type_6', \\\n",
    "        'msno_source_type_7', 'msno_source_type_8', 'msno_source_type_9', \\\n",
    "        'msno_timestamp_mean', 'msno_timestamp_std', 'registration_init_time', \\\n",
    "        'msno_song_length_mean', 'msno_artist_song_cnt_mean', 'msno_artist_rec_cnt_mean', \\\n",
    "        'msno_song_rec_cnt_mean', 'msno_yy_mean', 'msno_song_length_std', \\\n",
    "        'msno_artist_song_cnt_std', 'msno_artist_rec_cnt_std', 'msno_song_rec_cnt_std', \\\n",
    "        'msno_yy_std', 'artist_msno_cnt']\n",
    "\n",
    "usr_feat = member[usr_features].values\n",
    "usr_feat = StandardScaler().fit_transform(usr_feat)\n",
    "\n",
    "song_features = ['artist_rec_cnt', 'artist_song_cnt', 'composer_song_cnt', \\\n",
    "        'genre_rec_cnt', 'genre_song_cnt', 'song_length', \\\n",
    "        'song_rec_cnt', 'song_timestamp_mean', 'song_timestamp_std', \\\n",
    "        'xxx_rec_cnt', 'xxx_song_cnt', 'yy', 'yy_song_cnt']\n",
    "\n",
    "song_feat = song[song_features].values\n",
    "song_feat = StandardScaler().fit_transform(song_feat)\n",
    "\n",
    "n_factors = 48\n",
    "\n",
    "usr_component_features = ['member_component_%d'%i for i in range(n_factors)]\n",
    "song_component_features = ['song_component_%d'%i for i in range(n_factors)]\n",
    "\n",
    "usr_component = member[usr_component_features].values\n",
    "song_component = song[song_component_features].values\n",
    "\n",
    "n_artist = 16\n",
    "\n",
    "usr_artist_features = ['member_artist_component_%d'%i for i in range(n_artist)]\n",
    "song_artist_features = ['artist_component_%d'%i for i in range(n_artist)]\n",
    "\n",
    "usr_artist_component = member[usr_artist_features].values\n",
    "song_artist_component = song[song_artist_features].values\n",
    "\n",
    "del member\n",
    "del song\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataGenerator = DataGenerator()\n",
    "\n",
    "train_flow = dataGenerator.flow(train_embeddings+train_genre, [train_context], \\\n",
    "        train_y, batch_size=8192, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "## Model Structure\n",
    "######################################################\n",
    "\n",
    "## define the model\n",
    "def FunctionalDense(n, x, batchnorm=False, act='relu', lw1=0.0, dropout=0, name=''):\n",
    "    if lw1 == 0.0:\n",
    "        x = Dense(n, name=name+'_dense')(x)\n",
    "    else:\n",
    "        x = Dense(n, kernel_regularizer=l1(lw1), name=name+'_dense')(x)\n",
    "    \n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(name=name+'_batchnorm')(x)\n",
    "        \n",
    "    if act in {'relu', 'tanh', 'sigmoid'}:\n",
    "        x = Activation(act, name=name+'_activation')(x)\n",
    "    elif act =='prelu':\n",
    "        x = PReLU(name=name+'_activation')(x)\n",
    "    elif act == 'leakyrelu':\n",
    "        x = LeakyReLU(name=name+'_activation')(x)\n",
    "    elif act == 'elu':\n",
    "        x = ELU(name=name+'_activation')(x)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout, name=name+'_dropout')(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def get_model(K, K0, lw=1e-4, lw1=1e-4, lr=1e-3, act='relu', batchnorm=False):\n",
    "    embedding_inputs = []\n",
    "    embedding_outputs = []\n",
    "    for i in range(len(embedding_features) - 3):\n",
    "        val_bound = 0.0 if i == 0 else 0.005\n",
    "        tmp_input = Input(shape=(1,), dtype='int32', name=embedding_features[i]+'_input')\n",
    "        tmp_embeddings = Embedding(int(train_embeddings[i].max()+1),\n",
    "                K if i == 0 else K0,\n",
    "                embeddings_initializer=RandomUniform(minval=-val_bound, maxval=val_bound),\n",
    "                embeddings_regularizer=l2(lw),\n",
    "                input_length=1,\n",
    "                trainable=True,\n",
    "                name=embedding_features[i]+'_embeddings')(tmp_input)\n",
    "        tmp_embeddings = Flatten(name=embedding_features[i]+'_flatten')(tmp_embeddings)\n",
    "        \n",
    "        embedding_inputs.append(tmp_input)\n",
    "        embedding_outputs.append(tmp_embeddings)\n",
    "\n",
    "    song_id_input = Input(shape=(1,), dtype='int32', name='song_id_input')\n",
    "    before_song_id_input = Input(shape=(1,), dtype='int32', name='before_song_id_input')\n",
    "    after_song_id_input = Input(shape=(1,), dtype='int32', name='after_song_id_input')\n",
    "\n",
    "    embedding_inputs += [song_id_input, before_song_id_input, after_song_id_input]\n",
    "\n",
    "    genre_inputs = []\n",
    "    genre_outputs = []\n",
    "    genre_embeddings = Embedding(int(np.max(train_genre)+1),\n",
    "            K0,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.05, maxval=0.05),\n",
    "            embeddings_regularizer=l2(lw),\n",
    "            input_length=1,\n",
    "            trainable=True,\n",
    "            name='genre_embeddings')\n",
    "    for i in range(len(genre_features)):\n",
    "        tmp_input = Input(shape=(1,), dtype='int32', name=genre_features[i]+'_input')\n",
    "        tmp_embeddings = genre_embeddings(tmp_input)\n",
    "        tmp_embeddings = Flatten(name=genre_features[i]+'_flatten')(tmp_embeddings)\n",
    "        \n",
    "        genre_inputs.append(tmp_input)\n",
    "        genre_outputs.append(tmp_embeddings)\n",
    "\n",
    "    usr_input = Embedding(usr_feat.shape[0],\n",
    "            usr_feat.shape[1],\n",
    "            weights=[usr_feat],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='usr_feat')(embedding_inputs[0])\n",
    "    usr_input = Flatten(name='usr_feat_flatten')(usr_input)\n",
    "    \n",
    "    song_input = Embedding(song_feat.shape[0],\n",
    "            song_feat.shape[1],\n",
    "            weights=[song_feat],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='song_feat')(song_id_input)\n",
    "    song_input = Flatten(name='song_feat_flatten')(song_input)\n",
    "    \n",
    "    usr_component_input = Embedding(usr_component.shape[0],\n",
    "            usr_component.shape[1],\n",
    "            weights=[usr_component],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='usr_component')(embedding_inputs[0])\n",
    "    usr_component_input = Flatten(name='usr_component_flatten')(usr_component_input)\n",
    "    \n",
    "    song_component_embeddings = Embedding(song_component.shape[0],\n",
    "            song_component.shape[1],\n",
    "            weights=[song_component],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='song_component')\n",
    "    song_component_input = song_component_embeddings(song_id_input)\n",
    "    song_component_input = Flatten(name='song_component_flatten')(song_component_input)\n",
    "    before_song_component_input = song_component_embeddings(before_song_id_input)\n",
    "    before_song_component_input = Flatten(name='before_song_component_flatten')(before_song_component_input)\n",
    "    after_song_component_input = song_component_embeddings(after_song_id_input)\n",
    "    after_song_component_input = Flatten(name='after_song_component_flatten')(after_song_component_input)\n",
    "    \n",
    "    usr_artist_component_input = Embedding(usr_artist_component.shape[0],\n",
    "            usr_artist_component.shape[1],\n",
    "            weights=[usr_artist_component],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='usr_artist_component')(embedding_inputs[0])\n",
    "    usr_artist_component_input = Flatten(name='usr_artist_component_flatten')(usr_artist_component_input)\n",
    "    \n",
    "    song_artist_component_embeddings = Embedding(song_artist_component.shape[0],\n",
    "            song_artist_component.shape[1],\n",
    "            weights=[song_artist_component],\n",
    "            input_length=1,\n",
    "            trainable=False,\n",
    "            name='song_artist_component')\n",
    "    song_artist_component_input = song_artist_component_embeddings(song_id_input)\n",
    "    song_artist_component_input = Flatten(name='song_artist_component_flatten')(song_artist_component_input)\n",
    "    before_song_artist_component_input = song_artist_component_embeddings(before_song_id_input)\n",
    "    before_song_artist_component_input = Flatten(name='before_song_artist_component_flatten')(before_song_artist_component_input)\n",
    "    after_song_artist_component_input = song_artist_component_embeddings(after_song_id_input)\n",
    "    after_song_artist_component_input = Flatten(name='after_song_artist_component_flatten')(after_song_artist_component_input)\n",
    "    \n",
    "    context_input = Input(shape=(len(context_features),), name='context_feat')\n",
    "    \n",
    "    # basic profiles\n",
    "    usr_profile = concatenate(embedding_outputs[1:4]+[usr_input, \\\n",
    "            usr_component_input, usr_artist_component_input], name='usr_profile')\n",
    "    song_profile = concatenate(embedding_outputs[4:7]+genre_outputs+[song_input, \\\n",
    "            song_component_input, song_artist_component_input], name='song_profile')\n",
    "\n",
    "    multiply_component = dot([usr_component_input, song_component_input], axes=1, name='component_dot')\n",
    "    multiply_artist_component = dot([usr_artist_component_input, \\\n",
    "            song_artist_component_input], axes=1, name='artist_component_dot')\n",
    "    multiply_before_song = dot([before_song_component_input, song_component_input], \\\n",
    "            normalize=True, axes=1, name='before_component_dot')\n",
    "    multiply_after_song = dot([after_song_component_input, song_component_input], \\\n",
    "            normalize=True, axes=1, name='after_component_dot')\n",
    "    multiply_before_artist = dot([before_song_artist_component_input, song_artist_component_input], \\\n",
    "            normalize=True, axes=1, name='before_artist_component_dot')\n",
    "    multiply_after_artist = dot([after_song_artist_component_input, song_artist_component_input], \\\n",
    "            normalize=True, axes=1, name='after_artist_component_dot')\n",
    "    context_profile = concatenate(embedding_outputs[7:]+[context_input, \\\n",
    "            multiply_component, multiply_artist_component, before_song_component_input, \\\n",
    "            after_song_component_input, before_song_artist_component_input, \\\n",
    "            after_song_artist_component_input, multiply_before_song, multiply_after_song, \\\n",
    "            multiply_before_artist, multiply_after_artist], name='context_profile')\n",
    "    \n",
    "    # user field\n",
    "    usr_embeddings = FunctionalDense(K*2, usr_profile, lw1=lw1, batchnorm=batchnorm, act=act, name='usr_profile')\n",
    "    usr_embeddings = Dense(K, name='usr_profile_output')(usr_embeddings)\n",
    "    usr_embeddings = add([usr_embeddings, embedding_outputs[0]], name='usr_embeddings')\n",
    "    \n",
    "    # song field\n",
    "    song_embeddings = FunctionalDense(K*2, song_profile, lw1=lw1, batchnorm=batchnorm, act=act, name='song_profile')\n",
    "    song_embeddings = Dense(K, name='song_profile_output')(song_embeddings)\n",
    "    #song_embeddings = add([song_embeddings, embedding_outputs[4]], name='song_embeddings')\n",
    "    \n",
    "    # context field\n",
    "    context_embeddings = FunctionalDense(K, context_profile, lw1=lw1, batchnorm=batchnorm, act=act, name='context_profile')\n",
    "\n",
    "    # joint embeddings\n",
    "    joint = dot([usr_embeddings, song_embeddings], axes=1, normalize=False, name='pred_cross')\n",
    "    joint_embeddings = concatenate([usr_embeddings, song_embeddings, context_embeddings, joint], name='joint_embeddings')\n",
    "    \n",
    "    # top model\n",
    "    preds0 = FunctionalDense(K*2, joint_embeddings, batchnorm=batchnorm, act=act, name='preds_0')\n",
    "    preds1 = FunctionalDense(K*2, concatenate([joint_embeddings, preds0]), batchnorm=batchnorm, act=act, name='preds_1')\n",
    "    preds2 = FunctionalDense(K*2, concatenate([joint_embeddings, preds0, preds1]), batchnorm=batchnorm, act=act, name='preds_2')\n",
    "    \n",
    "    preds = concatenate([joint_embeddings, preds0, preds1, preds2], name='prediction_aggr')\n",
    "    preds = Dropout(0.5, name='prediction_dropout')(preds)\n",
    "    preds = Dense(1, activation='sigmoid', name='prediction')(preds)\n",
    "        \n",
    "    model = Model(inputs=embedding_inputs+genre_inputs+[context_input], outputs=preds)\n",
    "    \n",
    "    opt = RMSprop(lr=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 82, K0: 6, lw: 3.233625e-04, lw1: 0.000000e+00, lr: 8.507431e-03, lr_decay: 0.903615, act: elu, batchnorm: True\n",
      "Epoch 1/19\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.6286 - acc: 0.6801\n",
      "Epoch 2/19\n",
      "862/862 [==============================] - 25s 30ms/step - loss: 0.5823 - acc: 0.7038\n",
      "Epoch 3/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5725 - acc: 0.7104\n",
      "Epoch 4/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5658 - acc: 0.7143\n",
      "Epoch 5/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5608 - acc: 0.7172\n",
      "Epoch 6/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5566 - acc: 0.7194\n",
      "Epoch 7/19\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5528 - acc: 0.7216\n",
      "Epoch 8/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5498 - acc: 0.7232\n",
      "Epoch 9/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5471 - acc: 0.7249\n",
      "Epoch 10/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5447 - acc: 0.7263\n",
      "Epoch 11/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5425 - acc: 0.7280\n",
      "Epoch 12/19\n",
      "862/862 [==============================] - 25s 29ms/step - loss: 0.5403 - acc: 0.7306\n",
      "Epoch 13/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5358 - acc: 0.7365\n",
      "Epoch 14/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5306 - acc: 0.7415\n",
      "Epoch 15/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5272 - acc: 0.7441\n",
      "Epoch 16/19\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5247 - acc: 0.7457\n",
      "Epoch 17/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5228 - acc: 0.7472\n",
      "Epoch 18/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5211 - acc: 0.7483\n",
      "Epoch 19/19\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5195 - acc: 0.7496\n",
      "Model training done. Validation AUC: 0.72858\n",
      "K: 88, K0: 7, lw: 9.984157e-04, lw1: 0.000000e+00, lr: 1.253470e-02, lr_decay: 0.909158, act: leakyrelu, batchnorm: True\n",
      "Epoch 1/35\n",
      "862/862 [==============================] - 28s 33ms/step - loss: 0.7315 - acc: 0.6814\n",
      "Epoch 2/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6658 - acc: 0.7032\n",
      "Epoch 3/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6426 - acc: 0.7091\n",
      "Epoch 4/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6240 - acc: 0.7129\n",
      "Epoch 5/35\n",
      "862/862 [==============================] - 26s 31ms/step - loss: 0.6088 - acc: 0.7160\n",
      "Epoch 6/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5959 - acc: 0.7187\n",
      "Epoch 7/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5849 - acc: 0.7214\n",
      "Epoch 8/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5756 - acc: 0.7235\n",
      "Epoch 9/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5675 - acc: 0.7256\n",
      "Epoch 10/35\n",
      "862/862 [==============================] - 26s 31ms/step - loss: 0.5607 - acc: 0.7274\n",
      "Epoch 11/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5548 - acc: 0.7291\n",
      "Epoch 12/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5497 - acc: 0.7308\n",
      "Epoch 13/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5452 - acc: 0.7324\n",
      "Epoch 14/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5412 - acc: 0.7338\n",
      "Epoch 15/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5376 - acc: 0.7352\n",
      "Epoch 16/35\n",
      "862/862 [==============================] - 26s 31ms/step - loss: 0.5345 - acc: 0.7363\n",
      "Epoch 17/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5314 - acc: 0.7377\n",
      "Epoch 18/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5288 - acc: 0.7387\n",
      "Epoch 19/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5263 - acc: 0.7399\n",
      "Epoch 20/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5241 - acc: 0.7410\n",
      "Epoch 21/35\n",
      "862/862 [==============================] - 26s 31ms/step - loss: 0.5219 - acc: 0.7419\n",
      "Epoch 22/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5199 - acc: 0.7431\n",
      "Epoch 23/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5180 - acc: 0.7438\n",
      "Epoch 24/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5164 - acc: 0.7448\n",
      "Epoch 25/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5147 - acc: 0.7458\n",
      "Epoch 26/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5131 - acc: 0.7466\n",
      "Epoch 27/35\n",
      "862/862 [==============================] - 26s 31ms/step - loss: 0.5116 - acc: 0.7474\n",
      "Epoch 28/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5105 - acc: 0.7479\n",
      "Epoch 29/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5091 - acc: 0.7488\n",
      "Epoch 30/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5079 - acc: 0.7493\n",
      "Epoch 31/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5068 - acc: 0.7499\n",
      "Epoch 32/35\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5058 - acc: 0.7505\n",
      "Epoch 33/35\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5048 - acc: 0.7511\n",
      "Epoch 34/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5040 - acc: 0.7515\n",
      "Epoch 35/35\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5031 - acc: 0.7520\n",
      "Model training done. Validation AUC: 0.72832\n",
      "K: 106, K0: 10, lw: 1.520053e-03, lw1: 0.000000e+00, lr: 8.778001e-03, lr_decay: 0.916829, act: tanh, batchnorm: True\n",
      "Epoch 1/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.7393 - acc: 0.6723\n",
      "Epoch 2/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6642 - acc: 0.6995\n",
      "Epoch 3/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6436 - acc: 0.7048\n",
      "Epoch 4/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6266 - acc: 0.7084\n",
      "Epoch 5/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.6125 - acc: 0.7118\n",
      "Epoch 6/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.6009 - acc: 0.7140\n",
      "Epoch 7/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5910 - acc: 0.7159\n",
      "Epoch 8/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5825 - acc: 0.7179\n",
      "Epoch 9/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5754 - acc: 0.7193\n",
      "Epoch 10/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5693 - acc: 0.7209\n",
      "Epoch 11/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5640 - acc: 0.7222\n",
      "Epoch 12/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5598 - acc: 0.7231\n",
      "Epoch 13/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5561 - acc: 0.7240\n",
      "Epoch 14/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5528 - acc: 0.7250\n",
      "Epoch 15/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5501 - acc: 0.7255\n",
      "Epoch 16/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5478 - acc: 0.7263\n",
      "Epoch 17/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5457 - acc: 0.7269\n",
      "Epoch 18/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5440 - acc: 0.7274\n",
      "Epoch 19/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5424 - acc: 0.7279\n",
      "Epoch 20/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5409 - acc: 0.7284\n",
      "Epoch 21/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5397 - acc: 0.7289\n",
      "Epoch 22/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5387 - acc: 0.7293\n",
      "Epoch 23/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5376 - acc: 0.7297\n",
      "Epoch 24/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5368 - acc: 0.7303\n",
      "Epoch 25/38\n",
      "862/862 [==============================] - 28s 32ms/step - loss: 0.5360 - acc: 0.7305\n",
      "Epoch 26/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5353 - acc: 0.7308\n",
      "Epoch 27/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5345 - acc: 0.7313\n",
      "Epoch 28/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5338 - acc: 0.7318\n",
      "Epoch 29/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5332 - acc: 0.7321\n",
      "Epoch 30/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5326 - acc: 0.7325\n",
      "Epoch 31/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5319 - acc: 0.7329\n",
      "Epoch 32/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5314 - acc: 0.7333\n",
      "Epoch 33/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5310 - acc: 0.7333\n",
      "Epoch 34/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5306 - acc: 0.7336\n",
      "Epoch 35/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5301 - acc: 0.7340\n",
      "Epoch 36/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5297 - acc: 0.7343\n",
      "Epoch 37/38\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5293 - acc: 0.7344\n",
      "Epoch 38/38\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.5290 - acc: 0.7347\n",
      "Model training done. Validation AUC: 0.72796\n",
      "K: 51, K0: 15, lw: 8.714193e-04, lw1: 0.000000e+00, lr: 1.027691e-02, lr_decay: 0.769936, act: tanh, batchnorm: True\n",
      "Epoch 1/21\n",
      "862/862 [==============================] - 27s 32ms/step - loss: 0.6578 - acc: 0.6792\n",
      "Epoch 2/21\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5979 - acc: 0.7048\n",
      "Epoch 3/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5779 - acc: 0.7110\n",
      "Epoch 4/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5659 - acc: 0.7149\n",
      "Epoch 5/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5580 - acc: 0.7178\n",
      "Epoch 6/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5525 - acc: 0.7202\n",
      "Epoch 7/21\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5487 - acc: 0.7219\n",
      "Epoch 8/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5457 - acc: 0.7236\n",
      "Epoch 9/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5437 - acc: 0.7247\n",
      "Epoch 10/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5419 - acc: 0.7257\n",
      "Epoch 11/21\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5406 - acc: 0.7267\n",
      "Epoch 12/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5396 - acc: 0.7274\n",
      "Epoch 13/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5386 - acc: 0.7280\n",
      "Epoch 14/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5378 - acc: 0.7285\n",
      "Epoch 15/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5371 - acc: 0.7292\n",
      "Epoch 16/21\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5365 - acc: 0.7296\n",
      "Epoch 17/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5360 - acc: 0.7299\n",
      "Epoch 18/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5355 - acc: 0.7304\n",
      "Epoch 19/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5351 - acc: 0.7309\n",
      "Epoch 20/21\n",
      "862/862 [==============================] - 27s 31ms/step - loss: 0.5348 - acc: 0.7310\n",
      "Epoch 21/21\n",
      "862/862 [==============================] - 26s 30ms/step - loss: 0.5344 - acc: 0.7315\n",
      "Model training done. Validation AUC: 0.72767\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## Model Training\n",
    "######################################################\n",
    "\n",
    "## train the model\n",
    "para = pd.read_csv('./nn_record.csv').sort_values(by='val_auc', ascending=False)\n",
    "for i in range(1,5): # 5\n",
    "\n",
    "    K = para['K'].values[i]\n",
    "    K0 = para['K0'].values[i]\n",
    "    lw = para['lw'].values[i]\n",
    "    lw1 = para['lw1'].values[i]\n",
    "    lr = para['lr'].values[i]\n",
    "    lr_decay = para['lr_decay'].values[i]\n",
    "    activation = para['activation'].values[i]\n",
    "    batchnorm = para['batchnorm'].values[i]\n",
    "    bst_epoch = para['bst_epoch'].values[i]\n",
    "    train_loss0 = para['trn_loss'].values[i]\n",
    "    val_auc = para['val_auc'].values[i]\n",
    "\n",
    "    while(True):\n",
    "        print('K: %d, K0: %d, lw: %e, lw1: %e, lr: %e, lr_decay: %f, act: %s, batchnorm: %s'%(K, K0, lw, \\\n",
    "                lw1, lr, lr_decay, activation, batchnorm))\n",
    "        \n",
    "        model = get_model(K, K0, lw, lw1, lr, activation, batchnorm)\n",
    "        \n",
    "        #model.summary()\n",
    "        #from keras.utils import plot_model\n",
    "        #plot_model(model, to_file='model.png')\n",
    "\n",
    "        lr_reducer = LearningRateScheduler(lambda x: lr*(lr_decay**x))\n",
    "        \n",
    "        hist = model.fit_generator(train_flow, train_flow.__len__(), \\\n",
    "                 epochs=bst_epoch, workers=4, callbacks=[lr_reducer])\n",
    "        \n",
    "        train_loss = hist.history['loss'][-1]\n",
    "        \n",
    "        if(train_loss < train_loss0 * 1.1):\n",
    "            break\n",
    "        \n",
    "    val_auc = para['val_auc'].values[i]\n",
    "    print('Model training done. Validation AUC: %.5f'%val_auc)\n",
    "\n",
    "    flag = np.random.randint(0, 65536)\n",
    "    \n",
    "    test_flow = dataGenerator.flow(test_embeddings + test_genre, [test_context], \\\n",
    "            batch_size=16384, shuffle=False)\n",
    "    test_pred = model.predict_generator(test_flow, test_flow.__len__(), workers=1)\n",
    "    \n",
    "    test_sub = pd.DataFrame({'id': test_id, 'target': test_pred.ravel()})\n",
    "    test_sub.to_csv('./temp_nn/nn_%.5f_%.5f_%d.csv'%(val_auc, train_loss, flag), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K: 74, K0: 11, lw: 5.315258e-04, lw1: 0.000000e+00, lr: 1.405365e-03, lr_decay: 0.778385, act: elu, batchnorm: False\n",
    "Epoch 1/26\n",
    "862/862 [==============================] - 19s 23ms/step - loss: 0.5913 - acc: 0.6870\n",
    "Epoch 2/26\n",
    "862/862 [==============================] - 20s 23ms/step - loss: 0.5650 - acc: 0.7073\n",
    "Epoch 3/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5564 - acc: 0.7141\n",
    "Epoch 4/26\n",
    "862/862 [==============================] - 20s 23ms/step - loss: 0.5499 - acc: 0.7191\n",
    "Epoch 5/26\n",
    "862/862 [==============================] - 20s 23ms/step - loss: 0.5450 - acc: 0.7228\n",
    "Epoch 6/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5410 - acc: 0.7260\n",
    "Epoch 7/26\n",
    "862/862 [==============================] - 20s 23ms/step - loss: 0.5376 - acc: 0.7285\n",
    "Epoch 8/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5348 - acc: 0.7309\n",
    "Epoch 9/26\n",
    "862/862 [==============================] - 20s 23ms/step - loss: 0.5323 - acc: 0.7329\n",
    "Epoch 10/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5300 - acc: 0.7349\n",
    "Epoch 11/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5276 - acc: 0.7372\n",
    "Epoch 12/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5251 - acc: 0.7396\n",
    "Epoch 13/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5226 - acc: 0.7419\n",
    "Epoch 14/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5203 - acc: 0.7439\n",
    "Epoch 15/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5184 - acc: 0.7455\n",
    "Epoch 16/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5169 - acc: 0.7468\n",
    "Epoch 17/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5157 - acc: 0.7477\n",
    "Epoch 18/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5149 - acc: 0.7484\n",
    "Epoch 19/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5142 - acc: 0.7490\n",
    "Epoch 20/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5137 - acc: 0.7493\n",
    "Epoch 21/26\n",
    "862/862 [==============================] - 21s 24ms/step - loss: 0.5131 - acc: 0.7497\n",
    "Epoch 22/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5128 - acc: 0.7499\n",
    "Epoch 23/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5126 - acc: 0.7501\n",
    "Epoch 24/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5123 - acc: 0.7503\n",
    "Epoch 25/26\n",
    "862/862 [==============================] - 19s 22ms/step - loss: 0.5123 - acc: 0.7505\n",
    "Epoch 26/26\n",
    "862/862 [==============================] - 20s 24ms/step - loss: 0.5121 - acc: 0.7505\n",
    "Model training done. Validation AUC: 0.73192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i = 1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K: 82, K0: 6, lw: 3.233625e-04, lw1: 0.000000e+00, lr: 8.507431e-03, lr_decay: 0.903615, act: elu, batchnorm: True\n",
    "Epoch 1/19\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.6286 - acc: 0.6801\n",
    "Epoch 2/19\n",
    "862/862 [==============================] - 25s 30ms/step - loss: 0.5823 - acc: 0.7038\n",
    "Epoch 3/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5725 - acc: 0.7104\n",
    "Epoch 4/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5658 - acc: 0.7143\n",
    "Epoch 5/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5608 - acc: 0.7172\n",
    "Epoch 6/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5566 - acc: 0.7194\n",
    "Epoch 7/19\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5528 - acc: 0.7216\n",
    "Epoch 8/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5498 - acc: 0.7232\n",
    "Epoch 9/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5471 - acc: 0.7249\n",
    "Epoch 10/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5447 - acc: 0.7263\n",
    "Epoch 11/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5425 - acc: 0.7280\n",
    "Epoch 12/19\n",
    "862/862 [==============================] - 25s 29ms/step - loss: 0.5403 - acc: 0.7306\n",
    "Epoch 13/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5358 - acc: 0.7365\n",
    "Epoch 14/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5306 - acc: 0.7415b\n",
    "Epoch 15/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5272 - acc: 0.7441\n",
    "Epoch 16/19\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5247 - acc: 0.7457\n",
    "Epoch 17/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5228 - acc: 0.7472\n",
    "Epoch 18/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5211 - acc: 0.7483\n",
    "Epoch 19/19\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5195 - acc: 0.7496\n",
    "Model training done. Validation AUC: 0.72858\n",
    "K: 88, K0: 7, lw: 9.984157e-04, lw1: 0.000000e+00, lr: 1.253470e-02, lr_decay: 0.909158, act: leakyrelu, batchnorm: True\n",
    "Epoch 1/35\n",
    "862/862 [==============================] - 28s 33ms/step - loss: 0.7315 - acc: 0.6814\n",
    "Epoch 2/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6658 - acc: 0.7032\n",
    "Epoch 3/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6426 - acc: 0.7091\n",
    "Epoch 4/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6240 - acc: 0.7129\n",
    "Epoch 5/35\n",
    "862/862 [==============================] - 26s 31ms/step - loss: 0.6088 - acc: 0.7160\n",
    "Epoch 6/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5959 - acc: 0.7187\n",
    "Epoch 7/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5849 - acc: 0.7214\n",
    "Epoch 8/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5756 - acc: 0.7235\n",
    "Epoch 9/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5675 - acc: 0.7256\n",
    "Epoch 10/35\n",
    "862/862 [==============================] - 26s 31ms/step - loss: 0.5607 - acc: 0.7274\n",
    "Epoch 11/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5548 - acc: 0.7291\n",
    "Epoch 12/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5497 - acc: 0.7308\n",
    "Epoch 13/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5452 - acc: 0.7324\n",
    "Epoch 14/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5412 - acc: 0.7338\n",
    "Epoch 15/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5376 - acc: 0.7352\n",
    "Epoch 16/35\n",
    "862/862 [==============================] - 26s 31ms/step - loss: 0.5345 - acc: 0.7363\n",
    "Epoch 17/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5314 - acc: 0.7377\n",
    "Epoch 18/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5288 - acc: 0.7387\n",
    "Epoch 19/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5263 - acc: 0.7399\n",
    "Epoch 20/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5241 - acc: 0.7410\n",
    "Epoch 21/35\n",
    "862/862 [==============================] - 26s 31ms/step - loss: 0.5219 - acc: 0.7419\n",
    "Epoch 22/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5199 - acc: 0.7431\n",
    "Epoch 23/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5180 - acc: 0.7438\n",
    "Epoch 24/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5164 - acc: 0.7448\n",
    "Epoch 25/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5147 - acc: 0.7458\n",
    "Epoch 26/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5131 - acc: 0.7466\n",
    "Epoch 27/35\n",
    "862/862 [==============================] - 26s 31ms/step - loss: 0.5116 - acc: 0.7474\n",
    "Epoch 28/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5105 - acc: 0.7479\n",
    "Epoch 29/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5091 - acc: 0.7488\n",
    "Epoch 30/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5079 - acc: 0.7493\n",
    "Epoch 31/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5068 - acc: 0.7499\n",
    "Epoch 32/35\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5058 - acc: 0.7505\n",
    "Epoch 33/35\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5048 - acc: 0.7511\n",
    "Epoch 34/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5040 - acc: 0.7515\n",
    "Epoch 35/35\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5031 - acc: 0.7520\n",
    "Model training done. Validation AUC: 0.72832\n",
    "K: 106, K0: 10, lw: 1.520053e-03, lw1: 0.000000e+00, lr: 8.778001e-03, lr_decay: 0.916829, act: tanh, batchnorm: True\n",
    "Epoch 1/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.7393 - acc: 0.6723\n",
    "Epoch 2/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6642 - acc: 0.6995\n",
    "Epoch 3/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6436 - acc: 0.7048\n",
    "Epoch 4/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6266 - acc: 0.7084\n",
    "Epoch 5/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.6125 - acc: 0.7118\n",
    "Epoch 6/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.6009 - acc: 0.7140\n",
    "Epoch 7/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5910 - acc: 0.7159\n",
    "Epoch 8/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5825 - acc: 0.7179\n",
    "Epoch 9/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5754 - acc: 0.7193\n",
    "Epoch 10/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5693 - acc: 0.7209\n",
    "Epoch 11/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5640 - acc: 0.7222\n",
    "Epoch 12/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5598 - acc: 0.7231\n",
    "Epoch 13/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5561 - acc: 0.7240\n",
    "Epoch 14/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5528 - acc: 0.7250\n",
    "Epoch 15/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5501 - acc: 0.7255\n",
    "Epoch 16/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5478 - acc: 0.7263\n",
    "Epoch 17/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5457 - acc: 0.7269\n",
    "Epoch 18/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5440 - acc: 0.7274\n",
    "Epoch 19/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5424 - acc: 0.7279\n",
    "Epoch 20/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5409 - acc: 0.7284\n",
    "Epoch 21/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5397 - acc: 0.7289\n",
    "Epoch 22/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5387 - acc: 0.7293\n",
    "Epoch 23/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5376 - acc: 0.7297\n",
    "Epoch 24/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5368 - acc: 0.7303\n",
    "Epoch 25/38\n",
    "862/862 [==============================] - 28s 32ms/step - loss: 0.5360 - acc: 0.7305\n",
    "Epoch 26/38\n",
    "\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5353 - acc: 0.7308\n",
    "Epoch 27/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5345 - acc: 0.7313\n",
    "Epoch 28/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5338 - acc: 0.7318\n",
    "Epoch 29/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5332 - acc: 0.7321\n",
    "Epoch 30/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5326 - acc: 0.7325\n",
    "Epoch 31/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5319 - acc: 0.7329\n",
    "Epoch 32/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5314 - acc: 0.7333\n",
    "Epoch 33/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5310 - acc: 0.7333\n",
    "Epoch 34/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5306 - acc: 0.7336\n",
    "Epoch 35/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5301 - acc: 0.7340\n",
    "Epoch 36/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5297 - acc: 0.7343\n",
    "Epoch 37/38\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5293 - acc: 0.7344\n",
    "Epoch 38/38\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.5290 - acc: 0.7347\n",
    "Model training done. Validation AUC: 0.72796\n",
    "K: 51, K0: 15, lw: 8.714193e-04, lw1: 0.000000e+00, lr: 1.027691e-02, lr_decay: 0.769936, act: tanh, batchnorm: True\n",
    "Epoch 1/21\n",
    "862/862 [==============================] - 27s 32ms/step - loss: 0.6578 - acc: 0.6792\n",
    "Epoch 2/21\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5979 - acc: 0.7048\n",
    "Epoch 3/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5779 - acc: 0.7110\n",
    "Epoch 4/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5659 - acc: 0.7149\n",
    "Epoch 5/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5580 - acc: 0.7178\n",
    "Epoch 6/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5525 - acc: 0.7202\n",
    "Epoch 7/21\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5487 - acc: 0.7219\n",
    "Epoch 8/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5457 - acc: 0.7236\n",
    "Epoch 9/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5437 - acc: 0.7247\n",
    "Epoch 10/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5419 - acc: 0.7257\n",
    "Epoch 11/21\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5406 - acc: 0.7267\n",
    "Epoch 12/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5396 - acc: 0.7274\n",
    "Epoch 13/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5386 - acc: 0.7280\n",
    "Epoch 14/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5378 - acc: 0.7285\n",
    "Epoch 15/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5371 - acc: 0.7292\n",
    "Epoch 16/21\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5365 - acc: 0.7296\n",
    "Epoch 17/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5360 - acc: 0.7299\n",
    "Epoch 18/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5355 - acc: 0.7304\n",
    "Epoch 19/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5351 - acc: 0.7309\n",
    "Epoch 20/21\n",
    "862/862 [==============================] - 27s 31ms/step - loss: 0.5348 - acc: 0.7310\n",
    "Epoch 21/21\n",
    "862/862 [==============================] - 26s 30ms/step - loss: 0.5344 - acc: 0.7315\n",
    "Model training done. Validation AUC: 0.72767\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
