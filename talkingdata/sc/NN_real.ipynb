{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train\n",
      "loaded test\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_feather('Feathers/ss_alltrain_typechanged.ftr')\n",
    "print('loaded train')\n",
    "test = pd.read_feather('Feathers/ss_test_via_alltrain_typechanged.ftr')\n",
    "print('loaded test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('index', inplace=True)\n",
    "del train.index.name\n",
    "test.set_index('index', inplace=True)\n",
    "del test.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>app_day_hour_count</th>\n",
       "      <th>app_device_os_mean</th>\n",
       "      <th>attributed_timediff</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ip_app_day_hour_count</th>\n",
       "      <th>ip_app_device_countfromfuture</th>\n",
       "      <th>ip_app_device_countfrompast</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_device_os_lasttimediff</th>\n",
       "      <th>ip_device_os_mean</th>\n",
       "      <th>ip_device_os_time2nextclick</th>\n",
       "      <th>ip_device_os_time2previousclick</th>\n",
       "      <th>ip_os_day_hour_count</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>matrixFact_user_ip_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_ipchannel_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_iposdeviceapp_item_app</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.355859</td>\n",
       "      <td>-0.083193</td>\n",
       "      <td>0.482835</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.231806</td>\n",
       "      <td>0.354194</td>\n",
       "      <td>-0.21365</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718168</td>\n",
       "      <td>0.027336</td>\n",
       "      <td>1.292117</td>\n",
       "      <td>-0.207378</td>\n",
       "      <td>-0.221148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.269234</td>\n",
       "      <td>-0.426699</td>\n",
       "      <td>-1.119404</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.355859</td>\n",
       "      <td>-0.084415</td>\n",
       "      <td>0.482835</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.231806</td>\n",
       "      <td>0.262257</td>\n",
       "      <td>-0.21365</td>\n",
       "      <td>...</td>\n",
       "      <td>2.711555</td>\n",
       "      <td>0.086107</td>\n",
       "      <td>1.272907</td>\n",
       "      <td>-0.207378</td>\n",
       "      <td>-0.221148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.984914</td>\n",
       "      <td>-0.612455</td>\n",
       "      <td>-0.528700</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  app_day_hour_count  app_device_os_mean  attributed_timediff  channel  \\\n",
       "0    3           -1.355859           -0.083193             0.482835      133   \n",
       "1    3           -1.355859           -0.084415             0.482835      133   \n",
       "\n",
       "   device  hour  ip_app_day_hour_count  ip_app_device_countfromfuture  \\\n",
       "0       1    14              -0.231806                       0.354194   \n",
       "1       1    14              -0.231806                       0.262257   \n",
       "\n",
       "   ip_app_device_countfrompast ...  ip_device_os_lasttimediff  \\\n",
       "0                     -0.21365 ...                   2.718168   \n",
       "1                     -0.21365 ...                   2.711555   \n",
       "\n",
       "   ip_device_os_mean  ip_device_os_time2nextclick  \\\n",
       "0           0.027336                     1.292117   \n",
       "1           0.086107                     1.272907   \n",
       "\n",
       "   ip_device_os_time2previousclick  ip_os_day_hour_count  is_attributed  \\\n",
       "0                        -0.207378             -0.221148            0.0   \n",
       "1                        -0.207378             -0.221148            0.0   \n",
       "\n",
       "   matrixFact_user_ip_item_appdeviceos  \\\n",
       "0                            -0.269234   \n",
       "1                            -0.984914   \n",
       "\n",
       "   matrixFact_user_ipchannel_item_appdeviceos  \\\n",
       "0                                   -0.426699   \n",
       "1                                   -0.612455   \n",
       "\n",
       "   matrixFact_user_iposdeviceapp_item_app  os  \n",
       "0                               -1.119404  13  \n",
       "1                               -0.528700  19  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>app_day_hour_count</th>\n",
       "      <th>app_device_os_mean</th>\n",
       "      <th>attributed_timediff</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ip_app_day_hour_count</th>\n",
       "      <th>ip_app_device_countfromfuture</th>\n",
       "      <th>ip_app_device_countfrompast</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_device_os_lasttimediff</th>\n",
       "      <th>ip_device_os_mean</th>\n",
       "      <th>ip_device_os_time2nextclick</th>\n",
       "      <th>ip_device_os_time2previousclick</th>\n",
       "      <th>ip_os_day_hour_count</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>matrixFact_user_ip_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_ipchannel_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_iposdeviceapp_item_app</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>0.091585</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.215741</td>\n",
       "      <td>-0.197744</td>\n",
       "      <td>-0.192336</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132750</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>-0.205401</td>\n",
       "      <td>-0.205966</td>\n",
       "      <td>-0.217264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521780</td>\n",
       "      <td>0.467860</td>\n",
       "      <td>1.140992</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>-0.0755</td>\n",
       "      <td>-0.343579</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.119355</td>\n",
       "      <td>-0.060634</td>\n",
       "      <td>-0.101353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553337</td>\n",
       "      <td>0.201479</td>\n",
       "      <td>-0.204271</td>\n",
       "      <td>-0.205401</td>\n",
       "      <td>-0.190076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239275</td>\n",
       "      <td>0.255219</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  app_day_hour_count  app_device_os_mean  attributed_timediff  channel  \\\n",
       "0    9            0.790197             -0.0755             0.091585       17   \n",
       "1    9            0.790197             -0.0755            -0.343579      177   \n",
       "\n",
       "   device  hour  ip_app_day_hour_count  ip_app_device_countfromfuture  \\\n",
       "0       1     4              -0.215741                      -0.197744   \n",
       "1       1     4              -0.119355                      -0.060634   \n",
       "\n",
       "   ip_app_device_countfrompast ...  ip_device_os_lasttimediff  \\\n",
       "0                    -0.192336 ...                  -1.132750   \n",
       "1                    -0.101353 ...                   0.553337   \n",
       "\n",
       "   ip_device_os_mean  ip_device_os_time2nextclick  \\\n",
       "0           0.008702                    -0.205401   \n",
       "1           0.201479                    -0.204271   \n",
       "\n",
       "   ip_device_os_time2previousclick  ip_os_day_hour_count  is_attributed  \\\n",
       "0                        -0.205966             -0.217264            NaN   \n",
       "1                        -0.205401             -0.190076            NaN   \n",
       "\n",
       "   matrixFact_user_ip_item_appdeviceos  \\\n",
       "0                             0.521780   \n",
       "1                             0.239275   \n",
       "\n",
       "   matrixFact_user_ipchannel_item_appdeviceos  \\\n",
       "0                                    0.467860   \n",
       "1                                    0.255219   \n",
       "\n",
       "   matrixFact_user_iposdeviceapp_item_app  os  \n",
       "0                                1.140992   3  \n",
       "1                                0.778947   3  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ori_path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "\n",
    "test_ori = pd.read_csv(ori_path+\"test.csv\", dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app_day_hour_count', 'ip_app_device_time2nextclick', 'matrixFact_user_ip_item_appdeviceos', 'ip_app_day_hour_count', 'ip_device_os_time2nextclick', 'attributed_timediff', 'app_device_os_mean', 'ip_app_device_os_lasttimediff', 'ip_app_device_firsttimediff', 'ip_app_device_os_countfromfuture', 'ip_app_device_os_countfrompast', 'ip_app_device_os_time2previousclick', 'matrixFact_user_ipchannel_item_appdeviceos', 'ip_app_os_day_hour_count', 'ip_device_os_countfrompast', 'ip_app_device_countfromfuture', 'ip_device_os_time2previousclick', 'ip_app_device_mean', 'ip_device_os_firsttimediff', 'ip_app_device_os_firsttimediff', 'ip_app_device_countfrompast', 'ip_app_device_os_mean', 'ip_device_os_mean', 'ip_app_device_os_time2nextclick', 'ip_os_day_hour_count', 'ip_app_device_time2previousclick', 'ip_device_os_count', 'ip_device_os_lasttimediff', 'ip_day_hour_count', 'matrixFact_user_iposdeviceapp_item_app', 'ip_device_os_countfromfuture', 'ip_app_device_os_count', 'ip_app_device_lasttimediff'] 33\n"
     ]
    }
   ],
   "source": [
    "embedding_features = ['app','channel','device','os','hour']\n",
    "\n",
    "numeric_features = list(set(set(train.columns) - set(embedding_features)) - set(['is_attributed']))\n",
    "print(numeric_features, len(numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keras_data(dataset):\n",
    "    X = dict((col, np.array(dataset[col])) for col in embedding_features)\n",
    "    X_num =  dict(('num_'+col, np.array(dataset[col])) for col in numeric_features)\n",
    "    X.update(X_num)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((184903890, 39), (18790469, 39))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6089447)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ip_device_os_lasttimediff'].std(), test['ip_device_os_lasttimediff'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Flatten\n",
    "from keras.layers.merge import concatenate, dot, add, multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import SpatialDropout1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/hourdistri.csv', index_col='Unnamed: 0')\n",
    "index = {}\n",
    "for day in ['day7']:#, 'day8','day9']:\n",
    "    index[day] = list(range(df_hour.loc[day,'4start'], df_hour.loc[day,'6end0sec'])) + \\\n",
    "    list(range(df_hour.loc[day,'9start'], df_hour.loc[day,'11end0sec'])) + \\\n",
    "    list(range(df_hour.loc[day,'13start'], df_hour.loc[day,'15end0sec'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forval = train.index.isin(index['day7'])\n",
    "\n",
    "assert np.sum(forval) == 19534560\n",
    "assert len(forval) == 184903890"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "day8start = int(len(train)*1/3)\n",
    "day8start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "day9start = int(len(train)*2/3)\n",
    "day9start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del train_df, y_train, val_df, y_val; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.208416391164064"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof(train)/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-32768, 32767)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo(np.int16).min, np.iinfo(np.int16).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165369330, 165369330)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_keras_data(train[~forval])#[day8start:])#train.iloc[index['day8']+index['day9']])#:(day9len+day8len)])\n",
    "y_train = train[~forval]['is_attributed'].values\n",
    "\n",
    "len(y_train), len(train_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19534560, 19534560)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = get_keras_data(train[forval])#[(day9len+day8len):(day9len+day8len+day7len)])\n",
    "y_val = train[forval]['is_attributed'].values\n",
    "\n",
    "len(y_val), len(val_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = get_keras_data(test)\n",
    "\n",
    "len(test_df), len(test_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_size=50000):\n",
    "        super(Callback, self).__init__()\n",
    "        print('RocAuc evaluating batch size is: {}'.format(batch_size))\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            print('\\non epoch end, start predicting validation set...')\n",
    "            y_pred = self.model.predict(self.X_val, batch_size=self.batch_size,verbose=1)\n",
    "            print('start calculating ROC-AUC...')\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
    "            \n",
    "            \n",
    "import keras\n",
    "class RocAucMetricCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data=(), predict_batch_size=100000, include_on_batch=False):\n",
    "        super(RocAucMetricCallback, self).__init__()\n",
    "        self.predict_batch_size=predict_batch_size\n",
    "        self.include_on_batch=include_on_batch\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.include_on_batch):\n",
    "            logs['roc_auc_val']=float('-inf')\n",
    "            if(self.validation_data):\n",
    "                logs['roc_auc_val']=roc_auc_score(self.y_val,\n",
    "                                              self.model.predict(self.X_val,\n",
    "                                                                 batch_size=self.predict_batch_size))\n",
    "                \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('roc_auc_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('roc_auc_val')\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['roc_auc_val']=float('-inf')\n",
    "#         y_val = self.validation_data[-3]\n",
    "#         val_df = self.validation_data[:-3]\n",
    "        if(self.validation_data):\n",
    "            logs['roc_auc_val']=roc_auc_score(self.y_val,\n",
    "                                              self.model.predict(self.X_val,\n",
    "                                                                 batch_size=self.predict_batch_size))\n",
    "#             logs['roc_auc_val']=roc_auc_score(y_val,#self.validation_data[1], \n",
    "#                                               self.model.predict(val_df,#self.validation_data[0],\n",
    "#                                                                  batch_size=self.predict_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 729, 'channel': 201, 'device': 3798, 'hour': 23, 'os': 855}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dict = dict(train[embedding_features].max())\n",
    "max_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: 5385687\n",
      "Train on 165369330 samples, validate on 19534560 samples\n",
      "Epoch 1/4\n",
      "134600000/165369330 [=======================>......] - ETA: 2:17 - loss: 0.1523 - acc: 0.9854"
     ]
    }
   ],
   "source": [
    "#embids = embedding_features#['app', 'channel', 'device', 'os', 'hour', 'day', 'wday', 'qty', 'ip_app_count', 'ip_app_os_count']\n",
    "# get the max of each code type\n",
    "embmaxs = dict((col, max_dict[col]+1) for col in embedding_features)\n",
    "\n",
    "emb_n = 50\n",
    "\n",
    "# Build the inputs, embeddings and concatenate them all for each column\n",
    "emb_inputs = dict((col, Input(shape=[1], name = col))  for col in embedding_features)\n",
    "emb_model  = dict((col, Embedding(embmaxs[col], emb_n)(emb_inputs[col])) for col in embedding_features)\n",
    "\n",
    "fe = concatenate([(emb_) for emb_ in emb_model.values()])\n",
    "\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "\n",
    "conv = Conv1D(100, kernel_size=4, strides=1, padding='same')(s_dout)\n",
    "\n",
    "num_inputs = dict((col, Input(shape=[1], name = 'num_'+col))  for col in numeric_features)\n",
    "\n",
    "num_fe = concatenate([(num_) for num_ in num_inputs.values()])\n",
    "\n",
    "concat = concatenate([Flatten()(s_dout), Flatten()(conv), (num_fe)])\n",
    "\n",
    "dense_n = 1000\n",
    "\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(concat))\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[inp for inp in emb_inputs.values()] + [inp for inp in num_inputs.values()], outputs=outp)\n",
    "#model = Model(inputs=[inp for inp in emb_inputs.values()], outputs=outp)\n",
    "\n",
    "batch_size = 200000\n",
    "epochs = 4\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(list(train_df)[0]) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.002, 0.0002\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.002, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# earlystopping = EarlyStopping(monitor='val_loss', mode=\"min\", patience=8)\n",
    "# rocauc = RocAucEvaluation(validation_data=(val_df, y_val), interval=1, batch_size=pred_batch_size)\n",
    "\n",
    "import time\n",
    "tempid = str(int(time.time()))[3:]\n",
    "print('Model ID: ' + tempid) \n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "pred_batch_size = 100000\n",
    "model_save_path = 'NN_MODELS/NN_data{}_batchsize{}_ep{}_{}.hdf5'.format(len(y_train), batch_size, epochs, tempid)\n",
    "\n",
    "cb = [\n",
    "    RocAucMetricCallback(validation_data=(val_df, y_val)), # include it before EarlyStopping!\n",
    "    EarlyStopping(monitor='roc_auc_val',mode='max',patience=4, verbose=2),\n",
    "    ModelCheckpoint(model_save_path, monitor='roc_auc_val', verbose=1, save_best_only=True, mode='max'),\n",
    "#     RocAucEvaluation(validation_data=(val_df, y_val), interval=1, batch_size=pred_batch_size)\n",
    "]\n",
    "\n",
    "class_weight = {0:1,1:99}\n",
    "\n",
    "model.fit(train_df, y_train, batch_size=batch_size, epochs=epochs, \n",
    "          validation_data=(val_df, y_val), \n",
    "#           validation_split = 0.5,\n",
    "          class_weight=class_weight,\n",
    "          shuffle=True, verbose=1, callbacks=cb)#[rocauc, earlystopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('NN_batchsize200000_ep8_5308912.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19534560/19534560 [==============================] - 42s 2us/step\n"
     ]
    }
   ],
   "source": [
    "val_pred_savedmodel = model.predict(val_df, batch_size=pred_batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817132065702936"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_pred_fullmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818143556926712"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_pred_savedmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting....\n",
      "18790469/18790469 [==============================] - 41s 2us/step\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_ori['click_id'].astype('int')\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=pred_batch_size, verbose=1)\n",
    "\n",
    "flag = 'saved'\n",
    "sub.to_csv('nn_{}.csv.gz'.format(flag, tempid), index=False, float_format='%.9f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model predict val\n",
    "# model predict test\n",
    "\n",
    "# THEN load saved model \n",
    "# model predict val\n",
    "# model predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788076360576548"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val_1, val_pred_1) # 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761119662504989"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val_1, val_pred_1) # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_inputs = []\n",
    "embedding_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dim = 50\n",
    "for i in range(len(embedding_features)):\n",
    "    tmp_input = Input(shape=(1,), dtype='int32', name=embedding_features[i]+'_input')\n",
    "    tmp_embeddings = Embedding(int(train_embeddings[i].max()+1),output_dim,name=embedding_features[i]+'_embeddings')(tmp_input)\n",
    "    tmp_embeddings = Flatten(name=embedding_features[i]+'_flatten')(tmp_embeddings)\n",
    "    \n",
    "    embedding_inputs.append(tmp_input)\n",
    "    embedding_outputs.append(tmp_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_outputs.append(number_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile = concatenate(embedding_outputs, name='profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'profile/concat:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FunctionalDense(n, x, batchnorm=False, act='relu', lw1=0.0, dropout=0, name=''):\n",
    "    if lw1 == 0.0:\n",
    "        x = Dense(n, name=name+'_dense')(x)\n",
    "    else:\n",
    "        x = Dense(n, kernel_regularizer=l1(lw1), name=name+'_dense')(x)\n",
    "    \n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(name=name+'_batchnorm')(x)\n",
    "        \n",
    "    if act in {'relu', 'tanh', 'sigmoid'}:\n",
    "        x = Activation(act, name=name+'_activation')(x)\n",
    "    elif act =='prelu':\n",
    "        x = PReLU(name=name+'_activation')(x)\n",
    "    elif act == 'leakyrelu':\n",
    "        x = LeakyReLU(name=name+'_activation')(x)\n",
    "    elif act == 'elu':\n",
    "        x = ELU(name=name+'_activation')(x)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout, name=name+'_dropout')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile_embedddings = FunctionalDense(100, profile, batchnorm=True, dropout=0.2, name='profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
