{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/kai/data/resources/wordbatch-133/')\n",
    "sys.path.insert(0, '/home/kai/data/resources/randomstate-dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordbatch\n",
    "\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL\n",
    "from wordbatch.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordbatch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "\tt0 = time.time()\n",
    "\tyield\n",
    "\tprint(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "import os, psutil\n",
    "def cpuStats():\n",
    "\tpid = os.getpid()\n",
    "\tpy = psutil.Process(pid)\n",
    "\tmemoryUse = py.memory_info()[0] / 2. ** 30\n",
    "\tprint('memory GB:', memoryUse)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mean_auc= 0\n",
    "\n",
    "def fit_batch(clf, X, y, w):  clf.partial_fit(X, y, sample_weight=w)\n",
    "\n",
    "def predict_batch(clf, X):  return clf.predict(X)\n",
    "\n",
    "def evaluate_batch(clf, X, y, rcount):\n",
    "\tauc= roc_auc_score(y, predict_batch(clf, X))\n",
    "\tglobal mean_auc\n",
    "\tif mean_auc==0:\n",
    "\t\tmean_auc= auc\n",
    "\telse: mean_auc= 0.2*(mean_auc*4 + auc)\n",
    "\tprint(rcount, \"ROC AUC:\", auc, \"Running Mean:\", mean_auc)\n",
    "\treturn auc\n",
    "\n",
    "def df_add_counts(df, cols, tag=\"_count\"):\n",
    "\tarr_slice = df[cols].values\n",
    "\tunq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1),\n",
    "\t\t\t\t\t\t\t\t\t return_inverse=True, return_counts=True)\n",
    "\tdf[\"_\".join(cols)+tag] = counts[unqtags]\n",
    "\treturn df\n",
    "\n",
    "def df_add_uniques(df, cols, tag=\"_unique\"):\n",
    "\tgp = df[cols].groupby(by=cols[0:len(cols) - 1])[cols[len(cols) - 1]].nunique().reset_index(). \\\n",
    "\t\trename(index=str, columns={cols[len(cols) - 1]: \"_\".join(cols)+tag})\n",
    "\tdf= df.merge(gp, on=cols[0:len(cols) - 1], how='left')\n",
    "\treturn df\n",
    "\n",
    "def df2csr(wb, df, pick_hours=None):\n",
    "\tdf.reset_index(drop=True, inplace=True)\n",
    "\twith timer(\"Adding counts\"):\n",
    "\t\tdf['click_time']= pd.to_datetime(df['click_time'])\n",
    "\t\tdt= df['click_time'].dt\n",
    "\t\tdf['day'] = dt.day.astype('uint8')\n",
    "\t\tdf['hour'] = dt.hour.astype('uint8')\n",
    "\t\tdel(dt)\n",
    "\t\tdf= df_add_counts(df, ['ip', 'day', 'hour'])\n",
    "\t\tdf= df_add_counts(df, ['ip', 'app'])\n",
    "\t\tdf= df_add_counts(df, ['ip', 'app', 'os'])\n",
    "\t\tdf= df_add_counts(df, ['ip', 'device'])\n",
    "\t\tdf= df_add_counts(df, ['app', 'channel'])\n",
    "\t\tdf= df_add_uniques(df, ['ip', 'channel'])\n",
    "\n",
    "\twith timer(\"Adding next click times\"):\n",
    "\t\tD= 2**26\n",
    "\t\tdf['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "\t\t\t\t\t\t + \"_\" + df['os'].astype(str)).apply(hash) % D\n",
    "\t\tclick_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "\t\tdf['epochtime']= df['click_time'].astype(np.int64) // 10 ** 9\n",
    "\t\tnext_clicks= []\n",
    "\t\tfor category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n",
    "\t\t\tnext_clicks.append(click_buffer[category]-time)\n",
    "\t\t\tclick_buffer[category]= time\n",
    "\t\tdel(click_buffer)\n",
    "\t\tdf['next_click']= list(reversed(next_clicks))\n",
    "\n",
    "\twith timer(\"Log-binning features\"):\n",
    "\t\tfor fea in ['ip_day_hour_count','ip_app_count','ip_app_os_count','ip_device_count',\n",
    "\t\t\t\t'app_channel_count','next_click','ip_channel_unique']: \n",
    "\t\t\t\t    df[fea]= np.log2(1 + df[fea].values).astype(int)\n",
    "\n",
    "\twith timer(\"Generating str_array\"):\n",
    "\t\tstr_array= (\"I\" + df['ip'].astype(str) \\\n",
    "\t\t\t+ \" A\" + df['app'].astype(str) \\\n",
    "\t\t\t+ \" D\" + df['device'].astype(str) \\\n",
    "\t\t\t+ \" O\" + df['os'].astype(str) \\\n",
    "\t\t\t+ \" C\" + df['channel'].astype(str) \\\n",
    "\t\t\t+ \" WD\" + df['day'].astype(str) \\\n",
    "\t\t\t+ \" H\" + df['hour'].astype(str) \\\n",
    "\t\t\t+ \" AXC\" + df['app'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "\t\t\t+ \" OXC\" + df['os'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "\t\t\t+ \" AXD\" + df['app'].astype(str)+\"_\"+df['device'].astype(str) \\\n",
    "\t\t\t+ \" IXA\" + df['ip'].astype(str)+\"_\"+df['app'].astype(str) \\\n",
    "\t\t\t+ \" AXO\" + df['app'].astype(str)+\"_\"+df['os'].astype(str) \\\n",
    "\t\t\t+ \" IDHC\" + df['ip_day_hour_count'].astype(str) \\\n",
    "\t\t\t+ \" IAC\" + df['ip_app_count'].astype(str) \\\n",
    "\t\t\t+ \" AOC\" + df['ip_app_os_count'].astype(str) \\\n",
    "\t\t\t+ \" IDC\" + df['ip_device_count'].astype(str) \\\n",
    "\t\t\t+ \" AC\" + df['app_channel_count'].astype(str) \\\n",
    "\t\t\t+ \" NC\" + df['next_click'].astype(str) \\\n",
    "\t\t\t+ \" ICU\" + df['ip_channel_unique'].astype(str)\n",
    "\t\t  ).values\n",
    "\t#cpuStats()\n",
    "\tif 'is_attributed' in df.columns:\n",
    "\t\tlabels = df['is_attributed'].values\n",
    "\t\tweights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values],\n",
    "\t\t\t\t\t\t\t  df['hour'].apply(lambda x: 1.0 if x in pick_hours else 0.5))\n",
    "\telse:\n",
    "\t\tlabels = []\n",
    "\t\tweights = []\n",
    "\treturn str_array, labels, weights\n",
    "\n",
    "class ThreadWithReturnValue(threading.Thread):\n",
    "\tdef __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "\t\tthreading.Thread.__init__(self, group, target, name, args, kwargs, daemon=daemon)\n",
    "\t\tself._return = None\n",
    "\tdef run(self):\n",
    "\t\tif self._target is not None:\n",
    "\t\t\tself._return = self._target(*self._args, **self._kwargs)\n",
    "\tdef join(self):\n",
    "\t\tthreading.Thread.join(self)\n",
    "\t\treturn self._return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 10000000\n",
    "D = 2 ** 20\n",
    "\n",
    "wb = wordbatch.WordBatch(None, extractor=(WordHash, {\"ngram_range\": (1, 1), \"analyzer\": \"word\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t \"lowercase\": False, \"n_features\": D,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t \"norm\": None, \"binary\": True})\n",
    "\t\t\t\t\t\t , minibatch_size=batchsize // 80, procs=8, freeze=True, timeout=1800, verbose=0)\n",
    "clf = FM_FTRL(alpha=0.05, beta=0.1, L1=0.0, L2=0.0, D=D, alpha_fm=0.02, L2_fm=0.0, init_fm=0.01, weight_fm=1.0,\n",
    "\t\t\t  D_fm=8, e_noise=0.0, iters=2, inv_link=\"sigmoid\", e_clip=1.0, threads=4, use_avx=1, verbose=0)\n",
    "\n",
    "dtypes = {\n",
    "\t\t'ip'            : 'uint32',\n",
    "\t\t'app'           : 'uint16',\n",
    "\t\t'device'        : 'uint16',\n",
    "\t\t'os'            : 'uint16',\n",
    "\t\t'channel'       : 'uint16',\n",
    "\t\t'is_attributed' : 'uint8',\n",
    "\t\t}\n",
    "\n",
    "p = None\n",
    "rcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adding counts] done in 21 s\n",
      "[Adding next click times] done in 80 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 360 s\n",
      "Training 10000000 646.5228700637817\n",
      "memory GB: 4.920658111572266\n",
      "[Adding counts] done in 18 s\n",
      "[Adding next click times] done in 82 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 357 s\n",
      "Training 20000000 1309.398225069046\n",
      "memory GB: 7.0925140380859375\n",
      "20000000 ROC AUC: 0.977721070697 Running Mean: 0.977721070697\n",
      "[Adding counts] done in 19 s\n",
      "[Adding next click times] done in 84 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 366 s\n",
      "Training 30000000 2029.4362316131592\n",
      "memory GB: 3.6196823120117188\n",
      "[Adding counts] done in 21 s\n",
      "[Adding next click times] done in 84 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 364 s\n",
      "Training 40000000 2704.4555995464325\n",
      "memory GB: 6.0625457763671875\n",
      "40000000 ROC AUC: 0.980770906072 Running Mean: 0.978331037772\n",
      "[Adding counts] done in 19 s\n",
      "[Adding next click times] done in 82 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 366 s\n",
      "Training 50000000 3416.7914440631866\n",
      "memory GB: 6.836723327636719\n",
      "[Adding counts] done in 20 s\n",
      "[Adding next click times] done in 82 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 361 s\n",
      "Training 60000000 4081.7120048999786\n",
      "memory GB: 6.393222808837891\n",
      "60000000 ROC AUC: 0.97126196096 Running Mean: 0.97691722241\n",
      "[Adding counts] done in 19 s\n",
      "[Adding next click times] done in 84 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 360 s\n",
      "Training 70000000 4809.056674480438\n",
      "memory GB: 4.933551788330078\n",
      "[Adding counts] done in 21 s\n",
      "[Adding next click times] done in 82 s\n",
      "[Log-binning features] done in 3 s\n",
      "[Generating str_array] done in 356 s\n",
      "Training 80000000 5510.3574941158295\n",
      "memory GB: 6.9861907958984375\n",
      "80000000 ROC AUC: 0.983359363938 Running Mean: 0.978205650715\n",
      "[Adding counts] done in 17 s\n",
      "[Adding next click times] done in 79 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 340 s\n",
      "Training 90000000 6126.758071899414\n",
      "memory GB: 4.961833953857422\n",
      "[Adding counts] done in 17 s\n",
      "[Adding next click times] done in 81 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 344 s\n",
      "Training 100000000 6762.9041295051575\n",
      "memory GB: 6.608757019042969\n",
      "100000000 ROC AUC: 0.981873676494 Running Mean: 0.978939255871\n",
      "[Adding counts] done in 17 s\n",
      "[Adding next click times] done in 78 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 334 s\n",
      "Training 110000000 7427.294897079468\n",
      "memory GB: 7.010784149169922\n",
      "[Adding counts] done in 19 s\n",
      "[Adding next click times] done in 80 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 345 s\n",
      "Training 120000000 8063.005665063858\n",
      "memory GB: 5.056007385253906\n",
      "120000000 ROC AUC: 0.98208070951 Running Mean: 0.979567546599\n",
      "[Adding counts] done in 3 s\n",
      "[Adding next click times] done in 21 s\n",
      "[Log-binning features] done in 0 s\n",
      "[Generating str_array] done in 84 s\n",
      "Training 130000000 8389.774982452393\n",
      "memory GB: 3.6314048767089844\n"
     ]
    }
   ],
   "source": [
    "for df_c in pd.read_csv('/home/kai/data/kaggle/talkingdata/data/train.csv', engine='c', chunksize=batchsize,\n",
    "#for df_c in pd.read_csv('../input/train.csv', engine='c', chunksize=batchsize, \n",
    "\t\t\t\t\t\tskiprows= range(1,9308569), sep=\",\", dtype=dtypes):\n",
    "\trcount += batchsize\n",
    "\tif rcount== 130000000:\n",
    "\t\tdf_c['click_time'] = pd.to_datetime(df_c['click_time'])\n",
    "\t\tdf_c['day'] = df_c['click_time'].dt.day.astype('uint8')\n",
    "\t\tdf_c= df_c[df_c['day']==8]\n",
    "\tstr_array, labels, weights= df2csr(wb, df_c, pick_hours={4, 5, 10, 13, 14})\n",
    "\tdel(df_c)\n",
    "\tif p != None:\n",
    "\t\tp.join()\n",
    "\t\tdel(X)\n",
    "\tgc.collect()\n",
    "\tX= wb.transform(str_array)\n",
    "\tdel(str_array)\n",
    "\tif rcount % (2 * batchsize) == 0:\n",
    "\t\tif p != None:  p.join()\n",
    "\t\tp = threading.Thread(target=evaluate_batch, args=(clf, X, labels, rcount))\n",
    "\t\tp.start()\n",
    "\tprint(\"Training\", rcount, time.time() - start_time)\n",
    "\tcpuStats()\n",
    "\tif p != None:  p.join()\n",
    "\tp = threading.Thread(target=fit_batch, args=(clf, X, labels, weights))\n",
    "\tp.start()\n",
    "\tif rcount == 130000000:  break\n",
    "if p != None:  p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adding counts] done in 17 s\n",
      "[Adding next click times] done in 80 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 338 s\n",
      "[Adding counts] done in 17 s\n",
      "[Adding next click times] done in 71 s\n",
      "[Log-binning features] done in 1 s\n",
      "[Generating str_array] done in 303 s\n"
     ]
    }
   ],
   "source": [
    "del(X)\n",
    "p = None\n",
    "click_ids= []\n",
    "test_preds = []\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv', engine='c', chunksize=batchsize,\n",
    "#for df_c in pd.read_csv('../input/test.csv', engine='c', chunksize=batchsize,\n",
    "\t\t\t\t\t\tsep=\",\", dtype=dtypes):\n",
    "\trcount += batchsize\n",
    "\tif rcount % (10 * batchsize) == 0:\n",
    "\t\tprint(rcount)\n",
    "\tstr_array, labels, weights = df2csr(wb, df_c)\n",
    "\tclick_ids+= df_c['click_id'].tolist()\n",
    "\tdel(df_c)\n",
    "\tif p != None:\n",
    "\t\ttest_preds += list(p.join())\n",
    "\t\tdel (X)\n",
    "\tgc.collect()\n",
    "\tX = wb.transform(str_array)\n",
    "\tdel (str_array)\n",
    "\tp = ThreadWithReturnValue(target=predict_batch, args=(clf, X))\n",
    "\tp.start()\n",
    "if p != None:  test_preds += list(p.join())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4525246'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENO = str(int(time.time()))[3:]\n",
    "FILENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\"click_id\": click_ids, 'is_attributed': test_preds})\n",
    "df_sub.to_csv(\"wordbatch_fm_ftrl_%s.csv.gz\"%FILENO,  index=False, float_format='%.9f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18790464</th>\n",
       "      <td>18790464</td>\n",
       "      <td>0.009473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790465</th>\n",
       "      <td>18790465</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790466</th>\n",
       "      <td>18790467</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790467</th>\n",
       "      <td>18790466</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790468</th>\n",
       "      <td>18790468</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          click_id  is_attributed\n",
       "18790464  18790464       0.009473\n",
       "18790465  18790465       0.000003\n",
       "18790466  18790467       0.000807\n",
       "18790467  18790466       0.000642\n",
       "18790468  18790468       0.000002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
