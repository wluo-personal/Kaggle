{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'hour'          : 'uint8',\n",
    "        'is_attributed' : 'uint8', \n",
    "        'ip_day_hour_count': 'uint32', \n",
    "        'ip_os_day_hour_count': 'uint32', \n",
    "        'ip_app_day_hour_count': 'uint32', \n",
    "        'ip_app_os_day_hour_count': 'uint32', \n",
    "        'app_day_hour_count': 'uint32', \n",
    "        'ip_device_os_count': 'uint32', \n",
    "        'ip_app_device_os_count': 'uint32', \n",
    "        'ip_device_os_mean': 'float16',\n",
    "        'ip_app_device_os_mean': 'float16',\n",
    "        'ip_app_device_mean': 'float16',\n",
    "        'app_device_os_mean': 'float16',\n",
    "        'ip_device_os_time2nextclick': 'int32',\n",
    "        'ip_app_device_os_time2nextclick': 'int32',\n",
    "        'ip_app_device_time2nextclick': 'int32',\n",
    "        'ip_device_os_time2previousclick': 'int32',\n",
    "        'ip_app_device_os_time2previousclick': 'int32',\n",
    "        'ip_app_device_time2previousclick': 'int32',\n",
    "        'ip_device_os_countfromfuture': 'uint32', \n",
    "        'ip_app_device_os_countfromfuture': 'uint32', \n",
    "        'ip_app_device_countfromfuture': 'uint32', \n",
    "        'ip_device_os_countfrompast': 'uint32', \n",
    "        'ip_app_device_os_countfrompast': 'uint32', \n",
    "        'ip_app_device_countfrompast': 'uint32', \n",
    "        'ip_device_os_lasttimediff': 'int32',\n",
    "        'ip_app_device_os_lasttimediff': 'int32',\n",
    "        'ip_app_device_lasttimediff': 'int32',\n",
    "        'ip_device_os_firsttimediff': 'int32',\n",
    "        'ip_app_device_os_firsttimediff': 'int32',\n",
    "        'ip_app_device_firsttimediff': 'int32',\n",
    "        'matrixFact_user_iposdeviceapp_item_app': 'float64',#'float16',\n",
    "        'matrixFact_user_ip_item_appdeviceos': 'float64',\n",
    "        'matrixFact_user_ipchannel_item_appdeviceos': 'float64',\n",
    "        'ip_device_os_regression': 'float64',\n",
    "        'ip_app_device_os_regression': 'float64',\n",
    "        'ip_app_device_regression': 'float64',\n",
    "        'ip_app_device_os_channel_regression': 'float64'\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load day9 done!\n",
      "load day8 done!\n",
      "load day7 done!\n"
     ]
    }
   ],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/'\n",
    "file_format = '{}_equalhour_supplementV1.csv'\n",
    "# ALL_features_supplementV3_feature42.csv\n",
    "# test_features_supplementV3_feature42.csv\n",
    "\n",
    "#day7 = pd.read_csv(load_path+file_format.format('day7'),dtype=dtypes)\n",
    "#print('load day7 done!')\n",
    "day9 = pd.read_csv(load_path+file_format.format('day9'),dtype=dtypes)\n",
    "print('load day9 done!')\n",
    "day8 = pd.read_csv(load_path+file_format.format('day8'),dtype=dtypes)\n",
    "print('load day8 done!')\n",
    "day7 = pd.read_csv(load_path+file_format.format('day7'),dtype=dtypes)\n",
    "print('load day7 done!')\n",
    "day10_test = pd.read_csv(load_path+file_format.format('test'),dtype=dtypes)\n",
    "print('load day10_test done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/wl/data/equalhour/'\n",
    "alltrain = pd.read_csv(load_path+'ALL_features_supplementV3_feature42.csv', dtype=dtypes)\n",
    "print('load all train done!')\n",
    "#test_features_supplementV3_feature42.csv\n",
    "#day10_test = pd.read_csv(load_path+'test_equalhour_supplementV1.csv',dtype=dtypes)\n",
    "#print('load day10_test done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ori_path = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "\n",
    "test_ori = pd.read_csv(ori_path+\"test.csv\", dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df; \n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20898422, 49), (20446743, 49), (19534560, 49), (18790469, 48))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day9.shape, day8.shape, day7.shape, day10_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day9len = 20898422\n",
    "day8len = 20446743\n",
    "day7len = 19534560\n",
    "day10_testlen = 18790469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = day9.append(day8)\n",
    "train_df = train_df.append(day7)\n",
    "train_df = train_df.append(day10_test)\n",
    "\n",
    "del day9, day8, day7, day10_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app_day_hour_countself', 'ip_app_day_hour_countself', 'ip_app_device_os_channel_regression', 'ip_app_device_os_countself', 'ip_app_device_os_regression', 'ip_app_device_regression', 'ip_app_os_day_hour_countself', 'ip_day_hour_countself', 'ip_device_os_countself', 'ip_device_os_regression', 'ip_os_day_hour_countself']\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [col for col in train_df.columns if 'countself' in col or 'regression' in col]\n",
    "print(drop_cols)\n",
    "\n",
    "train_df.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_cols = [col for col in train_df.columns if '_mean' in col]\n",
    "\n",
    "print(mean_cols)\n",
    "\n",
    "for col in mean_cols:\n",
    "    train_df[col] = train_df[col].apply(lambda x: 1000*(x+0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79670194, 49)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app 12.051646278155166\n",
      "app_day_hour_count 317948.8327729941\n",
      "app_day_hour_countself 331807.1676141277\n",
      "app_device_os_mean 22.817935043641945\n",
      "channel 268.5154238484721\n",
      "device 16.67861386154024\n",
      "hour 9.130806258611596\n",
      "ip_app_day_hour_count 122.49097051276165\n",
      "ip_app_day_hour_countself 127.3686383767338\n",
      "ip_app_device_countfromfuture 486.44615839645127\n",
      "ip_app_device_countfrompast 899.1860877858537\n",
      "ip_app_device_firsttimediff 56106.48533563255\n",
      "ip_app_device_lasttimediff 20271.962059223806\n",
      "ip_app_device_mean 20.048032130209904\n",
      "ip_app_device_os_channel_regression 0.16028655163786176\n",
      "ip_app_device_os_count 612.4232526407554\n",
      "ip_app_device_os_countfromfuture 59.714352634813466\n",
      "ip_app_device_os_countfrompast 111.09855112189133\n",
      "ip_app_device_os_countself 176.3862600726268\n",
      "ip_app_device_os_firsttimediff 36341.098738883455\n",
      "ip_app_device_os_lasttimediff 12919.837145432331\n",
      "ip_app_device_os_mean 18.826975531738217\n",
      "ip_app_device_os_regression 0.2965852969088752\n",
      "ip_app_device_os_time2nextclick 1939.6723312484967\n",
      "ip_app_device_os_time2previousclick 3626.556356948246\n",
      "ip_app_device_regression 0.10856570648642229\n",
      "ip_app_device_time2nextclick 832.428191777718\n",
      "ip_app_device_time2previousclick 1166.5153663363742\n",
      "ip_app_os_day_hour_count 17.10234832615068\n",
      "ip_app_os_day_hour_countself 17.775780968130196\n",
      "ip_day_hour_count 1171.1301798888553\n",
      "ip_day_hour_countself 1182.6648978949888\n",
      "ip_device_os_count 5837.693530205286\n",
      "ip_device_os_countfromfuture 539.1255856989629\n",
      "ip_device_os_countfrompast 1007.3954245925396\n",
      "ip_device_os_countself 1562.049825570007\n",
      "ip_device_os_firsttimediff 48959.91208239056\n",
      "ip_device_os_lasttimediff 17566.01825869785\n",
      "ip_device_os_mean 20.013992561161686\n",
      "ip_device_os_regression 0.1633866954319845\n",
      "ip_device_os_time2nextclick 521.3551888928499\n",
      "ip_device_os_time2previousclick 839.5710677822625\n",
      "ip_os_day_hour_count 136.90445679095498\n",
      "ip_os_day_hour_countself 140.22627051945454\n",
      "is_attributed 0.0025018181340339496\n",
      "matrixFact_user_ip_item_appdeviceos -8.077890522385259\n",
      "matrixFact_user_ipchannel_item_appdeviceos -7.980067501686275\n",
      "matrixFact_user_iposdeviceapp_item_app -8.570056845666315\n",
      "os 21.712111746583673\n"
     ]
    }
   ],
   "source": [
    "for col in train_df.columns:\n",
    "    print(col, train_df[col].mean())#, train_df[col].std(), train_df[col].min(), train_df[col].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.429955707862973"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train_df)/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>app_day_hour_count</th>\n",
       "      <th>app_device_os_mean</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ip_app_day_hour_count</th>\n",
       "      <th>ip_app_device_countfromfuture</th>\n",
       "      <th>ip_app_device_countfrompast</th>\n",
       "      <th>ip_app_device_firsttimediff</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_device_os_lasttimediff</th>\n",
       "      <th>ip_device_os_mean</th>\n",
       "      <th>ip_device_os_time2nextclick</th>\n",
       "      <th>ip_device_os_time2previousclick</th>\n",
       "      <th>ip_os_day_hour_count</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>matrixFact_user_ip_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_ipchannel_item_appdeviceos</th>\n",
       "      <th>matrixFact_user_iposdeviceapp_item_app</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18790464</th>\n",
       "      <td>9</td>\n",
       "      <td>498766</td>\n",
       "      <td>21.387596</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>82498</td>\n",
       "      <td>...</td>\n",
       "      <td>420</td>\n",
       "      <td>30.749817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.629337</td>\n",
       "      <td>-5.651320</td>\n",
       "      <td>-5.672787</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790465</th>\n",
       "      <td>23</td>\n",
       "      <td>41818</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>82565</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.987357</td>\n",
       "      <td>-8.566782</td>\n",
       "      <td>-10.731715</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790466</th>\n",
       "      <td>18</td>\n",
       "      <td>274350</td>\n",
       "      <td>20.478268</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>448</td>\n",
       "      <td>81965</td>\n",
       "      <td>...</td>\n",
       "      <td>1611</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.892519</td>\n",
       "      <td>-8.240774</td>\n",
       "      <td>-8.256477</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790467</th>\n",
       "      <td>27</td>\n",
       "      <td>20183</td>\n",
       "      <td>20.479221</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53879</td>\n",
       "      <td>...</td>\n",
       "      <td>3553</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1380</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.022797</td>\n",
       "      <td>-7.136669</td>\n",
       "      <td>-9.291574</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790468</th>\n",
       "      <td>12</td>\n",
       "      <td>338304</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3075</td>\n",
       "      <td>594</td>\n",
       "      <td>10313</td>\n",
       "      <td>82797</td>\n",
       "      <td>...</td>\n",
       "      <td>3359</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>564</td>\n",
       "      <td>141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.841059</td>\n",
       "      <td>-9.271717</td>\n",
       "      <td>-9.500175</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          app  app_day_hour_count  app_device_os_mean  channel  device  hour  \\\n",
       "18790464    9              498766           21.387596      127       1    15   \n",
       "18790465   23               41818           20.000000      153       1    15   \n",
       "18790466   18              274350           20.478268      265       1    15   \n",
       "18790467   27               20183           20.479221      122       1    15   \n",
       "18790468   12              338304           20.000000      265       2    15   \n",
       "\n",
       "          ip_app_day_hour_count  ip_app_device_countfromfuture  \\\n",
       "18790464                      3                              2   \n",
       "18790465                      5                              4   \n",
       "18790466                      6                              4   \n",
       "18790467                      1                              0   \n",
       "18790468                   3075                            594   \n",
       "\n",
       "          ip_app_device_countfrompast  ip_app_device_firsttimediff ...  \\\n",
       "18790464                           48                        82498 ...   \n",
       "18790465                           90                        82565 ...   \n",
       "18790466                          448                        81965 ...   \n",
       "18790467                            1                        53879 ...   \n",
       "18790468                        10313                        82797 ...   \n",
       "\n",
       "          ip_device_os_lasttimediff  ip_device_os_mean  \\\n",
       "18790464                        420          30.749817   \n",
       "18790465                         25          20.000000   \n",
       "18790466                       1611          20.000000   \n",
       "18790467                       3553          20.000000   \n",
       "18790468                       3359          20.000000   \n",
       "\n",
       "          ip_device_os_time2nextclick  ip_device_os_time2previousclick  \\\n",
       "18790464                            0                                0   \n",
       "18790465                            5                                4   \n",
       "18790466                           12                                0   \n",
       "18790467                         1380                                1   \n",
       "18790468                           61                              564   \n",
       "\n",
       "          ip_os_day_hour_count  is_attributed  \\\n",
       "18790464                    12            NaN   \n",
       "18790465                     7            NaN   \n",
       "18790466                    13            NaN   \n",
       "18790467                     9            NaN   \n",
       "18790468                   141            NaN   \n",
       "\n",
       "          matrixFact_user_ip_item_appdeviceos  \\\n",
       "18790464                            -5.629337   \n",
       "18790465                            -8.987357   \n",
       "18790466                            -7.892519   \n",
       "18790467                            -7.022797   \n",
       "18790468                           -10.841059   \n",
       "\n",
       "          matrixFact_user_ipchannel_item_appdeviceos  \\\n",
       "18790464                                   -5.651320   \n",
       "18790465                                   -8.566782   \n",
       "18790466                                   -8.240774   \n",
       "18790467                                   -7.136669   \n",
       "18790468                                   -9.271717   \n",
       "\n",
       "          matrixFact_user_iposdeviceapp_item_app  os  \n",
       "18790464                               -5.672787  13  \n",
       "18790465                              -10.731715  37  \n",
       "18790466                               -8.256477  17  \n",
       "18790467                               -9.291574  13  \n",
       "18790468                               -9.500175  27  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_features = ['app','channel','device','os','hour']\n",
    "\n",
    "number_features = list(set(set(train_df.columns) - set(embedding_features)) - set(['is_attributed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_df[embedding_features] = train_df[embedding_features].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_dict = dict(train_df[embedding_features].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 600, 'channel': 192, 'device': 2985, 'hour': 8, 'os': 586}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in train.columns:\n",
    "    nan_amount = len(np.argwhere(np.isnan(day8[col])))\n",
    "    if nan_amount != 0:\n",
    "        print('train', col, nan_amount)\n",
    "    nan_amount = len(np.argwhere(np.isnan(day9[col])))\n",
    "    if nan_amount != 0:\n",
    "        print('test', col, nan_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number_features.remove('app_device_os_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(number_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79670194"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>app_day_hour_count</th>\n",
       "      <th>app_device_os_mean</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ip_app_day_hour_count</th>\n",
       "      <th>ip_app_device_countfromfuture</th>\n",
       "      <th>ip_app_device_countfrompast</th>\n",
       "      <th>ip_app_device_firsttimediff</th>\n",
       "      <th>...</th>\n",
       "      <th>ss_ip_app_device_os_lasttimediff</th>\n",
       "      <th>ss_matrixFact_user_ipchannel_item_appdeviceos</th>\n",
       "      <th>ss_ip_os_day_hour_count</th>\n",
       "      <th>ss_ip_device_os_count</th>\n",
       "      <th>ss_ip_app_device_os_count</th>\n",
       "      <th>ss_app_device_os_mean</th>\n",
       "      <th>ss_matrixFact_user_ip_item_appdeviceos</th>\n",
       "      <th>ss_app_day_hour_count</th>\n",
       "      <th>ss_ip_app_device_time2previousclick</th>\n",
       "      <th>ss_ip_app_device_firsttimediff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>475489</td>\n",
       "      <td>20.469208</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>43077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946795</td>\n",
       "      <td>0.455693</td>\n",
       "      <td>-0.217598</td>\n",
       "      <td>-0.203043</td>\n",
       "      <td>-0.179866</td>\n",
       "      <td>-0.080696</td>\n",
       "      <td>0.510935</td>\n",
       "      <td>0.635208</td>\n",
       "      <td>-0.282290</td>\n",
       "      <td>-0.641153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>475489</td>\n",
       "      <td>20.469208</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>481</td>\n",
       "      <td>353</td>\n",
       "      <td>43196</td>\n",
       "      <td>...</td>\n",
       "      <td>2.085028</td>\n",
       "      <td>0.244434</td>\n",
       "      <td>-0.195399</td>\n",
       "      <td>-0.187311</td>\n",
       "      <td>-0.171692</td>\n",
       "      <td>-0.080696</td>\n",
       "      <td>0.230121</td>\n",
       "      <td>0.635208</td>\n",
       "      <td>-0.277549</td>\n",
       "      <td>-0.635241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  app_day_hour_count  app_device_os_mean  channel  device  hour  \\\n",
       "0    9              475489           20.469208       17       1     0   \n",
       "1    9              475489           20.469208      170       1     0   \n",
       "\n",
       "   ip_app_day_hour_count  ip_app_device_countfromfuture  \\\n",
       "0                      8                             50   \n",
       "1                     50                            481   \n",
       "\n",
       "   ip_app_device_countfrompast  ip_app_device_firsttimediff  \\\n",
       "0                           67                        43077   \n",
       "1                          353                        43196   \n",
       "\n",
       "                ...                ss_ip_app_device_os_lasttimediff  \\\n",
       "0               ...                                       -0.946795   \n",
       "1               ...                                        2.085028   \n",
       "\n",
       "   ss_matrixFact_user_ipchannel_item_appdeviceos  ss_ip_os_day_hour_count  \\\n",
       "0                                       0.455693                -0.217598   \n",
       "1                                       0.244434                -0.195399   \n",
       "\n",
       "   ss_ip_device_os_count  ss_ip_app_device_os_count  ss_app_device_os_mean  \\\n",
       "0              -0.203043                  -0.179866              -0.080696   \n",
       "1              -0.187311                  -0.171692              -0.080696   \n",
       "\n",
       "   ss_matrixFact_user_ip_item_appdeviceos  ss_app_day_hour_count  \\\n",
       "0                                0.510935               0.635208   \n",
       "1                                0.230121               0.635208   \n",
       "\n",
       "   ss_ip_app_device_time2previousclick  ss_ip_app_device_firsttimediff  \n",
       "0                            -0.282290                       -0.641153  \n",
       "1                            -0.277549                       -0.635241  \n",
       "\n",
       "[2 rows x 70 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28332"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_df[:(day9len+day8len+day7len)]\n",
    "test = train_df[-day10_testlen:]\n",
    "\n",
    "assert len(train) + len(test) == len(train_df)\n",
    "del train_df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print('fitting...')\n",
    "scaler_dict = dict((col, StandardScaler().fit(train[[col]].values)) for col in number_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60879725, 38), (18790469, 38))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "workers = 20\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    return pd.concat(list(result))\n",
    "\n",
    "def scaler_transform(x, **kwargs):\n",
    "    scaler_dict=kwargs.pop('scaler_dict')\n",
    "    col = kwargs.pop('col')\n",
    "    return scaler_dict[col].transform(x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "100%|██████████| 32/32 [1:14:24<00:00, 139.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(number_features):\n",
    "    train['ss_'+col]=apply_by_multiprocessing(train[col], scaler_transform, workers=workers, col=col, scaler_dict=scaler_dict)\n",
    "    test['ss_'+col]=apply_by_multiprocessing(test[col], scaler_transform, workers=workers, col=col, scaler_dict=scaler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip_app_device_os_time2previousclick',\n",
       " 'ip_app_device_mean',\n",
       " 'ip_app_day_hour_count',\n",
       " 'ip_app_device_os_countfrompast',\n",
       " 'ip_app_device_os_countfromfuture',\n",
       " 'ip_device_os_mean',\n",
       " 'ip_app_os_day_hour_count',\n",
       " 'ip_device_os_firsttimediff',\n",
       " 'ip_app_device_countfromfuture',\n",
       " 'ip_device_os_time2previousclick',\n",
       " 'ip_device_os_countfromfuture',\n",
       " 'ip_app_device_countfrompast',\n",
       " 'ip_device_os_lasttimediff',\n",
       " 'ip_app_device_os_mean',\n",
       " 'ip_app_device_os_time2nextclick',\n",
       " 'matrixFact_user_iposdeviceapp_item_app',\n",
       " 'ip_device_os_time2nextclick',\n",
       " 'ip_app_device_os_firsttimediff',\n",
       " 'ip_app_device_time2nextclick',\n",
       " 'ip_app_device_lasttimediff',\n",
       " 'ip_day_hour_count',\n",
       " 'ip_device_os_countfrompast',\n",
       " 'ip_app_device_os_lasttimediff',\n",
       " 'matrixFact_user_ipchannel_item_appdeviceos',\n",
       " 'ip_os_day_hour_count',\n",
       " 'ip_device_os_count',\n",
       " 'ip_app_device_os_count',\n",
       " 'app_device_os_mean',\n",
       " 'matrixFact_user_ip_item_appdeviceos',\n",
       " 'app_day_hour_count',\n",
       " 'ip_app_device_time2previousclick',\n",
       " 'ip_app_device_firsttimediff']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss_numeric_features = ['ss_'+col for col in number_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000000082129168, 0.9903295029296838)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ss_ip_device_os_lasttimediff'].std(), test['ss_ip_device_os_lasttimediff'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print('transforming...')\n",
    "for col in tqdm(number_features):\n",
    "    train[col] = train[col].apply(lambda x: scaler_dict[col].transform(x)[0][0])\n",
    "    test[col] = test[col].apply(lambda x: scaler_dict[col].transform(x)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train.to_csv('day9_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test.to_csv('day7_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dtypes = dict()\n",
    "\n",
    "for k, v in train.dtypes.iteritems():\n",
    "    train_dtypes[k] = str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open('day9_dtypes.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_dtypes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('day9_dtypes.pickle', 'rb') as handle:\n",
    "    train_dtypes = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train = pd.read_csv('day9_scaled.csv', dtype=train_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test = pd.read_csv('day7_scaled.csv', dtype=train_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train.drop('app_device_os_mean', axis=1, inplace=True)\n",
    "test.drop('app_device_os_mean', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20898422"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss_ip_app_device_os_time2previousclick -4.982598400515375e-17 0.024773937859798093\n",
      "ss_ip_app_device_mean 7.540797228873829e-19 0.03212167241955859\n",
      "ss_ip_app_day_hour_count -3.832092863240237e-17 -0.03971174021142749\n",
      "ss_ip_app_device_os_countfrompast 2.672997282998916e-17 -0.01694037465093912\n",
      "ss_ip_app_device_os_countfromfuture -2.1293969552910885e-17 -0.023730980798660945\n",
      "ss_ip_device_os_mean 1.4639020504924727e-17 0.0391170518298525\n",
      "ss_ip_app_os_day_hour_count -7.159614072249437e-18 -0.034969883464774885\n",
      "ss_ip_device_os_firsttimediff -2.595388112200093e-16 -0.024230394868122222\n",
      "ss_ip_app_device_countfromfuture 1.5435933730102724e-17 -0.025652275226938717\n",
      "ss_ip_device_os_time2previousclick -5.891182184253759e-18 0.014420249096518366\n",
      "ss_ip_device_os_countfromfuture -6.8272167574710336e-18 -0.012835057267286855\n",
      "ss_ip_app_device_countfrompast 6.727124082908548e-17 -0.014510626677935063\n",
      "ss_ip_device_os_lasttimediff 2.469450612713264e-16 -0.0586067098110574\n",
      "ss_ip_app_device_os_mean 8.596765608504827e-17 0.032286194145425405\n",
      "ss_ip_app_device_os_time2nextclick -3.566735231610961e-18 0.021129650188321088\n",
      "ss_matrixFact_user_iposdeviceapp_item_app 1.425784295050227e-14 0.07583786235029019\n",
      "ss_ip_device_os_time2nextclick -2.8612312679970235e-17 0.007761519019529632\n",
      "ss_ip_app_device_os_firsttimediff 6.610598282671625e-17 -0.012269505619620707\n",
      "ss_ip_app_device_time2nextclick -4.832832868800611e-18 0.0289993062135463\n",
      "ss_ip_app_device_lasttimediff 1.1165561935522649e-16 -0.03057386436489185\n",
      "ss_ip_day_hour_count -1.6634804944078765e-17 -0.0112656764725749\n",
      "ss_ip_device_os_countfrompast -2.6623530993234278e-17 -0.004820305460849582\n",
      "ss_ip_app_device_os_lasttimediff 1.447907763969568e-16 -0.046526963360938006\n",
      "ss_matrixFact_user_ipchannel_item_appdeviceos -8.10101928972122e-15 -0.0050771496187175845\n",
      "ss_ip_os_day_hour_count 2.054140709304742e-20 -0.02233432067765848\n",
      "ss_ip_device_os_count 1.3921471807151682e-17 -0.0019532830302567777\n",
      "ss_ip_app_device_os_count -7.803867294713197e-18 -0.013249414366967511\n",
      "ss_app_device_os_mean -4.9545873908430377e-17 0.03797578427340154\n",
      "ss_matrixFact_user_ip_item_appdeviceos 6.475220139224895e-15 -0.0052719122361819925\n",
      "ss_app_day_hour_count 1.2350987864855967e-16 -0.2597733996240182\n",
      "ss_ip_app_device_time2previousclick 6.91166995163313e-17 0.02040930883640263\n",
      "ss_ip_app_device_firsttimediff 2.1443735084625648e-16 0.025929875207029347\n"
     ]
    }
   ],
   "source": [
    "for col in ss_numeric_features:\n",
    "    print(col, train[col].mean(), test[col].mean())#train[col].std(), train[col].min(), train[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_number = train[number_features].values\n",
    "test_number = test[number_features].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_number = StandardScaler()\n",
    "train_number = ss_number.fit_transform(train_number)\n",
    "test_number= ss_number.transform(test_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Flatten\n",
    "from keras.layers.merge import concatenate, dot, add, multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import SpatialDropout1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keras_data(dataset):\n",
    "    X = dict((col, np.array(dataset[col])) for col in embedding_features)\n",
    "    X_num =  dict(('num_'+col, np.array(dataset[col])) for col in ss_numeric_features)\n",
    "    X.update(X_num)\n",
    "    return X\n",
    "\n",
    "#fe = concatenate([(emb_) for emb_ in emb_model.values()])\n",
    "# Rest of the model\n",
    "#model = Model(inputs=[inp for inp in emb_inputs.values()] + [inp for inp in num_inputs.values()], outputs=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((20898422, 49), (20446743, 49), (19534560, 49), (18790469, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60879725, 70), (18790469, 70))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df, y_train, val_df, y_val; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12911"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df, y_train, val_df, y_val; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60879725, 70)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(number_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60879725, 38)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(number_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18790469, 38)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index().to_feather('Feathers/standardscaled_train_day9_20898422_day8_20446743_day7_19534560.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.reset_index().to_feather('Feathers/standardscaled_test_inorder_no_clickid.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ftr = pd.read_feather('Feathers/standardscaled_test_inorder_no_clickid.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(number_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41345165, 41345165)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_keras_data(train[:(day9len+day8len)])\n",
    "y_train = train[:(day9len+day8len)]['is_attributed'].values\n",
    "\n",
    "len(y_train), len(train_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19534560, 19534560)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = get_keras_data(train[(day9len+day8len):(day9len+day8len+day7len)])\n",
    "y_val = train[(day9len+day8len):(day9len+day8len+day7len)]['is_attributed'].values\n",
    "\n",
    "len(y_val), len(val_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = get_keras_data(test)\n",
    "\n",
    "len(test_df), len(test_df['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, batch_size=50000):\n",
    "        super(Callback, self).__init__()\n",
    "        print('RocAuc evaluating batch size is: {}'.format(batch_size))\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            print('\\non epoch end, start predicting validation set...')\n",
    "            y_pred = self.model.predict(self.X_val, batch_size=self.batch_size,verbose=1)\n",
    "            print('start calculating ROC-AUC...')\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"ROC-AUC - epoch: {:d} - score: {:.6f}\\n\\n\".format(epoch+1, score))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5308912\n",
      "RocAuc evaluating batch size is: 100000\n",
      "Train on 41345165 samples, validate on 19534560 samples\n",
      "Epoch 1/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9811\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 1 - score: 0.979120\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05348, saving model to NN_batchsize200000_ep8_5308912.hdf5\n",
      "41345165/41345165 [==============================] - 270s 7us/step - loss: 0.1682 - acc: 0.9811 - val_loss: 0.0535 - val_acc: 0.9852\n",
      "Epoch 2/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9862\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 2 - score: 0.980779\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 269s 6us/step - loss: 0.1480 - acc: 0.9862 - val_loss: 0.0561 - val_acc: 0.9853\n",
      "Epoch 3/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9862\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 3 - score: 0.980984\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 269s 7us/step - loss: 0.1450 - acc: 0.9862 - val_loss: 0.0600 - val_acc: 0.9842\n",
      "Epoch 4/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9864\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 4 - score: 0.981026\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 268s 6us/step - loss: 0.1436 - acc: 0.9864 - val_loss: 0.0641 - val_acc: 0.9831\n",
      "Epoch 5/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9865\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 5 - score: 0.981683\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 268s 6us/step - loss: 0.1424 - acc: 0.9865 - val_loss: 0.0556 - val_acc: 0.9844\n",
      "Epoch 6/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9865\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 6 - score: 0.981814\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05348 to 0.05341, saving model to NN_batchsize200000_ep8_5308912.hdf5\n",
      "41345165/41345165 [==============================] - 268s 6us/step - loss: 0.1414 - acc: 0.9865 - val_loss: 0.0534 - val_acc: 0.9871\n",
      "Epoch 7/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9865\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 7 - score: 0.981756\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 268s 6us/step - loss: 0.1408 - acc: 0.9865 - val_loss: 0.0628 - val_acc: 0.9843\n",
      "Epoch 8/8\n",
      "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9866\n",
      "on epoch end, start predicting validation set...\n",
      "19534560/19534560 [==============================] - 43s 2us/step\n",
      "start calculating ROC-AUC...\n",
      "ROC-AUC - epoch: 8 - score: 0.981713\n",
      "\n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "41345165/41345165 [==============================] - 268s 6us/step - loss: 0.1401 - acc: 0.9866 - val_loss: 0.0609 - val_acc: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbce4fe22e8>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embids = embedding_features#['app', 'channel', 'device', 'os', 'hour', 'day', 'wday', 'qty', 'ip_app_count', 'ip_app_os_count']\n",
    "# get the max of each code type\n",
    "embmaxs = dict((col, max_dict[col]+1) for col in embedding_features)\n",
    "\n",
    "emb_n = 50\n",
    "\n",
    "# Build the inputs, embeddings and concatenate them all for each column\n",
    "emb_inputs = dict((col, Input(shape=[1], name = col))  for col in embedding_features)\n",
    "emb_model  = dict((col, Embedding(embmaxs[col], emb_n)(emb_inputs[col])) for col in embedding_features)\n",
    "\n",
    "fe = concatenate([(emb_) for emb_ in emb_model.values()])\n",
    "\n",
    "s_dout = SpatialDropout1D(0.2)(fe)\n",
    "\n",
    "conv = Conv1D(100, kernel_size=4, strides=1, padding='same')(s_dout)\n",
    "\n",
    "num_inputs = dict((col, Input(shape=[1], name = 'num_'+col))  for col in ss_numeric_features)\n",
    "\n",
    "num_fe = concatenate([(num_) for num_ in num_inputs.values()])\n",
    "\n",
    "concat = concatenate([Flatten()(s_dout), Flatten()(conv), (num_fe)])\n",
    "\n",
    "dense_n = 1000\n",
    "\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(concat))\n",
    "x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "\n",
    "outp = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[inp for inp in emb_inputs.values()] + [inp for inp in num_inputs.values()], outputs=outp)\n",
    "#model = Model(inputs=[inp for inp in emb_inputs.values()], outputs=outp)\n",
    "\n",
    "batch_size = 200000\n",
    "epochs = 8\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(list(train_df)[0]) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.002, 0.0002\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.002, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])\n",
    "\n",
    "import time\n",
    "tempid = str(int(time.time()))[3:]\n",
    "print('Model ID: ' + tempid) \n",
    "model_save_path = 'NN_batchsize{}_ep{}_{}.hdf5'.format(batch_size, epochs, tempid)\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode=\"min\", patience=5)\n",
    "pred_batch_size = 100000\n",
    "rocauc = RocAucEvaluation(validation_data=(val_df, y_val), interval=1, batch_size=pred_batch_size)\n",
    "\n",
    "class_weight = {0:1,1:99}\n",
    "\n",
    "model.fit(train_df, y_train, batch_size=batch_size, epochs=epochs, \n",
    "          validation_data=(val_df, y_val), class_weight=class_weight,\n",
    "          shuffle=True, verbose=1, callbacks=[rocauc, earlystopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('NN_batchsize200000_ep8_5308912.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19534560/19534560 [==============================] - 42s 2us/step\n"
     ]
    }
   ],
   "source": [
    "val_pred_savedmodel = model.predict(val_df, batch_size=pred_batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817132065702936"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_pred_fullmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818143556926712"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_pred_savedmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_s = train.head(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "the feather-format library is not installed\nyou can install via conda\nconda install feather-format -c conda-forge\nor via pip\npip install -U feather-format\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36m_try_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'feather'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-f07ad4cda5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_s.ftr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \"\"\"\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m         \u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m     def to_parquet(self, fname, engine='auto', compression='snappy',\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(df, path)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feather only support IO with DataFrames\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mfeather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mvalid_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'string'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unicode'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36m_try_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# give a nice error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         raise ImportError(\"the feather-format library is not installed\\n\"\n\u001b[0m\u001b[1;32m     19\u001b[0m                           \u001b[0;34m\"you can install via conda\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                           \u001b[0;34m\"conda install feather-format -c conda-forge\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: the feather-format library is not installed\nyou can install via conda\nconda install feather-format -c conda-forge\nor via pip\npip install -U feather-format\n"
     ]
    }
   ],
   "source": [
    "train.to_feather('train_s.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting....\n",
      "18790469/18790469 [==============================] - 41s 2us/step\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_ori['click_id'].astype('int')\n",
    "\n",
    "print(\"predicting....\")\n",
    "sub['is_attributed'] = model.predict(test_df, batch_size=pred_batch_size, verbose=1)\n",
    "\n",
    "flag = 'saved'\n",
    "sub.to_csv('nn_{}.csv.gz'.format(flag, tempid), index=False, float_format='%.9f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model predict val\n",
    "# model predict test\n",
    "\n",
    "# THEN load saved model \n",
    "# model predict val\n",
    "# model predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704907335882857"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RocAuc evaluating batch size is: 50000\n",
    "Epoch 1/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9838\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 45s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 1 - score: 0.978881\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 232s 6us/step - loss: 0.1686 - acc: 0.9838\n",
    "Epoch 2/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9861\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 45s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 2 - score: 0.980353\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 232s 6us/step - loss: 0.1481 - acc: 0.9861\n",
    "Epoch 3/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9863\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 45s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 3 - score: 0.981099\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 231s 6us/step - loss: 0.1456 - acc: 0.9863\n",
    "Epoch 4/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9863\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 46s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 4 - score: 0.981275\n",
    "\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 232s 6us/step - loss: 0.1437 - acc: 0.9863\n",
    "        \n",
    "        \n",
    "        Epoch 1/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9865\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 45s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 1 - score: 0.981597\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 231s 6us/step - loss: 0.1425 - acc: 0.9865\n",
    "Epoch 2/4\n",
    "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: acc,loss\n",
    "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9864\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 45s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 2 - score: 0.981716\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 231s 6us/step - loss: 0.1415 - acc: 0.9864\n",
    "Epoch 3/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9866\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 46s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 3 - score: 0.981976\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 231s 6us/step - loss: 0.1408 - acc: 0.9866\n",
    "Epoch 4/4\n",
    "41200000/41345165 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9866\n",
    "on epoch end, start predicting validation set...\n",
    "19534560/19534560 [==============================] - 46s 2us/step\n",
    "start calculating ROC-AUC...\n",
    "ROC-AUC - epoch: 4 - score: 0.981670\n",
    "\n",
    "\n",
    "41345165/41345165 [==============================] - 231s 6us/step - loss: 0.1402 - acc: 0.9866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788076360576548"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val_1, val_pred_1) # 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761119662504989"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val_1, val_pred_1) # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_inputs = []\n",
    "embedding_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dim = 50\n",
    "for i in range(len(embedding_features)):\n",
    "    tmp_input = Input(shape=(1,), dtype='int32', name=embedding_features[i]+'_input')\n",
    "    tmp_embeddings = Embedding(int(train_embeddings[i].max()+1),output_dim,name=embedding_features[i]+'_embeddings')(tmp_input)\n",
    "    tmp_embeddings = Flatten(name=embedding_features[i]+'_flatten')(tmp_embeddings)\n",
    "    \n",
    "    embedding_inputs.append(tmp_input)\n",
    "    embedding_outputs.append(tmp_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'app_input_1:0' shape=(?, 1) dtype=int32>,\n",
       " <tf.Tensor 'channel_input:0' shape=(?, 1) dtype=int32>,\n",
       " <tf.Tensor 'device_input:0' shape=(?, 1) dtype=int32>,\n",
       " <tf.Tensor 'os_input:0' shape=(?, 1) dtype=int32>,\n",
       " <tf.Tensor 'hour_input:0' shape=(?, 1) dtype=int32>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'app_flatten/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'channel_flatten/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'device_flatten/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'os_flatten/Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'hour_flatten/Reshape:0' shape=(?, ?) dtype=float32>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_input = Input(shape=(len(number_features),), name='number_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'number_feat:0' shape=(?, 36) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_outputs.append(number_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile = concatenate(embedding_outputs, name='profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'profile/concat:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FunctionalDense(n, x, batchnorm=False, act='relu', lw1=0.0, dropout=0, name=''):\n",
    "    if lw1 == 0.0:\n",
    "        x = Dense(n, name=name+'_dense')(x)\n",
    "    else:\n",
    "        x = Dense(n, kernel_regularizer=l1(lw1), name=name+'_dense')(x)\n",
    "    \n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(name=name+'_batchnorm')(x)\n",
    "        \n",
    "    if act in {'relu', 'tanh', 'sigmoid'}:\n",
    "        x = Activation(act, name=name+'_activation')(x)\n",
    "    elif act =='prelu':\n",
    "        x = PReLU(name=name+'_activation')(x)\n",
    "    elif act == 'leakyrelu':\n",
    "        x = LeakyReLU(name=name+'_activation')(x)\n",
    "    elif act == 'elu':\n",
    "        x = ELU(name=name+'_activation')(x)\n",
    "    \n",
    "    if dropout > 0:\n",
    "        x = Dropout(dropout, name=name+'_dropout')(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profile_embedddings = FunctionalDense(100, profile, batchnorm=True, dropout=0.2, name='profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
