{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/nblogreg/train_nblogreg.csv\n",
      "../../data/nblogreg/nblogreg.csv\n",
      "../../data/logreg/train_logreg.csv\n",
      "../../data/logreg/logreg.csv\n",
      "../../data/cnn/train_cnn.csv\n",
      "../../data/cnn/cnn.csv\n",
      "../../data/lstm/train_lstm.csv\n",
      "../../data/lstm/lstm.csv\n",
      "['toxic' 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate' 'toxic'\n",
      " 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate' 'toxic'\n",
      " 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate' 'toxic'\n",
      " 'severe_toxic' 'obscene' 'threat' 'insult' 'identity_hate']\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = ['nblogreg', 'logreg', 'cnn', 'lstm']\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "PATH = '../../data/'\n",
    "\n",
    "train_file = PATH + model[0] + '/train_' + model[0] + '.csv'\n",
    "test_file = PATH + model[0] + '/' + model[0] + '.csv'\n",
    "print(train_file)\n",
    "print(test_file)\n",
    "\n",
    "train = pd.read_csv(train_file)[label_cols]\n",
    "test = pd.read_csv(test_file)[label_cols]\n",
    "\n",
    "for i in range(1, len(model)):\n",
    "    train_file = PATH + model[i] + '/train_' + model[i] + '.csv'\n",
    "    test_file = PATH + model[i] + '/' + model[i] + '.csv'\n",
    "    print(train_file)\n",
    "    print(test_file)\n",
    "\n",
    "    train = pd.concat([train, pd.read_csv(train_file)[label_cols]], axis=1)\n",
    "    test = pd.concat([test, pd.read_csv(test_file)[label_cols]], axis=1)\n",
    "\n",
    "y = pd.read_csv(PATH + 'train.csv')[label_cols]\n",
    "\n",
    "features = list(label_cols)\n",
    "\n",
    "print(train.columns.values)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "0:\tlearn: 0.9908660\ttest: 0.9909193\tbest: 0.9909193 (0)\ttotal: 623ms\tremaining: 1.25s\n",
      "1:\tlearn: 0.9932177\ttest: 0.9931720\tbest: 0.9931720 (1)\ttotal: 1.25s\tremaining: 624ms\n",
      "2:\tlearn: 0.9947389\ttest: 0.9947188\tbest: 0.9947188 (2)\ttotal: 1.87s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9947188388\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "fit severe_toxic\n",
      "0:\tlearn: 0.9935309\ttest: 0.9927865\tbest: 0.9927865 (0)\ttotal: 399ms\tremaining: 798ms\n",
      "1:\tlearn: 0.9977643\ttest: 0.9976600\tbest: 0.9976600 (1)\ttotal: 953ms\tremaining: 477ms\n",
      "2:\tlearn: 0.9980051\ttest: 0.9979694\tbest: 0.9979694 (2)\ttotal: 1.48s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9979693688\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "fit obscene\n",
      "0:\tlearn: 0.9939165\ttest: 0.9945320\tbest: 0.9945320 (0)\ttotal: 674ms\tremaining: 1.35s\n",
      "1:\tlearn: 0.9958896\ttest: 0.9961944\tbest: 0.9961944 (1)\ttotal: 1.3s\tremaining: 651ms\n",
      "2:\tlearn: 0.9961478\ttest: 0.9964769\tbest: 0.9964769 (2)\ttotal: 1.99s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9964768791\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "fit threat\n",
      "0:\tlearn: 0.9891846\ttest: 0.9895575\tbest: 0.9895575 (0)\ttotal: 456ms\tremaining: 911ms\n",
      "1:\tlearn: 0.9891925\ttest: 0.9895575\tbest: 0.9895575 (1)\ttotal: 1.35s\tremaining: 675ms\n",
      "2:\tlearn: 0.9918717\ttest: 0.9925251\tbest: 0.9925251 (2)\ttotal: 2.22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9925251482\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "fit insult\n",
      "0:\tlearn: 0.9911359\ttest: 0.9915202\tbest: 0.9915202 (0)\ttotal: 516ms\tremaining: 1.03s\n",
      "1:\tlearn: 0.9936774\ttest: 0.9939918\tbest: 0.9939918 (1)\ttotal: 1.25s\tremaining: 624ms\n",
      "2:\tlearn: 0.9947193\ttest: 0.9950057\tbest: 0.9950057 (2)\ttotal: 1.91s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9950056961\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "fit identity_hate\n",
      "0:\tlearn: 0.9983670\ttest: 0.9985464\tbest: 0.9985464 (0)\ttotal: 611ms\tremaining: 1.22s\n",
      "1:\tlearn: 0.9984275\ttest: 0.9985842\tbest: 0.9985842 (1)\ttotal: 1.1s\tremaining: 551ms\n",
      "2:\tlearn: 0.9985278\ttest: 0.9986181\tbest: 0.9986181 (2)\ttotal: 1.71s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9986180931\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def print_feature_importance(x, features, models):\n",
    "    dict = {}\n",
    "    for i in range(len(x)):\n",
    "        which_model = models[i // len(features)]\n",
    "        which_feature = features[i % len(features)]\n",
    "        dict[(which_model + ' ' + which_feature)] = x[i]\n",
    "    print(dict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "out = np.zeros((test.shape[0], len(label_cols)))\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit ' + j)\n",
    "    ensemble = CatBoostClassifier(iterations=3,\n",
    "                                  depth=10, \n",
    "                                  learning_rate=0.001, \n",
    "                                  loss_function='CrossEntropy',\n",
    "                                  eval_metric='AUC')\n",
    "    ensemble.fit(X_train[j], y_train[j], use_best_model=True, eval_set=[X_test[j], y_test[j]])\n",
    "#     print_feature_importance(ensemble.get_feature_importance(X_train, y_train[j]), features, model)\n",
    "    out[:, i] = ensemble.predict_proba(test.values)[:, 0] # TODO: should ues 1 or 0?\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "submission[label_cols] = out\n",
    "submission.to_csv(PATH + 'ensemble/catboost_ensemble.csv', index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
