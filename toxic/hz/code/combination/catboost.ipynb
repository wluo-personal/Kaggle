{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/nblogreg/train_nblogreg.csv\n",
      "../../data/nblogreg/nblogreg.csv\n",
      "../../data/nbnn/train_nbnn.csv\n",
      "../../data/nbnn/nbnn.csv\n",
      "../../data/cnn/train_cnn.csv\n",
      "../../data/cnn/cnn.csv\n",
      "../../data/lstm/train_lstm.csv\n",
      "../../data/lstm/lstm.csv\n",
      "other features\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = ['nblogreg', 'nbnn', 'cnn', 'lstm']\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "PATH = '../../data/'\n",
    "\n",
    "train_file = PATH + model[0] + '/train_' + model[0] + '.csv'\n",
    "test_file = PATH + model[0] + '/' + model[0] + '.csv'\n",
    "print(train_file)\n",
    "print(test_file)\n",
    "\n",
    "train = pd.read_csv(train_file)[label_cols]\n",
    "test = pd.read_csv(test_file)[label_cols]\n",
    "\n",
    "for i in range(1, len(model)):\n",
    "    train_file = PATH + model[i] + '/train_' + model[i] + '.csv'\n",
    "    test_file = PATH + model[i] + '/' + model[i] + '.csv'\n",
    "    print(train_file)\n",
    "    print(test_file)\n",
    "\n",
    "    train = pd.concat([train, pd.read_csv(train_file)[label_cols]], axis=1)\n",
    "    test = pd.concat([test, pd.read_csv(test_file)[label_cols]], axis=1)    \n",
    "\n",
    "other_feature_cols = ['word_count', 'unique_word_count', 'consecutive_question_marks',\\\n",
    "                      'consecutive_exclamation_marks', 'uppercase_letters', 'ellipsis',\\\n",
    "                      'period', 'parentheses_paird', 'cleaned_word_count', 'cleaned_unique_word_count',\\\n",
    "                      'cleaned_consecutive_question_marks', 'cleaned_consecutive_exclamation_marks',\\\n",
    "                      'cleaned_uppercase_letters', 'cleaned_ellipsis', 'cleaned_period', 'cleaned_parentheses_pair']\n",
    "\n",
    "print('other features')\n",
    "train = pd.concat([train, pd.read_csv(PATH + 'cleaned_train.csv')[other_feature_cols]], axis=1)\n",
    "test = pd.concat([test, pd.read_csv(PATH + 'cleaned_test.csv')[other_feature_cols]], axis=1)\n",
    "\n",
    "y = pd.read_csv(PATH + 'train.csv')[label_cols]\n",
    "\n",
    "features = list(label_cols)\n",
    "features.extend(other_feature_cols)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "0:\tlearn: 0.6897887\ttest: 0.6897824\tbest: 0.6897824 (0)\ttotal: 527ms\tremaining: 1.05s\n",
      "1:\tlearn: 0.6870233\ttest: 0.6870154\tbest: 0.6870154 (1)\ttotal: 1s\tremaining: 503ms\n",
      "2:\tlearn: 0.6845811\ttest: 0.6845638\tbest: 0.6845638 (2)\ttotal: 1.46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6845638022\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "{'nblogreg toxic': 0.7672547441218098, 'nblogreg severe_toxic': 0.0, 'nblogreg obscene': 1.143144402471642, 'nblogreg threat': 3.5403910212980323, 'nblogreg insult': 0.0, 'nblogreg identity_hate': 1.7272417196716312, 'nblogreg word_count': 5.85103594175941, 'nblogreg unique_word_count': 0.0, 'nblogreg consecutive_question_marks': 0.0, 'nblogreg consecutive_exclamation_marks': 0.0, 'nblogreg uppercase_letters': 2.5836407435859696, 'nblogreg ellipsis': 0.9499030623221179, 'nblogreg period': 1.7205401964730045, 'nblogreg parentheses_paird': 21.061915251114925, 'nblogreg cleaned_word_count': 7.231817724268177, 'nblogreg cleaned_unique_word_count': 0.0, 'nblogreg cleaned_consecutive_question_marks': 3.963744002095236, 'nblogreg cleaned_consecutive_exclamation_marks': 4.879769472850561, 'nblogreg cleaned_uppercase_letters': 15.946587033185237, 'nblogreg cleaned_ellipsis': 2.820705152496886, 'nblogreg cleaned_period': 14.568429524900884, 'nblogreg cleaned_parentheses_pair': 0.0, 'nbnn toxic': 9.592640743739803, 'nbnn severe_toxic': 0.0, 'nbnn obscene': 0.5323857123196427, 'nbnn threat': 0.9930516181659398, 'nbnn insult': 0.0, 'nbnn identity_hate': 0.0, 'nbnn word_count': 0.0, 'nbnn unique_word_count': 0.0, 'nbnn consecutive_question_marks': 0.04406127261597654, 'nbnn consecutive_exclamation_marks': 0.0, 'nbnn uppercase_letters': 0.0, 'nbnn ellipsis': 0.0, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.07987744706265971, 'nbnn cleaned_consecutive_question_marks': 0.001863213480460377, 'nbnn cleaned_consecutive_exclamation_marks': 0.0}\n",
      "fit severe_toxic\n",
      "0:\tlearn: 0.6888677\ttest: 0.6888637\tbest: 0.6888637 (0)\ttotal: 446ms\tremaining: 892ms\n",
      "1:\tlearn: 0.6845410\ttest: 0.6845332\tbest: 0.6845332 (1)\ttotal: 912ms\tremaining: 456ms\n",
      "2:\tlearn: 0.6803376\ttest: 0.6803259\tbest: 0.6803259 (2)\ttotal: 1.35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6803258653\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "{'nblogreg toxic': 0.11767649380980948, 'nblogreg severe_toxic': 13.328827516213693, 'nblogreg obscene': 4.069179424559478, 'nblogreg threat': 0.0, 'nblogreg insult': 0.0, 'nblogreg identity_hate': 0.0, 'nblogreg word_count': 9.916439007999085, 'nblogreg unique_word_count': 7.162120302925606, 'nblogreg consecutive_question_marks': 0.0, 'nblogreg consecutive_exclamation_marks': 0.0, 'nblogreg uppercase_letters': 5.18616036349187, 'nblogreg ellipsis': 0.0, 'nblogreg period': 28.465977940635867, 'nblogreg parentheses_paird': 4.914870356940283, 'nblogreg cleaned_word_count': 1.6380305465866047, 'nblogreg cleaned_unique_word_count': 0.4926855642480944, 'nblogreg cleaned_consecutive_question_marks': 0.0, 'nblogreg cleaned_consecutive_exclamation_marks': 1.273721198541045, 'nblogreg cleaned_uppercase_letters': 0.0, 'nblogreg cleaned_ellipsis': 1.691481070848824, 'nblogreg cleaned_period': 0.0, 'nblogreg cleaned_parentheses_pair': 1.24465826539782, 'nbnn toxic': 7.52533702535005, 'nbnn severe_toxic': 1.5223285045107338, 'nbnn obscene': 0.0, 'nbnn threat': 3.0184618749702286, 'nbnn insult': 0.03891799983569237, 'nbnn identity_hate': 0.060939773329239055, 'nbnn word_count': 3.6511659149268683, 'nbnn unique_word_count': 0.0, 'nbnn consecutive_question_marks': 2.5339292826962123, 'nbnn consecutive_exclamation_marks': 0.0, 'nbnn uppercase_letters': 0.0, 'nbnn ellipsis': 0.0, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.12007404318684627, 'nbnn cleaned_consecutive_question_marks': 0.5658869165699525, 'nbnn cleaned_consecutive_exclamation_marks': 1.4611306124261119}\n",
      "fit obscene\n",
      "0:\tlearn: 0.6894605\ttest: 0.6894625\tbest: 0.6894625 (0)\ttotal: 449ms\tremaining: 898ms\n",
      "1:\tlearn: 0.6859766\ttest: 0.6859816\tbest: 0.6859816 (1)\ttotal: 898ms\tremaining: 449ms\n",
      "2:\tlearn: 0.6823887\ttest: 0.6824045\tbest: 0.6824045 (2)\ttotal: 1.36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6824044962\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "{'nblogreg toxic': 1.5252822720806032, 'nblogreg severe_toxic': 0.5771557119385775, 'nblogreg obscene': 3.323685412042411, 'nblogreg threat': 1.22222003093723, 'nblogreg insult': 0.0, 'nblogreg identity_hate': 1.1603595362310342, 'nblogreg word_count': 0.0, 'nblogreg unique_word_count': 0.0, 'nblogreg consecutive_question_marks': 6.216854065327885, 'nblogreg consecutive_exclamation_marks': 1.5202768492191434, 'nblogreg uppercase_letters': 0.0, 'nblogreg ellipsis': 0.47522172690126685, 'nblogreg period': 0.0, 'nblogreg parentheses_paird': 0.0, 'nblogreg cleaned_word_count': 21.376357916264357, 'nblogreg cleaned_unique_word_count': 15.959240257215304, 'nblogreg cleaned_consecutive_question_marks': 32.840784510044394, 'nblogreg cleaned_consecutive_exclamation_marks': 0.0, 'nblogreg cleaned_uppercase_letters': 0.0, 'nblogreg cleaned_ellipsis': 2.233224192839506, 'nblogreg cleaned_period': 1.1106275710523539, 'nblogreg cleaned_parentheses_pair': 4.325128293891302, 'nbnn toxic': 0.0, 'nbnn severe_toxic': 0.0, 'nbnn obscene': 2.205552368184873, 'nbnn threat': 0.0, 'nbnn insult': 0.03357649819917667, 'nbnn identity_hate': 0.0029032030717982184, 'nbnn word_count': 2.128375366876474, 'nbnn unique_word_count': 0.0, 'nbnn consecutive_question_marks': 0.08534041888957455, 'nbnn consecutive_exclamation_marks': 0.0, 'nbnn uppercase_letters': 0.0, 'nbnn ellipsis': 0.9009279290936345, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.7769058696991227, 'nbnn cleaned_consecutive_question_marks': 0.0, 'nbnn cleaned_consecutive_exclamation_marks': 0.0}\n",
      "fit threat\n",
      "0:\tlearn: 0.6891042\ttest: 0.6891021\tbest: 0.6891021 (0)\ttotal: 443ms\tremaining: 886ms\n",
      "1:\tlearn: 0.6852277\ttest: 0.6852216\tbest: 0.6852216 (1)\ttotal: 907ms\tremaining: 454ms\n",
      "2:\tlearn: 0.6811886\ttest: 0.6811827\tbest: 0.6811827 (2)\ttotal: 1.36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6811827171\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "{'nblogreg toxic': 0.0, 'nblogreg severe_toxic': 0.0, 'nblogreg obscene': 0.0, 'nblogreg threat': 29.436978205728593, 'nblogreg insult': 0.0, 'nblogreg identity_hate': 0.0, 'nblogreg word_count': 3.205319954100252, 'nblogreg unique_word_count': 1.8316671107198277, 'nblogreg consecutive_question_marks': 4.385396437638342, 'nblogreg consecutive_exclamation_marks': 0.0, 'nblogreg uppercase_letters': 3.5507932328938305, 'nblogreg ellipsis': 4.925460822262879, 'nblogreg period': 0.0, 'nblogreg parentheses_paird': 0.16741690929811537, 'nblogreg cleaned_word_count': 0.0, 'nblogreg cleaned_unique_word_count': 0.0, 'nblogreg cleaned_consecutive_question_marks': 0.8421229082367081, 'nblogreg cleaned_consecutive_exclamation_marks': 1.7617062488135087, 'nblogreg cleaned_uppercase_letters': 0.0, 'nblogreg cleaned_ellipsis': 13.231981299808396, 'nblogreg cleaned_period': 11.98536703679561, 'nblogreg cleaned_parentheses_pair': 6.764138595937413, 'nbnn toxic': 15.137572639278076, 'nbnn severe_toxic': 0.0, 'nbnn obscene': 0.0, 'nbnn threat': 0.0, 'nbnn insult': 0.05783450038917226, 'nbnn identity_hate': 0.0, 'nbnn word_count': 0.029252900580728394, 'nbnn unique_word_count': 0.1519385989628569, 'nbnn consecutive_question_marks': 0.0, 'nbnn consecutive_exclamation_marks': 0.0, 'nbnn uppercase_letters': 1.343935867584268, 'nbnn ellipsis': 1.0851494984503718, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.10596723252104982, 'nbnn cleaned_consecutive_question_marks': 0.0, 'nbnn cleaned_consecutive_exclamation_marks': 0.0}\n",
      "fit insult\n",
      "0:\tlearn: 0.6894698\ttest: 0.6894749\tbest: 0.6894749 (0)\ttotal: 448ms\tremaining: 896ms\n",
      "1:\tlearn: 0.6857265\ttest: 0.6857288\tbest: 0.6857288 (1)\ttotal: 908ms\tremaining: 454ms\n",
      "2:\tlearn: 0.6821238\ttest: 0.6821293\tbest: 0.6821293 (2)\ttotal: 1.37s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.682129287\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nblogreg toxic': 6.388874172247247, 'nblogreg severe_toxic': 0.40214236047163954, 'nblogreg obscene': 0.0, 'nblogreg threat': 3.134833721554143, 'nblogreg insult': 3.038370332510139, 'nblogreg identity_hate': 0.0, 'nblogreg word_count': 0.0, 'nblogreg unique_word_count': 0.0, 'nblogreg consecutive_question_marks': 3.255522278185245, 'nblogreg consecutive_exclamation_marks': 0.0, 'nblogreg uppercase_letters': 0.0, 'nblogreg ellipsis': 0.0, 'nblogreg period': 6.8109527366333324, 'nblogreg parentheses_paird': 13.586071844291766, 'nblogreg cleaned_word_count': 51.306169731462646, 'nblogreg cleaned_unique_word_count': 0.0, 'nblogreg cleaned_consecutive_question_marks': 0.5748868170052024, 'nblogreg cleaned_consecutive_exclamation_marks': 0.0, 'nblogreg cleaned_uppercase_letters': 0.8736411416459646, 'nblogreg cleaned_ellipsis': 1.4958807230387594, 'nblogreg cleaned_period': 0.0, 'nblogreg cleaned_parentheses_pair': 0.0, 'nbnn toxic': 2.5333972823804745, 'nbnn severe_toxic': 0.0, 'nbnn obscene': 1.5997083042678526, 'nbnn threat': 0.0, 'nbnn insult': 0.0, 'nbnn identity_hate': 0.0, 'nbnn word_count': 0.0, 'nbnn unique_word_count': 0.0, 'nbnn consecutive_question_marks': 1.0868243449967467, 'nbnn consecutive_exclamation_marks': 0.0, 'nbnn uppercase_letters': 0.6209091393759245, 'nbnn ellipsis': 2.2216458031117865, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.0, 'nbnn cleaned_consecutive_question_marks': 0.0, 'nbnn cleaned_consecutive_exclamation_marks': 1.0701692668211285}\n",
      "fit identity_hate\n",
      "0:\tlearn: 0.6892389\ttest: 0.6892338\tbest: 0.6892338 (0)\ttotal: 446ms\tremaining: 891ms\n",
      "1:\tlearn: 0.6852400\ttest: 0.6852432\tbest: 0.6852432 (1)\ttotal: 674ms\tremaining: 337ms\n",
      "2:\tlearn: 0.6810810\ttest: 0.6810839\tbest: 0.6810839 (2)\ttotal: 1.11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6810839146\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "{'nblogreg toxic': 2.070836807607041, 'nblogreg severe_toxic': 2.806685517585045, 'nblogreg obscene': 1.110538244671813, 'nblogreg threat': 1.772550052814093, 'nblogreg insult': 2.9611027345277394, 'nblogreg identity_hate': 46.22596680089149, 'nblogreg word_count': 0.0, 'nblogreg unique_word_count': 0.0, 'nblogreg consecutive_question_marks': 0.0, 'nblogreg consecutive_exclamation_marks': 0.0, 'nblogreg uppercase_letters': 3.396837095437551, 'nblogreg ellipsis': 1.5563879213339544, 'nblogreg period': 0.0, 'nblogreg parentheses_paird': 6.286606609892092, 'nblogreg cleaned_word_count': 19.425124129688694, 'nblogreg cleaned_unique_word_count': 0.0, 'nblogreg cleaned_consecutive_question_marks': 2.2938679974084644, 'nblogreg cleaned_consecutive_exclamation_marks': 0.0, 'nblogreg cleaned_uppercase_letters': 3.851570564474264, 'nblogreg cleaned_ellipsis': 0.15966261053407974, 'nblogreg cleaned_period': 0.0, 'nblogreg cleaned_parentheses_pair': 0.0, 'nbnn toxic': 0.0, 'nbnn severe_toxic': 0.0, 'nbnn obscene': 0.0, 'nbnn threat': 0.0, 'nbnn insult': 0.0, 'nbnn identity_hate': 0.0, 'nbnn word_count': 1.8943185812339411, 'nbnn unique_word_count': 0.0, 'nbnn consecutive_question_marks': 0.033564864410063074, 'nbnn consecutive_exclamation_marks': 2.888605492499583, 'nbnn uppercase_letters': 0.0, 'nbnn ellipsis': 0.0, 'nbnn period': 0.0, 'nbnn parentheses_paird': 0.0, 'nbnn cleaned_word_count': 0.0, 'nbnn cleaned_unique_word_count': 0.07370355886834816, 'nbnn cleaned_consecutive_question_marks': 0.0, 'nbnn cleaned_consecutive_exclamation_marks': 1.1920704161217313}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def print_feature_importance(x, features, models):\n",
    "    dict = {}\n",
    "    for i in range(len(x)):\n",
    "        which_model = models[i // len(features)]\n",
    "        which_feature = features[i % len(features)]\n",
    "        dict[(which_model + ' ' + which_feature)] = x[i]\n",
    "    print(dict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "out = np.zeros((test.shape[0], len(label_cols)))\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit ' + j)\n",
    "    ensemble = CatBoostClassifier(iterations=3,\n",
    "                                  depth=10, \n",
    "                                  learning_rate=0.001, \n",
    "                                  loss_function='Logloss')\n",
    "    ensemble.fit(X_train, y_train[j], use_best_model=True, eval_set=[X_test, y_test[j]])\n",
    "    print_feature_importance(ensemble.get_feature_importance(X_train, y_train[j]), features, model)\n",
    "    out[:, i] = ensemble.predict_proba(test.values)[:, 0] # TODO: should ues 1 or 0?\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "submission[label_cols] = out\n",
    "submission.to_csv(PATH + 'ensemble/catboost_ensemble.csv', index=False)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
