{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "\n",
    "PATH = '../../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APO = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"i would\",\n",
    "    \"i'd\" : \"i had\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"i'm\" : \"i am\",\n",
    "    \"im\" : \"i am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"i have\",\n",
    "    \"ive\" : \"i have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\": \"trying\",\n",
    "    \"u\" : \"you\",\n",
    "    \"r\" : \"are\",\n",
    "    \"ur\" : \"you are\",\n",
    "    \"fuckin\" : \"fucking\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inplace na\n",
      "comment text cleaning\n",
      "word count\n",
      "unique word count\n",
      "question marks\n",
      "consecutive question marks\n",
      "exclamation marks\n",
      "consecutive exclamation marks\n",
      "uppercase letters\n",
      "ellipsis\n",
      "period and ellipsis\n",
      "parentheses pairs\n",
      "special symbols\n",
      "sentence count\n",
      "upper_word_ratio\n",
      "unique_word_ratio\n",
      "mark_count_ratio\n",
      "['id' 'comment_text' 'toxic' 'severe_toxic' 'obscene' 'threat' 'insult'\n",
      " 'identity_hate' 'comment_text_cleaned' 'word_count' 'cleaned_word_count'\n",
      " 'unique_word_count' 'cleaned_unique_word_count' 'question_marks'\n",
      " 'consecutive_question_marks' 'exclamation_marks'\n",
      " 'consecutive_exclamation_marks' 'uppercase_letters' 'ellipsis' 'period'\n",
      " 'parentheses_pair' 'special_symbol' 'sentence' 'upper_word_ratio'\n",
      " 'unique_word_ratio' 'mark_count_ratio']\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "tok = TweetTokenizer()\n",
    "\n",
    "def clean(comment):\n",
    "    comment = comment.lower()\n",
    "    comment = re.sub(r'\\n+', ' ', comment)\n",
    "    comment = re.sub('\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}', '',comment) # remove leaky elements like ip,user\n",
    "    comment = re.sub('\\[\\[.*\\]', '',comment)    #removing usernames\n",
    "    comment = re.sub('[=\",~]', '', comment)\n",
    "    comment = re.sub('-', ' ', comment)\n",
    "    text = tok.tokenize(comment)\n",
    "    text = [word for word in  text if not re.match(r'http:\\/\\/.*', word)]\n",
    "    text = [APO[word] if word in APO else word for word in text]\n",
    "    text = tok.tokenize(' '.join(text))\n",
    "    text = [lem.lemmatize(word, 'v') for word in text]\n",
    "    text = [lem.lemmatize(word, 'n') for word in text]\n",
    "    text = ' '.join(text).lower()\n",
    "    text = re.sub(r'\\/', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    if text == '': text = 'na'\n",
    "    return text\n",
    "\n",
    "# word count\n",
    "def word_count(comment): return len(comment.split())\n",
    "# unique word count\n",
    "def unique_word_count(comment): return len(set(comment.split()))\n",
    "# find the count of quesiton marks\n",
    "def question_mark_count(comment): return len(re.findall(r'\\?', comment))\n",
    "# find the count of consecutive question marks (i.e. ??)\n",
    "def multi_question_mark_count(comment): return len(re.findall(r'\\?{2,}', comment))\n",
    "# find the count of exclamation marks\n",
    "def exclamation_mark_count(comment): return len(re.findall(r'!', comment))\n",
    "# find the count of consecutive exclamation marks (i.e. !!)\n",
    "def multi_exclamation_mark_count(comment): return len(re.findall(r'!{2,}', comment))\n",
    "# find the count of uppercase letters\n",
    "def uppercase_letter_count(comment): return len(re.findall(r'[A-Z]', comment))\n",
    "# count ellipsis (3 or more . (i.e. ...))\n",
    "def ellipsis_count(comment): return len(re.findall(r'\\.{3,}', comment))\n",
    "# count period and ellipsis\n",
    "def period_count(comment): return len(re.findall(r'\\.+', comment))\n",
    "# count parentheses pairs\n",
    "def parentheses_pair_count(comment): return len(re.findall(r'\\(.*\\)', comment))\n",
    "# count special symbols\n",
    "def special_symbol_count(comment): return len(re.findall(r'[\\%\\#\\@\\*\\&\\$]', comment))\n",
    "# count period and change line\n",
    "def sentence_count(comment): return len(re.findall(r'[\\n+\\.+\\?+!+]', comment))\n",
    "\n",
    "print('inplace na')\n",
    "train['comment_text'].fillna('na', inplace=True)\n",
    "test['comment_text'].fillna('na', inplace=True)\n",
    "\n",
    "print('comment text cleaning')\n",
    "train['comment_text_cleaned'] = train['comment_text'].apply(clean)\n",
    "test['comment_text_cleaned'] = test['comment_text'].apply(clean)\n",
    "\n",
    "print('word count')\n",
    "train['word_count'] = train['comment_text'].apply(word_count)\n",
    "test['word_count'] = test['comment_text'].apply(word_count)\n",
    "train['cleaned_word_count'] = train['comment_text_cleaned'].apply(word_count)\n",
    "test['cleaned_word_count'] = test['comment_text_cleaned'].apply(word_count)\n",
    "\n",
    "print('unique word count')\n",
    "train['unique_word_count'] = train['comment_text'].apply(unique_word_count)\n",
    "test['unique_word_count'] = test['comment_text'].apply(unique_word_count)\n",
    "train['cleaned_unique_word_count'] = train['comment_text_cleaned'].apply(unique_word_count)\n",
    "test['cleaned_unique_word_count'] = test['comment_text_cleaned'].apply(unique_word_count)\n",
    "\n",
    "print('question marks')\n",
    "train['question_marks'] = train['comment_text'].apply(question_mark_count)\n",
    "test['question_marks'] = test['comment_text'].apply(question_mark_count)\n",
    "\n",
    "print('consecutive question marks')\n",
    "train['consecutive_question_marks'] = train['comment_text'].apply(multi_question_mark_count)\n",
    "test['consecutive_question_marks'] = test['comment_text'].apply(multi_question_mark_count)\n",
    "\n",
    "print('exclamation marks')\n",
    "train['exclamation_marks'] = train['comment_text'].apply(exclamation_mark_count)\n",
    "test['exclamation_marks'] = test['comment_text'].apply(exclamation_mark_count)\n",
    "\n",
    "print('consecutive exclamation marks')\n",
    "train['consecutive_exclamation_marks'] = train['comment_text'].apply(multi_exclamation_mark_count)\n",
    "test['consecutive_exclamation_marks'] = test['comment_text'].apply(multi_exclamation_mark_count)\n",
    "\n",
    "print('uppercase letters')\n",
    "train['uppercase_letters'] = train['comment_text'].apply(uppercase_letter_count)\n",
    "test['uppercase_letters'] = test['comment_text'].apply(uppercase_letter_count)\n",
    "\n",
    "print('ellipsis')\n",
    "train['ellipsis'] = train['comment_text'].apply(ellipsis_count)\n",
    "test['ellipsis'] = test['comment_text'].apply(ellipsis_count)\n",
    "\n",
    "print('period and ellipsis')\n",
    "train['period'] = train['comment_text'].apply(period_count)\n",
    "test['period'] = test['comment_text'].apply(period_count)\n",
    "\n",
    "print('parentheses pairs')\n",
    "train['parentheses_pair'] = train['comment_text'].apply(parentheses_pair_count)\n",
    "test['parentheses_pair'] = test['comment_text'].apply(parentheses_pair_count)\n",
    "\n",
    "print('special symbols')\n",
    "train['special_symbol'] = train['comment_text'].apply(special_symbol_count)\n",
    "test['special_symbol'] = test['comment_text'].apply(special_symbol_count)\n",
    "\n",
    "print('sentence count')\n",
    "train['sentence'] = train['comment_text'].apply(sentence_count)\n",
    "test['sentence'] = test['comment_text'].apply(sentence_count)\n",
    "\n",
    "print('upper_word_ratio')\n",
    "train['upper_word_ratio'] = train['uppercase_letters'] / (train['word_count'] + 1)\n",
    "test['upper_word_ratio'] = test['uppercase_letters'] / (test['word_count'] + 1)\n",
    "\n",
    "print('unique_word_ratio')\n",
    "train['unique_word_ratio'] = train['unique_word_count'] / (train['word_count'] + 1)\n",
    "test['unique_word_ratio'] = test['unique_word_count'] / (test['word_count'] + 1)\n",
    "\n",
    "print('mark_count_ratio')\n",
    "train['mark_count_ratio'] = (train['question_marks']+train['exclamation_marks']+train['special_symbol'])\\\n",
    "                            /(train['word_count'] + 1)\n",
    "test['mark_count_ratio'] = (test['question_marks']+test['exclamation_marks']+test['special_symbol'])\\\n",
    "                            /(test['word_count'] + 1)\n",
    "\n",
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train.to_csv(PATH + 'cleaned_train.csv')\n",
    "test.to_csv(PATH + 'cleaned_test.csv')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
