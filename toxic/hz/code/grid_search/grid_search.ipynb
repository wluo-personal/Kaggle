{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Bidirectional, GlobalMaxPool1D, Dropout, BatchNormalization\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastText import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 10)\n",
      "74.75983104699475\n",
      "110.47788051973407\n"
     ]
    }
   ],
   "source": [
    "HOME = '/home/kai/data/kaggle/toxic/hz/'\n",
    "DATA = HOME + 'data/'\n",
    "MODEL = HOME + 'model/'\n",
    "RECORD = DATA + 'summary.csv'\n",
    "\n",
    "combine_test = False\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "tok = TweetTokenizer()\n",
    "# train = pd.read_csv(DATA + 'cleaned_train.csv')\n",
    "train = pd.read_csv('/home/kai/data/kaggle/toxic/dataset/training/emoji_train.csv')\n",
    "\n",
    "train_sentences = train['comment_text_cleaned']\n",
    "sentences = train_sentences\n",
    "\n",
    "text_length = sentences.apply(lambda x: len(tok.tokenize(x)))\n",
    "mean_length = text_length.mean()\n",
    "std_length = text_length.std()\n",
    "\n",
    "print(train.shape)\n",
    "print(mean_length)\n",
    "print(std_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# grid search params\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "class grid_search_generator(object):\n",
    "    # Here needs to be modified\n",
    "    def __init__(self, config_file_url=None):\n",
    "        if config_file_url == None:\n",
    "            self.params = {'max_features': [200000], \n",
    "                      'epochs': [40], \n",
    "                      'batch_size': [1024],\n",
    "                      'max_len': [int(np.round(mean_length + 3*std_length))], # max sequence length\n",
    "                      'dropout': [0.2, 0.5],\n",
    "                      'patience': [5],\n",
    "                      'model_file': [MODEL + 'lstm_best.hdf5'],\n",
    "                      'loss': ['binary_crossentropy'],\n",
    "                      'label_len': [len(label_cols)],\n",
    "                      # fixed grid search params separate line\n",
    "                      'embed_trainable': [True, False],\n",
    "                      'batch_normalization': [True, False],\n",
    "                      'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "                      'lstm_activation': ['relu', 'tanh', 'sigmoid'],\n",
    "                      'lstm_units': [5, 50, 100, 200],\n",
    "                      'dense_units': [50, 100, 200, 300],\n",
    "                      'lstm_layer_size': [1, 2],\n",
    "                      'dense_layer_size': [1, 2, 3],\n",
    "                      'embedding_param': [{'embed_file': '/home/kai/data/resources/glove/glove.6B.50d.txt', 'embed_size': 50, 'embed_type': 'glove'},\n",
    "                                          {'embed_file': '/home/kai/data/resources/glove/glove.6B.100d.txt', 'embed_size': 100, 'embed_type': 'glove'},\n",
    "                                          {'embed_file': '/home/kai/data/resources/glove/glove.6B.200d.txt', 'embed_size': 200, 'embed_type': 'glove'},\n",
    "                                          {'embed_file': '/home/kai/data/resources/glove/glove.6B.300d.txt', 'embed_size': 300, 'embed_type': 'glove'},\n",
    "                                          {'embed_file': '/home/kai/data/resources/FastText/wiki.en.bin', 'embed_size': 300, 'embed_type': 'fasttext'}]\n",
    "                    }\n",
    "\n",
    "            self.binding = {'embedding_param': ['embed_type', 'embed_file', 'embed_size']}\n",
    "            self.score_name_list = ['val_loss', 'val_auc', 'train_auc']\n",
    "            \n",
    "            self.single_keys = [key for key in self.params.keys() if key not in self.binding.keys()]\n",
    "            self.binding_keys = list(self.binding.keys())\n",
    "\n",
    "            self._terminate = False\n",
    "        else:\n",
    "            with open(config_file_url, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                self.params = data['params']\n",
    "                self.binding = data['binding']\n",
    "                self.score_name_list = data['score_name_list']\n",
    "                self.single_keys = data['single_keys']\n",
    "                self.binding_keys = data['binding_keys']\n",
    "                self._idx = data['_idx']\n",
    "                \n",
    "        self._terminate = False\n",
    "        self.keys = list(self.single_keys)\n",
    "        self.keys.extend(self.binding_keys)\n",
    "        self.param_keys = list(self.single_keys)\n",
    "        for i in range(len(self.single_keys), len(self.keys)):\n",
    "            self.param_keys.extend(self.binding[self.keys[i]])\n",
    "        \n",
    "        if config_file_url == None: self._idx = [int(0) for i in range(len(self.keys))]\n",
    "        self._ub = [len(self.params[key]) for key in self.keys]\n",
    "    \n",
    "    def _next_idx(self):\n",
    "        i = 0\n",
    "        self._idx[i] = (self._idx[i] + 1) % self._ub[i]\n",
    "        i += 1\n",
    "        end_loop = (self._idx[i-1]!=0 or i==len(self._idx))\n",
    "        terminate = (self._idx[i-1]==0 and i==len(self._idx))\n",
    "        while(not end_loop):\n",
    "            self._idx[i] = (self._idx[i] + 1) % self._ub[i]\n",
    "            i += 1\n",
    "            end_loop = (self._idx[i-1]!=0 or i==len(self._idx))\n",
    "            terminate = (self._idx[i-1]==0 and i==len(self._idx))\n",
    "        self._terminate = terminate\n",
    "\n",
    "    def _next_param_list(self):\n",
    "        if not self._terminate:\n",
    "            input = [self.params[self.keys[i]][self._idx[i]] for i in range(len(self.single_keys))]\n",
    "            for i in range(len(self.single_keys), len(self.keys)):\n",
    "                input.extend([self.params[self.keys[i]][self._idx[i]][key] for key in self.binding[self.keys[i]]])\n",
    "            self._next_idx()\n",
    "            return input\n",
    "        else: return None\n",
    "        \n",
    "    def get_csv(self, csv_url):\n",
    "        value_list = [float('nan') for i in range(len(self.score_name_list))]\n",
    "        column_name = list(self.param_keys)\n",
    "        column_name.extend(self.score_name_list)\n",
    "        param_list = []\n",
    "        \n",
    "        param = self._next_param_list()\n",
    "        while param != None:\n",
    "            param.extend(value_list)\n",
    "            param_list.append(param)\n",
    "            param = self._next_param_list()\n",
    "        pd.DataFrame(param_list, columns=column_name).to_csv(csv_url, index=False)\n",
    "        self._idx = [0 for i in range(len(self.keys))]\n",
    "        self._terminate = False\n",
    "        print('successfully generated grid search csv file\\n')\n",
    "        return 0\n",
    "    \n",
    "    def _get_grid_search_param(self, keys, values): return dict(zip(keys, values))\n",
    "    \n",
    "    def next_param(self, url):\n",
    "        value = self._next_param_list()\n",
    "        if value == None:\n",
    "            with open(url, 'w') as f: f.write('terminate')\n",
    "            return None\n",
    "        param_dict = self._get_grid_search_param(self.param_keys, value)\n",
    "        with open(url, 'w') as f:\n",
    "            data = {\n",
    "                'params': self.params,\n",
    "                'binding': self.binding,\n",
    "                'score_name_list': self.score_name_list,\n",
    "                'single_keys': self.single_keys,\n",
    "                'binding_keys': self.binding_keys,\n",
    "                '_idx': self._idx\n",
    "            }\n",
    "            json.dump(data, f)\n",
    "        return param_dict\n",
    "    \n",
    "    # get_model, train, recorder\n",
    "    def grid_search_on_model(self, get_model, train, recorder, record_file, x, y, tokenizer,\\\n",
    "                             val_size=0.2, shuffle=True, url='a.json'):\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=val_size, shuffle=shuffle)\n",
    "        params = self.next_param(url)\n",
    "        record_start = True\n",
    "        while params != None:\n",
    "            print(params)\n",
    "            model = get_model(params, tokenizer)\n",
    "            train_auc, val_auc, val_loss = train(model, x_train, y_train, x_val, y_val, params)\n",
    "            recorder(record_file, params, record_start, train_auc, val_auc, val_loss)\n",
    "            record_start = False\n",
    "            params = self.next_param(url)\n",
    "            \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# record grid search results\n",
    "def recorder(record_file, params, initialize, train_auc, val_auc, val_loss):\n",
    "    if initialize:\n",
    "        head = ''\n",
    "        for x in params.keys():\n",
    "            head += x + ','\n",
    "        head += 'train_auc,val_auc,val_loss\\n'\n",
    "        with open(record_file, 'w') as f: f.write(head)\n",
    "    r = ''\n",
    "    for x in params.values():\n",
    "        r += str(x) + ','\n",
    "    r += '%.6f,%.6f,%.6f\\n'%(train_auc, val_auc, val_loss)\n",
    "    with open(record_file, 'a') as f: f.write(r)\n",
    "    print('train_auc: {}, val_auc: {}, val_loss: {}\\n\\n'.format(train_auc, val_auc, val_loss))\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def glove_get_embedding_matrix(embedding_file, embed_size, max_features, tokenizer):\n",
    "#     with open(embedding_file) as ef:\n",
    "#         embeddings_index = dict(get_coefs(*o.strip().split()) for o in ef.readlines())\n",
    "    embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embedding_file, encoding='utf8'))\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i < max_features:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix, nb_words\n",
    "\n",
    "def fasttext_get_embedding_matrix(embedding_file, embed_size, max_features, tokenizer):\n",
    "    word_index = tokenizer.word_index\n",
    "    ft_model = load_model(embedding_file)\n",
    "    nb_words = min(max_features, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i < max_features:\n",
    "            embedding_vector = ft_model.get_word_vector(word).astype('float32')\n",
    "            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix, nb_words\n",
    "\n",
    "def get_embedding_matrix(embed_type, file, size, max_features, tokenizer):\n",
    "    if embed_type == 'fasttext': return fasttext_get_embedding_matrix(file, size, max_features, tokenizer)\n",
    "    else: return glove_get_embedding_matrix(file, size, max_features, tokenizer)\n",
    "\n",
    "def get_rnn_model(params, tokenizer):\n",
    "    embed_type = params['embed_type']\n",
    "    embed_file = params['embed_file']\n",
    "    embed_size = params['embed_size']\n",
    "    lstm_units = params['lstm_units']\n",
    "    lstm_activation = params['lstm_activation']\n",
    "    dense_units = params['dense_units']\n",
    "    activation = params['activation']\n",
    "    embed_trainable = params['embed_trainable']\n",
    "    batch_normalization = params['batch_normalization']\n",
    "    \n",
    "    max_len = params['max_len']\n",
    "    dropout = params['dropout']\n",
    "    loss = params['loss']\n",
    "    label_len = params['label_len']\n",
    "    max_features = params['max_features']\n",
    "    \n",
    "    embedding_matrix, inp_len = get_embedding_matrix(embed_type, embed_file, embed_size, max_features, tokenizer)\n",
    "    input = Input(shape=(max_len, ))\n",
    "    x = Embedding(inp_len, embed_size, weights=[embedding_matrix], trainable=embed_trainable)(input)\n",
    "    for i in range(params['lstm_layer_size']):\n",
    "        x = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=dropout,\\\n",
    "                               recurrent_dropout=dropout, activation=lstm_activation))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    for i in range(params['dense_layer_size']):\n",
    "        x = Dense(dense_units, activation=activation)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(label_len, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, x, y, x_val, y_val, params):\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    patience = params['patience']\n",
    "    model_file = params['model_file']\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    earlystopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n",
    "    callbacks_list = [checkpoint, earlystopping]\n",
    "    history = model.fit(x, y, batch_size=batch_size, epochs=epochs,\\\n",
    "                        validation_data=(x_val,y_val), callbacks=callbacks_list)\n",
    "    \n",
    "    # predict\n",
    "    model.load_weights(model_file)\n",
    "    y_train = model.predict(x, verbose=1)\n",
    "    y_pre = model.predict(x_val, verbose=1)\n",
    "    \n",
    "    # compute the scores\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    if np.isnan(y_val).any():\n",
    "        print('y_val contains Nan')\n",
    "    if np.isnan(y_pre).any():\n",
    "        print('y_pre contains Nan')\n",
    "    val_auc = roc_auc_score(y_val, y_pre)\n",
    "    train_auc = roc_auc_score(y, y_train)\n",
    "    \n",
    "    return val_loss, val_auc, train_auc\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'binary_crossentropy', 'patience': 5, 'max_len': 406, 'max_features': 200000, 'embed_size': 50, 'lstm_activation': 'relu', 'label_len': 6, 'dense_layer_size': 1, 'embed_trainable': True, 'epochs': 40, 'batch_size': 1024, 'activation': 'relu', 'batch_normalization': True, 'dropout': 0.2, 'embed_file': '/home/kai/data/resources/glove/glove.6B.50d.txt', 'dense_units': 50, 'model_file': '/home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5', 'lstm_units': 5, 'lstm_layer_size': 1, 'embed_type': 'glove'}\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.6658 - acc: 0.9597\n",
      "Epoch 00001: val_loss improved from inf to 0.63772, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 981us/step - loss: 0.6657 - acc: 0.9597 - val_loss: 0.6377 - val_acc: 0.9637\n",
      "Epoch 2/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.6127 - acc: 0.9633\n",
      "Epoch 00002: val_loss improved from 0.63772 to 0.58772, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 967us/step - loss: 0.6126 - acc: 0.9632 - val_loss: 0.5877 - val_acc: 0.9637\n",
      "Epoch 3/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.5654 - acc: 0.9632\n",
      "Epoch 00003: val_loss improved from 0.58772 to 0.54284, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 975us/step - loss: 0.5653 - acc: 0.9632 - val_loss: 0.5428 - val_acc: 0.9637\n",
      "Epoch 4/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.9633\n",
      "Epoch 00004: val_loss improved from 0.54284 to 0.50257, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 977us/step - loss: 0.5228 - acc: 0.9632 - val_loss: 0.5026 - val_acc: 0.9637\n",
      "Epoch 5/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.9633\n",
      "Epoch 00005: val_loss improved from 0.50257 to 0.46651, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 972us/step - loss: 0.4847 - acc: 0.9632 - val_loss: 0.4665 - val_acc: 0.9637\n",
      "Epoch 6/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.9632\n",
      "Epoch 00006: val_loss improved from 0.46651 to 0.43421, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 980us/step - loss: 0.4505 - acc: 0.9632 - val_loss: 0.4342 - val_acc: 0.9637\n",
      "Epoch 7/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.9633\n",
      "Epoch 00007: val_loss improved from 0.43421 to 0.40528, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 968us/step - loss: 0.4200 - acc: 0.9632 - val_loss: 0.4053 - val_acc: 0.9637\n",
      "Epoch 8/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.9633\n",
      "Epoch 00008: val_loss improved from 0.40528 to 0.37939, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 980us/step - loss: 0.3926 - acc: 0.9632 - val_loss: 0.3794 - val_acc: 0.9637\n",
      "Epoch 9/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.3682 - acc: 0.9632\n",
      "Epoch 00009: val_loss improved from 0.37939 to 0.35621, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 975us/step - loss: 0.3681 - acc: 0.9632 - val_loss: 0.3562 - val_acc: 0.9637\n",
      "Epoch 10/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.9633\n",
      "Epoch 00010: val_loss improved from 0.35621 to 0.33543, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 979us/step - loss: 0.3462 - acc: 0.9632 - val_loss: 0.3354 - val_acc: 0.9637\n",
      "Epoch 11/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.9632\n",
      "Epoch 00011: val_loss improved from 0.33543 to 0.31680, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 979us/step - loss: 0.3266 - acc: 0.9632 - val_loss: 0.3168 - val_acc: 0.9637\n",
      "Epoch 12/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9633\n",
      "Epoch 00012: val_loss improved from 0.31680 to 0.30007, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 966us/step - loss: 0.3089 - acc: 0.9632 - val_loss: 0.3001 - val_acc: 0.9637\n",
      "Epoch 13/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9632\n",
      "Epoch 00013: val_loss improved from 0.30007 to 0.28506, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.2931 - acc: 0.9632 - val_loss: 0.2851 - val_acc: 0.9637\n",
      "Epoch 14/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.9632\n",
      "Epoch 00014: val_loss improved from 0.28506 to 0.27155, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.2789 - acc: 0.9632 - val_loss: 0.2715 - val_acc: 0.9637\n",
      "Epoch 15/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.9632\n",
      "Epoch 00015: val_loss improved from 0.27155 to 0.25940, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 968us/step - loss: 0.2661 - acc: 0.9632 - val_loss: 0.2594 - val_acc: 0.9637\n",
      "Epoch 16/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9633\n",
      "Epoch 00016: val_loss improved from 0.25940 to 0.24844, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.2546 - acc: 0.9632 - val_loss: 0.2484 - val_acc: 0.9637\n",
      "Epoch 17/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9632\n",
      "Epoch 00017: val_loss improved from 0.24844 to 0.23857, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 979us/step - loss: 0.2442 - acc: 0.9632 - val_loss: 0.2386 - val_acc: 0.9637\n",
      "Epoch 18/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9632\n",
      "Epoch 00018: val_loss improved from 0.23857 to 0.22967, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 980us/step - loss: 0.2348 - acc: 0.9632 - val_loss: 0.2297 - val_acc: 0.9637\n",
      "Epoch 19/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9633\n",
      "Epoch 00019: val_loss improved from 0.22967 to 0.22161, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 967us/step - loss: 0.2264 - acc: 0.9632 - val_loss: 0.2216 - val_acc: 0.9637\n",
      "Epoch 20/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9633\n",
      "Epoch 00020: val_loss improved from 0.22161 to 0.21434, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 974us/step - loss: 0.2187 - acc: 0.9632 - val_loss: 0.2143 - val_acc: 0.9637\n",
      "Epoch 21/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9632\n",
      "Epoch 00021: val_loss improved from 0.21434 to 0.20775, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 979us/step - loss: 0.2118 - acc: 0.9632 - val_loss: 0.2078 - val_acc: 0.9637\n",
      "Epoch 22/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9632\n",
      "Epoch 00022: val_loss improved from 0.20775 to 0.20178, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 124s 972us/step - loss: 0.2056 - acc: 0.9632 - val_loss: 0.2018 - val_acc: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9633\n",
      "Epoch 00023: val_loss improved from 0.20178 to 0.19637, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.1999 - acc: 0.9632 - val_loss: 0.1964 - val_acc: 0.9637\n",
      "Epoch 24/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9632\n",
      "Epoch 00024: val_loss improved from 0.19637 to 0.19146, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.1948 - acc: 0.9632 - val_loss: 0.1915 - val_acc: 0.9637\n",
      "Epoch 25/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9632\n",
      "Epoch 00025: val_loss improved from 0.19146 to 0.18700, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 967us/step - loss: 0.1901 - acc: 0.9632 - val_loss: 0.1870 - val_acc: 0.9637\n",
      "Epoch 26/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9633\n",
      "Epoch 00026: val_loss improved from 0.18700 to 0.18296, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 980us/step - loss: 0.1859 - acc: 0.9632 - val_loss: 0.1830 - val_acc: 0.9637\n",
      "Epoch 27/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9633\n",
      "Epoch 00027: val_loss improved from 0.18296 to 0.17927, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 966us/step - loss: 0.1820 - acc: 0.9632 - val_loss: 0.1793 - val_acc: 0.9637\n",
      "Epoch 28/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9633\n",
      "Epoch 00028: val_loss improved from 0.17927 to 0.17593, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 127s 991us/step - loss: 0.1785 - acc: 0.9632 - val_loss: 0.1759 - val_acc: 0.9637\n",
      "Epoch 29/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9632\n",
      "Epoch 00029: val_loss improved from 0.17593 to 0.17288, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 123s 966us/step - loss: 0.1754 - acc: 0.9632 - val_loss: 0.1729 - val_acc: 0.9637\n",
      "Epoch 30/40\n",
      "126976/127656 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9632\n",
      "Epoch 00030: val_loss improved from 0.17288 to 0.17011, saving model to /home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5\n",
      "127656/127656 [==============================] - 125s 978us/step - loss: 0.1725 - acc: 0.9632 - val_loss: 0.1701 - val_acc: 0.9637\n",
      "Epoch 31/40\n",
      " 89088/127656 [===================>..........] - ETA: 35s - loss: 0.1699 - acc: 0.9634"
     ]
    }
   ],
   "source": [
    "param_class = grid_search_generator()\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=param_class.params['max_features'][0])\n",
    "tokenizer.fit_on_texts(sentences.values)\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_sentences.values)\n",
    "\n",
    "x = sequence.pad_sequences(tokenized_train, maxlen=param_class.params['max_len'][0])\n",
    "y = train[label_cols].values\n",
    "\n",
    "param_class.grid_search_on_model(get_rnn_model, train_model, recorder, RECORD, x, y, tokenizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embed_trainable': True, 'patience': 5, 'embed_type': 'glove', 'batch_size': 1024, 'dense_units': 50, 'epochs': 40, 'activation': 'relu', 'model_file': '/home/kai/data/kaggle/toxic/hz/model/lstm_best.hdf5', 'max_len': 406, 'loss': 'binary_crossentropy', 'max_features': 200000, 'lstm_layer_size': 1, 'lstm_activation': 'tanh', 'dropout': 0.2, 'label_len': 6, 'lstm_units': 5, 'embed_file': '/home/kai/data/resources/glove/glove.6B.50d.txt', 'batch_normalization': True, 'dense_layer_size': 1, 'embed_size': 50}\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/40\n",
      "109568/127656 [========================>.....] - ETA: 19s - loss: 0.3810 - acc: 0.8783"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e9c2758582db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mparam_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search_on_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_rnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECORD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a692c34c575d>\u001b[0m in \u001b[0;36mgrid_search_on_model\u001b[0;34m(self, get_model, train, recorder, record_file, x, y, tokenizer, val_size, shuffle, url)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mrecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mrecord_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-92942977ed31>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x, y, x_val, y_val, params)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mearlystopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#continue case\n",
    "\n",
    "param_class = grid_search_generator('a.json')\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=param_class.params['max_features'][0])\n",
    "tokenizer.fit_on_texts(sentences.values)\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_sentences.values)\n",
    "\n",
    "x = sequence.pad_sequences(tokenized_train, maxlen=param_class.params['max_len'][0])\n",
    "y = train[label_cols].values\n",
    "\n",
    "param_class.grid_search_on_model(get_rnn_model, train_model, recorder, RECORD, x, y, tokenizer)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(y).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-977511115cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "y1 = np.array([0,0,0,1])\n",
    "y2 = np.array([0,0,0,0])\n",
    "roc_auc_score(y2, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
