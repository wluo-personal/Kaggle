{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from base_layer_utils import BaseLayerDataRepo, BaseLayerResultsRepo, ModelName\n",
    "from base_layer_utils import compute_layer1_oof\n",
    "from base_layer_utils import SklearnBLE\n",
    "\n",
    "#from fast_text_data import FastTextDataGenerator# fasttext_data_process \n",
    "#from tfidf_data import tfidf_data_process\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>set</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>comment_text_polarity</th>\n",
       "      <th>comment_text_ori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                id  \\\n",
       "0  explanation why the edits made under my userna...  0000997932d777bf   \n",
       "1  d aww he matches this background colour i m se...  000103f0d9cfb60f   \n",
       "\n",
       "   identity_hate  insult  obscene    set  severe_toxic  threat  toxic  \\\n",
       "0            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "1            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "\n",
       "   toxicity                              comment_text_polarity  \\\n",
       "0       0.0  explanation why the edits made under my userna...   \n",
       "1       0.0  d aww he matches this background colour i m se...   \n",
       "\n",
       "                                    comment_text_ori  \n",
       "0  Explanation\\nWhy the edits made under my usern...  \n",
       "1  D'aww! He matches this background colour I'm s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('~/data/toxic/data/train_preprocessed_clean.csv')\n",
    "train_ori = pd.read_csv('~/data/toxic/data/train.csv')\n",
    "train = train.merge(train_ori[['comment_text', 'id']], on='id', suffixes=('', '_ori'))\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>set</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>comment_text_polarity</th>\n",
       "      <th>comment_text_ori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yo bitch ja rule is more succesful then you ll...</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yo bitch ja rule is more succesful then you ll...</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from rfc the title is fine as it is imo</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from rfc the title is fine as it is imo cleane...</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                id  \\\n",
       "0  yo bitch ja rule is more succesful then you ll...  00001cee341fdb12   \n",
       "1            from rfc the title is fine as it is imo  0000247867823ef7   \n",
       "\n",
       "   identity_hate  insult  obscene   set  severe_toxic  threat  toxic  \\\n",
       "0            NaN     NaN      NaN  test           NaN     NaN    NaN   \n",
       "1            NaN     NaN      NaN  test           NaN     NaN    NaN   \n",
       "\n",
       "   toxicity                              comment_text_polarity  \\\n",
       "0       NaN  yo bitch ja rule is more succesful then you ll...   \n",
       "1       NaN  from rfc the title is fine as it is imo cleane...   \n",
       "\n",
       "                                    comment_text_ori  \n",
       "0  Yo bitch Ja Rule is more succesful then you'll...  \n",
       "1  == From RfC == \\n\\n The title is fine as it is...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('~/data/toxic/data/test_preprocessed_clean.csv')\n",
    "test_ori = pd.read_csv('~/data/toxic/data/test.csv')\n",
    "test = test.merge(test_ori[['comment_text', 'id']], on='id', suffixes=('', '_ori'))\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train = train.head(10000)\n",
    "test = test.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 12), (153164, 12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '~/data/toxic/data/'\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop(label_cols, axis=1, inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bldr = BaseLayerDataRepo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfdata_compatible_models= [ModelName.LGB, ModelName.LGB_PERLABEL, ModelName.NBLGB, ModelName.NBLGB_PERLABEL,\n",
    "                              ModelName.XGB, ModelName.XGB_PERLABEL, ModelName.NBXGB, ModelName.NBXGB_PERLABEL,\n",
    "                              ModelName.LOGREG, ModelName.LOGREG_PERLABEL, ModelName.NBLOGREG, ModelName.NBLOGREG_PERLABEL,\n",
    "                              ModelName.LSVC, ModelName.LSVC_PERLABEL, ModelName.NBLSVC, ModelName.NBLSVC_PERLABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting word\n",
      "transforming train word\n",
      "transforming test word\n",
      "tfidf(word level) done\n",
      "tfidf_word_(1, 1)_30000_1_1.0 is added to the base layer data repo\n"
     ]
    }
   ],
   "source": [
    "bldr.add_tfidf_data(train_sentence=train['comment_text'], test_sentence=test['comment_text'], \n",
    "                    y_train=train[label_cols], label_cols=label_cols, \n",
    "                    compatible_models=tfidfdata_compatible_models, word_ngram=(1,1), word_max=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_id: tfidf_word_(1, 1)_30000_1_1.0 \n",
      "\tx_train: (159571, 30000)\tx_test: (153164, 30000)\n",
      "\ty_train type: <class 'dict'>\n",
      "\tcompatible_models: {<ModelName.NBXGB: 2>, <ModelName.NBLGB: 6>, <ModelName.XGB: 1>, <ModelName.NBXGB_PERLABEL: 4>, <ModelName.LOGREG: 9>, <ModelName.LOGREG_PERLABEL: 11>, <ModelName.NBLOGREG: 10>, <ModelName.NBLSVC_PERLABEL: 16>, <ModelName.NBLGB_PERLABEL: 8>, <ModelName.NBLSVC: 14>, <ModelName.LSVC_PERLABEL: 15>, <ModelName.XGB_PERLABEL: 3>, <ModelName.NBLOGREG_PERLABEL: 12>, <ModelName.LSVC: 13>, <ModelName.LGB_PERLABEL: 7>, <ModelName.LGB: 5>}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(bldr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start generating oof_train, oof_test,  layer1 estimater prediction and model data id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment any model to add to the model pool\n",
    "\n",
    "model_pool = {}\n",
    "\n",
    "SEED = 1001\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "###################################  Logreg normal   ####################################\n",
    "logreg_ble = SklearnBLE(LogisticRegression, nb=False, seed=SEED)\n",
    "model_pool[ModelName.LOGREG] = logreg_ble\n",
    "###################################  Logreg nb       ####################################\n",
    "nblogreg_params = {'C':0.25}\n",
    "nblogreg_ble = SklearnBLE(LogisticRegression, nb=True, seed=SEED, params=nblogreg_params)\n",
    "model_pool[ModelName.NBLOGREG] = nblogreg_ble\n",
    "###################################  Logreg per label  ##################################\n",
    "logreg_params_per_label = {\n",
    "    'identity_hate': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'insult': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'obscene': {'C': 0.7, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'severe_toxic': {'C': 0.3,'class_weight': None, 'fit_intercept': True},\n",
    "    'threat': {'C': 0.05, 'class_weight': 'balanced', 'fit_intercept': True}, \n",
    "    'toxic': {'C': 0.8, 'class_weight': 'balanced', 'fit_intercept': True}\n",
    "}\n",
    "logreg_per_label_ble = SklearnBLE(LogisticRegression, nb=False, seed=SEED, per_label_params=logreg_params_per_label)\n",
    "model_pool[ModelName.LOGREG_PERLABEL] = logreg_per_label_ble\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# ###################################  Logreg normal   ####################################\n",
    "# lsvc_ble = SklearnBLE(LinearSVC, need_calibrated_classifier_cv=True)\n",
    "# model_pool[ModelName.LSVC] = lsvc_ble\n",
    "# ###################################  Logreg nb   ####################################\n",
    "# nblsvc_params = {'C':0.02}\n",
    "# nblsvc_ble = SklearnBLE(LinearSVC, nb=True, seed=SEED, params=nblogreg_params, need_calibrated_classifier_cv=True)\n",
    "# model_pool[ModelName.NBLSVC] = nblsvc_ble\n",
    "\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# ###################################  XGB normal   ####################################\n",
    "# xgb_params = {'n_jobs': 10}\n",
    "# xgb_ble = SklearnBLE(XGBClassifier, seed=SEED, params=xgb_params)# XGBoostBLE(params=xgb_params, nb=False, seed=SEED)\n",
    "# model_pool[ModelName.XGB] = xgb_ble\n",
    "# ###################################  XGB nb   ####################################\n",
    "# nbxgb_ble = SklearnBLE(XGBClassifier, nb=True, seed=SEED, params=xgb_params)\n",
    "# model_pool[ModelName.NBXGB] = nbxgb_ble\n",
    "\n",
    "\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "# ###################################  LGB normal   ####################################\n",
    "# lgb_params = {'n_jobs': 8,'n_estimators': 50}\n",
    "# lgb_ble = SklearnBLE(LGBMClassifier, seed=SEED, params=lgb_params)\n",
    "# model_pool[ModelName.LGB] = lgb_ble\n",
    "# ###################################  LGB nb   ####################################\n",
    "# nblgb_ble = SklearnBLE(LGBMClassifier, nb=True, seed=SEED, params=lgb_params)\n",
    "# model_pool[ModelName.NBLGB] = nblgb_ble\n",
    "# ###################################  LGB per label   ####################################\n",
    "# lgb_params_per_label = {}\n",
    "# lgb_params_per_label['toxic'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# lgb_params_per_label['severe_toxic'] = {'n_jobs': 8, 'num_leaves': 11}\n",
    "# lgb_params_per_label['obscene'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# lgb_params_per_label['threat'] = {'n_jobs': 8, 'num_leaves': 11}\n",
    "# lgb_params_per_label['insult'] = {'n_jobs': 8,'num_leaves': 11}\n",
    "# lgb_params_per_label['identity_hate'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# nblgb_per_label_ble = SklearnBLE(LGBMClassifier, seed=SEED, per_label_params=lgb_params_per_label)\n",
    "# model_pool[ModelName.NBLGB_PERLABEL] = nblgb_per_label_ble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelName.LOGREG: 9>,\n",
       " <ModelName.NBLOGREG: 10>,\n",
       " <ModelName.LOGREG_PERLABEL: 11>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.head(2)['id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing... label: toxic        model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: toxic        model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: toxic        model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: severe_toxic model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: severe_toxic model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: severe_toxic model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: obscene      model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: obscene      model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: obscene      model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: threat       model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: threat       model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: threat       model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: insult       model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: insult       model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: insult       model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: identity_hate model_data_id: ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: identity_hate model_data_id: ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n",
      "Computing... label: identity_hate model_data_id: ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "dimension before selecting: train:(159571, 30000) test:(153164, 30000)\n",
      "dimension after selecting: train:(159571, 15000) test:(153164, 15000)\n"
     ]
    }
   ],
   "source": [
    "layer1_est_preds, layer1_oof_train, layer1_oof_mean_test, model_data_id_list = compute_layer1_oof(bldr, model_pool, label_cols, sfm_threshold='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit the layer 1 estimator predictions. If they look fine, save them to BaseLayerResultsRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0',\n",
       " 'ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0',\n",
       " 'ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate files to submit from layer 1 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions_to_file(base_layer_est_preds):\n",
    "    for key in base_layer_est_preds:\n",
    "        submission = pd.read_csv(PATH + 'sample_submission.csv')#.head(1000)\n",
    "        submission[label_cols] = base_layer_est_preds[key]\n",
    "        sub_id = int(time.time())\n",
    "        print(sub_id)\n",
    "        submission.to_csv('./BaseEstPreds/' + key + '_' + str(sub_id) + '.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522094161\n",
      "1522094166\n",
      "1522094171\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer1_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check before save to BaseLayerResultsRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0',\n",
       " 'ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0',\n",
       " 'ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_id_list # model_data we just computed in the layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obscene', 'identity_hate', 'severe_toxic', 'threat', 'insult', 'toxic']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_oof_train) # list keys (which are labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_train['toxic']) # number of models to stack (each model will predict one set of toxic, servere_toxic, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_train['toxic'][0]) # examples in oof_train (meta features, x_train) (meta labels are in train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obscene', 'identity_hate', 'severe_toxic', 'threat', 'insult', 'toxic']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_oof_mean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_mean_test['toxic'][0]) # examples in oof_test (will be used by meta model (after validation) to predict the final prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the doc string to BaseLayerResultsRepo to set params\n",
    "base_layer_results_repo = BaseLayerResultsRepo(load_from_file=False, filepath='obj/WithPreprocessedFile/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.add(layer1_oof_train, layer1_oof_mean_test, layer1_est_preds, model_data_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0 already existed in the repo. score: 0 update to 0.9888\n",
      "ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0 already existed in the repo. score: 0 update to 0.9777\n",
      "ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0 already existed in the repo. score: 0 update to 0.9666\n"
     ]
    }
   ],
   "source": [
    " # let's give some fake scores\n",
    "base_layer_results_repo.add_score('ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0', 0.9888)\n",
    "base_layer_results_repo.add_score('ModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0', 0.9777)\n",
    "base_layer_results_repo.add_score('ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0', 0.9666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next step: go to stack_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack 1\n"
     ]
    }
   ],
   "source": [
    "print('stack 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
