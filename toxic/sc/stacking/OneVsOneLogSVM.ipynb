{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def onevsone_data_process():\n",
    "    \"\"\"\n",
    "    wei/Toxic/models/data/cleaned_train.csv\n",
    "    wei/Toxic/models/data/cleaned_test.csv\n",
    "\n",
    "    return :x_train: sparse matrix\n",
    "            y_train: DataFrame\n",
    "            x_test: sparse matrix\n",
    "    \"\"\"\n",
    "    train = pd.read_csv('/home/kai/data/wei/Toxic/models/data/cleaned_train.csv')\n",
    "    test = pd.read_csv('/home/kai/data/wei/Toxic/models/data/cleaned_test.csv')\n",
    "    label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "    train_sentence = train['comment_text_cleaned_polarity']\n",
    "    test_sentence = test['comment_text_cleaned_polarity']\n",
    "\n",
    "    train_sentence_retain_punctuation = train['comment_text_cleaned_retain_punctuation']\n",
    "    test_sentence_retain_punctuation = test['comment_text_cleaned_retain_punctuation']\n",
    "    print('loading data done!')\n",
    "    #########################################\n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "    char_vectorizer = TfidfVectorizer(ngram_range=(2,5), \n",
    "                                      strip_accents='unicode', \n",
    "                                      max_features=200000, \n",
    "                                      analyzer='char', \n",
    "                                      sublinear_tf=True)\n",
    "    \n",
    "\n",
    "    print('fitting char')\n",
    "    char_vectorizer.fit(train_sentence_retain_punctuation.values)\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(train_sentence.values)\n",
    "\n",
    "\n",
    "    print('transforming train char')\n",
    "    train_char = char_vectorizer.transform(train_sentence_retain_punctuation.values)\n",
    "    print('transforming train phrase')\n",
    "    train_phrase = phrase_vectorizer.transform(train_sentence.values)\n",
    "\n",
    "\n",
    "    print('transforming test char')\n",
    "    test_char = char_vectorizer.transform(test_sentence_retain_punctuation.values)\n",
    "    print('transforming test phrase')\n",
    "    test_phrase = phrase_vectorizer.transform(test_sentence.values)\n",
    "\n",
    "\n",
    "    x_train = hstack((train_char, train_phrase), format='csr')\n",
    "    x_test = hstack((test_char, test_phrase), format='csr')\n",
    "    y_train = train[label_cols]\n",
    "    idd = 'wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w'\n",
    "    \n",
    "    return (x_train, y_train, x_test, idd)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
