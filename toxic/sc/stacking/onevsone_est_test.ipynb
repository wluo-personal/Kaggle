{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "\n",
    "class BaseLayerEstimator1(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, x_train, y_train):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x_train):\n",
    "        pass \n",
    "    \n",
    "    \n",
    "\n",
    "class OneVSOneReg(BaseLayerEstimator1):\n",
    "    def __init__(self, x_train, y_train, model='logistic'):\n",
    "        \"\"\"\n",
    "        x_train: sparse matrix, raw tfidf\n",
    "        y_train: dataframe, with only label columns. should be 6 columns in total\n",
    "        model: only support logistic or svc\n",
    "        \"\"\"\n",
    "        self.r = {}\n",
    "        self.setModelName(model)\n",
    "        assert self.model_name in ['logistic', 'svc']\n",
    "        self.param = {}\n",
    "        self.param['logistic'] = {'identity_hate': 9.0,\n",
    "                                     'insult': 1.5,\n",
    "                                     'obscene': 1.0,\n",
    "                                     'severe_toxic': 4.0,\n",
    "                                     'threat': 9.0,\n",
    "                                     'toxic': 2.7}\n",
    "        self.param['svc'] = {'identity_hate': 0.9,\n",
    "                             'insult': 0.15,\n",
    "                             'obscene': 0.15,\n",
    "                             'severe_toxic': 0.15,\n",
    "                             'threat': 1.0,\n",
    "                             'toxic': 0.29}\n",
    "        \n",
    "        \n",
    "        \n",
    "        for col in y_train.columns:\n",
    "            print('calculating naive bayes for {}'.format(col))\n",
    "            self.r[col] = np.log(self.pr(1, y_train[col].values, x_train) / self.pr(0, y_train[col], x_train))\n",
    "        print('initializing done')\n",
    "        print('OneVsOne is using {} kernel'.format(self.model_name))\n",
    "        \n",
    "    def setModelName(self, name):\n",
    "        self.model_name = name\n",
    "        assert self.model_name in ['logistic', 'svc']\n",
    "        print('OneVsOne is using {} kernel'.format(self.model_name))\n",
    "        \n",
    "    def pr(self, y_i, y, train_features):\n",
    "        p = train_features[np.array(y==y_i)].sum(0)\n",
    "        return (p + 1) / (np.array(y == y_i).sum() + 1)\n",
    "    \n",
    "    def oneVsOneSplit(self, x_train, y_train, label):\n",
    "        print('Starting One vs One dataset splitting')\n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = y_train.values\n",
    "        model_train = x_train[np.array(y_train == 1)]\n",
    "        y_model_train = y_train[np.array(y_train == 1)]\n",
    "        non_model_train = x_train[np.array(y_train == 0)]\n",
    "        non_model_train = non_model_train[:model_train.shape[0]]\n",
    "        y_non_model_train = y_train[np.array(y_train == 0)]\n",
    "        y_non_model_train = y_non_model_train[:model_train.shape[0]]\n",
    "        x_model_stack = vstack([model_train, non_model_train])\n",
    "        y_model_stack = np.concatenate([y_model_train, y_non_model_train])\n",
    "        x_nb = x_model_stack.multiply(self.r[label]).tocsr()\n",
    "        y_nb = y_model_stack\n",
    "        print('splitting done!')\n",
    "        return (x_nb, y_nb)\n",
    "    \n",
    "    def train(self, x_train, y_train, label, oneVSone=True):\n",
    "        ### construct one vs one\n",
    "        if oneVSone:\n",
    "            x_nb, y_nb = self.oneVsOneSplit(x_train, y_train, label)\n",
    "        else:\n",
    "            print('Training on whole dataset. One on One is diabled!')\n",
    "            if isinstance(y_train, pd.Series):\n",
    "                y_nb = y_train.values\n",
    "            else:\n",
    "                y_nb = y_train\n",
    "            x_nb = x_train\n",
    "        ### start training\n",
    "        if self.model_name is 'logistic':\n",
    "            print('start training logistic regression')\n",
    "            if oneVSone:\n",
    "                self.model = LogisticRegression(C=self.param['logistic'][label])\n",
    "            else:\n",
    "                self.model = LogisticRegression(C=0.25)\n",
    "            self.model.fit(x_nb, y_nb)\n",
    "            print('training done')\n",
    "            \n",
    "        else:\n",
    "            print('start training linear svc regression')\n",
    "            if oneVSone:\n",
    "                 lsvc = LinearSVC(C=self.param['svc'][label])\n",
    "            else:\n",
    "                lsvc = LinearSVC(C=0.02)\n",
    "            self.model = CalibratedClassifierCV(lsvc) \n",
    "            self.model.fit(x_nb, y_nb)\n",
    "            print('training done')\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self, x_test, label):\n",
    "        print('applying naive bayes to dataset')\n",
    "        x_nb_test = x_test.multiply(self.r[label]).tocsr()\n",
    "        print('predicting')\n",
    "        pred = self.model.predict_proba(x_nb_test)[:,1]\n",
    "        print('predicting done')\n",
    "        return pred\n",
    "    \n",
    "##### example        \n",
    "# aa = OneVSOneReg(train_tfidf, train[label_cols], model='logistic')\n",
    "# aa.setModelName('svc')\n",
    "# aa.train(train_tfidf,train['toxic'], 'toxic')\n",
    "# aa.predict(test_tfidf, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from onevsone_data import onevsone_data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data done!\n",
      "fitting char\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f22d2b65ec87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_1v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_1v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_1v1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_id_1v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monevsone_data_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/shiyi/stacking/onevsone_data.py\u001b[0m in \u001b[0;36monevsone_data_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitting char'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mchar_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentence_retain_punctuation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitting phrase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mphrase_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \"\"\"\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_1v1, y_train_1v1, x_test_1v1, data_id_1v1 = onevsone_data_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsOne is using svc kernel\n",
      "calculating naive bayes for toxic\n",
      "calculating naive bayes for severe_toxic\n",
      "calculating naive bayes for obscene\n",
      "calculating naive bayes for threat\n",
      "calculating naive bayes for insult\n",
      "calculating naive bayes for identity_hate\n",
      "initializing done\n",
      "OneVsOne is using svc kernel\n"
     ]
    }
   ],
   "source": [
    "onevsone_svc = OneVSOneReg(x_train_1v1, y_train_1v1, model='svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting One vs One dataset splitting\n",
      "splitting done!\n",
      "start training linear svc regression\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "onevsone_svc.train(x_train_1v1, y_train_1v1['toxic'], 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying naive bayes to dataset\n",
      "predicting\n",
      "predicting done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99999993,  0.02563926,  0.25582663, ...,  0.00467807,\n",
       "        0.08956339,  0.99991951])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onevsone_svc.predict(x_test_1v1, 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
