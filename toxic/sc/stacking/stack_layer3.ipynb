{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from base_layer_utils import BaseLayerDataRepo, BaseLayerResultsRepo, ModelName\n",
    "from base_layer_utils import LightgbmBLE, SklearnBLE, XGBoostBLE\n",
    "\n",
    "#from fast_text_data import fasttext_data_process\n",
    "#from tfidf_data import tfidf_data_process\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.cross_validation import KFold # replace with model_selection?\n",
    "#from sklearn.model_selection import KFold\n",
    "import time, re, gc\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 27)\n",
      "(153164, 21)\n"
     ]
    }
   ],
   "source": [
    "PATH = '~/data/toxic/data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'cleaned_train.csv')\n",
    "test = pd.read_csv(PATH + 'cleaned_test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select layer2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from file\n"
     ]
    }
   ],
   "source": [
    "base_layer_results_repo = BaseLayerResultsRepo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827\tModelName.NBLSVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "0.9826\tModelName.NBSVM_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "0.9819\tModelName.ONESVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "0.9818\tModelName.ONELOGREG_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "0.9815\tModelName.NBLSVC_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "0.9803\tModelName.NBSVM_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "0.9796\tModelName.LOGREG_wordtfidf_word_(1, 1)_100000_1_1.0_char_(2, 5)_200000_1_1.0\n",
      "0.9794\tModelName.LGB_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "0.9793\tModelName.LOGREG_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "0.9786\tModelName.ONESVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w\n",
      "0.9774\tModelName.NBLSVC_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "0.9768\tModelName.NBSVM_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "0.9765\tModelName.NBLGB_wordtfidf_word_(1, 1)_100000_1_1.0_char_(2, 5)_200000_1_1.0\n",
      "0.9765\tModelName.NBLSVC_tfidf_word_df2_ng(1, 2)_wmf200000\n",
      "0.976\tModelName.LOGREG_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "0.9752\tModelName.LOGREG_tfidf_word_df2_ng(1, 2)_wmf200000\n",
      "0.9745\tModelName.LOGREG_wordtfidf_word_(1, 1)_100000_1_1.0_char_(0, 0)_100000_1_1.0\n",
      "0.9726\tModelName.LGB_tfidf_word_df2_ng(1, 2)_wmf200000\n",
      "0.9723\tModelName.LGB_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "0.9662\tModelName.NBLGB_wordtfidf_word_(1, 1)_100000_1_1.0_char_(0, 0)_100000_1_1.0\n",
      "0.09854\tModelName.LOGREG_layer2\n",
      "0.09854\tModelName.XGB_layer2\n",
      "0.09853\tModelName.XGB_layer2_usingthebadhalf\n",
      "0.09852\tModelName.LOGREG_1sthalf16_layer2\n",
      "0.09851\tModelName.LOGREG_2ndhalf16_layer2\n",
      "0.09851\tModelName.LOGREG_all16_layer2\n",
      "0.09851\tModelName.XGB_layer2_UsingAll14\n",
      "0.09851\tModelName.LOGREG_layer2_GoodHalfOfXGB\n",
      "0.09839\tModelName.XGB_w_globalfeatures_1stHalf14_layer2\n",
      "0.09827\tModelName.LGB_layer2\n",
      "0.09825\tModelName.RNN_rnn_data_001\n",
      "0.009839\tModelName.LGB_w_features_All16_seed1001_layer2\n",
      "0.009835\tModelName.LGB_w_features_1stHalf16_seed1001_layer2\n",
      "0.009833\tModelName.LOGREG_w_features_All16_seed1001_layer2\n",
      "0.009827\tModelName.LOGREG_w_features_2ndHalf16_seed1001_layer2\n",
      "0.009821\tModelName.LGB_w_features_2ndHalf16_seed1001_layer2\n",
      "0.009818\tModelName.LOGREG_w_features_1stHalf16_seed1001_layer2\n",
      "0\tModelName.XGB_w_features_2ndHalf16_seed1001_layer2\n",
      "0\tModelName.RNN_rnn_data_fasttext_200_300\n",
      "0\tModelName.XGB_w_features_1stHalf16_seed1001_layer2\n",
      "0\tModelName.XGB_w_features_All16_seed1001_layer2\n"
     ]
    }
   ],
   "source": [
    "_ = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base_layer_results_repo.remove('ModelName.NBSVM_tfidf_word_df2_ng(1, 2)_wmf200000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_layer_results_repo.remove('ModelName.LGB_layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = [\n",
    "    'ModelName.LGB_w_features_All16_seed1001_layer2',\n",
    "    'ModelName.LGB_w_features_1stHalf16_seed1001_layer2',\n",
    "    'ModelName.LOGREG_w_features_All16_seed1001_layer2',\n",
    "    'ModelName.LOGREG_w_features_2ndHalf16_seed1001_layer2',\n",
    "    'ModelName.LGB_w_features_2ndHalf16_seed1001_layer2',\n",
    "    'ModelName.LOGREG_w_features_1stHalf16_seed1001_layer2',\n",
    "    'ModelName.XGB_w_features_2ndHalf16_seed1001_layer2',\n",
    "    'ModelName.XGB_w_features_All16_seed1001_layer2',\n",
    "    'ModelName.XGB_w_features_1stHalf16_seed1001_layer2',\n",
    "    'ModelName.NBLSVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real',\n",
    "    'ModelName.LGB_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_oof_train_loaded, layer1_oof_test_loaded, layer1_est_preds_loaded = base_layer_results_repo.get_results(threshold=0.976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName.LOGREG_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "ModelName.LOGREG_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "ModelName.NBLSVC_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "ModelName.NBSVM_tfidf_word_df2_ng(1, 1)_wmf200000\n",
      "ModelName.LOGREG_wordtfidf_word_(1, 1)_100000_1_1.0_char_(2, 5)_200000_1_1.0\n",
      "ModelName.NBSVM_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "ModelName.NBSVM_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "ModelName.NBLSVC_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "ModelName.ONESVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "ModelName.ONELOGREG_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "ModelName.NBLSVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w_real\n",
      "ModelName.LGB_tfidf_wordchar_charmaxdf0.300000_ng(1, 2)_wmf100000_cmf100000\n",
      "ModelName.NBLGB_wordtfidf_word_(1, 1)_100000_1_1.0_char_(2, 5)_200000_1_1.0\n",
      "ModelName.NBLSVC_tfidf_word_df2_ng(1, 2)_wmf200000\n",
      "ModelName.ONESVC_wordtfidf_ng13_mf10w_chartfidf_ng25_mf20w\n"
     ]
    }
   ],
   "source": [
    "for i, key in enumerate(layer1_est_preds_loaded.keys()):\n",
    "    print(key)\n",
    "    #print(pd.DataFrame(layer1_est_preds_loaded[key]).describe())\n",
    "    if i == 0:\n",
    "        blend = layer1_est_preds_loaded[key]\n",
    "    else:\n",
    "        blend += layer1_est_preds_loaded[key]\n",
    "\n",
    "print(i+1)\n",
    "blend /= i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.238268</td>\n",
       "      <td>0.042403</td>\n",
       "      <td>0.149167</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.135564</td>\n",
       "      <td>0.052887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.347316</td>\n",
       "      <td>0.097724</td>\n",
       "      <td>0.285312</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>0.238925</td>\n",
       "      <td>0.107604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>0.009109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.356963</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.076996</td>\n",
       "      <td>0.029181</td>\n",
       "      <td>0.113123</td>\n",
       "      <td>0.041675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.999418</td>\n",
       "      <td>0.989320</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.994861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0              1              2              3  \\\n",
       "count  153164.000000  153164.000000  153164.000000  153164.000000   \n",
       "mean        0.238268       0.042403       0.149167       0.032390   \n",
       "std         0.347316       0.097724       0.285312       0.058814   \n",
       "min         0.000545       0.002229       0.001659       0.002371   \n",
       "25%         0.012608       0.006459       0.009911       0.009608   \n",
       "50%         0.036056       0.009710       0.016530       0.014505   \n",
       "75%         0.356963       0.021545       0.076996       0.029181   \n",
       "max         0.999991       0.972263       0.999418       0.989320   \n",
       "\n",
       "                   4              5  \n",
       "count  153164.000000  153164.000000  \n",
       "mean        0.135564       0.052887  \n",
       "std         0.238925       0.107604  \n",
       "min         0.001655       0.001755  \n",
       "25%         0.011659       0.009109  \n",
       "50%         0.023393       0.015000  \n",
       "75%         0.113123       0.041675  \n",
       "max         0.996741       0.994861  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(blend).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer2_oof_train_loaded, layer2_oof_test_loaded, layer2_est_preds_loaded = base_layer_results_repo.get_results(chosen_ones=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(layer2_oof_train_loaded['toxic']) == len(layer2_est_preds_loaded) == len(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before we choose which models to assemble, we can do:\n",
    "#### 1. scatter plot analysis to check the diversity\n",
    "#### 2. submit to check if the models have similar performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_layer_oof_per_label(layer1_oof_dict, label):\n",
    "    x = None\n",
    "    data_list = layer1_oof_dict[label]\n",
    "    for i in range(len(data_list)):\n",
    "        if i == 0:\n",
    "            x = data_list[0]\n",
    "        else:\n",
    "            x = np.concatenate((x, data_list[i]), axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. simple blend of two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0 0.9910814282997946\n",
      "toxic 1 0.990771077509489\n",
      "toxic 0.9910856078589341 0.9550000000000001\n",
      "severe_toxic 0 0.9925828223897508\n",
      "severe_toxic 1 0.9919322096940085\n",
      "severe_toxic 0.9928764823290488 0.128\n",
      "obscene 0 0.9962181243081879\n",
      "obscene 1 0.9959665500533149\n",
      "obscene 0.9962206810311406 0.984\n",
      "threat 0 0.9946855970430916\n",
      "threat 1 0.99310288682231\n",
      "threat 0.9948137226753532 0.294\n",
      "insult 0 0.991952202527335\n",
      "insult 1 0.991528941423655\n",
      "insult 0.9919546286846996 0.936\n",
      "identity_hate 0 0.9933174155555204\n",
      "identity_hate 1 0.9925218214135401\n",
      "identity_hate 0.9934864460389672 0.203\n"
     ]
    }
   ],
   "source": [
    "result = np.empty((test.shape[0],len(label_cols)))\n",
    "\n",
    "# mix the first two models\n",
    "for i, label in enumerate(label_cols):\n",
    "    x_train = combine_layer_oof_per_label(layer2_oof_train_loaded, label)\n",
    "    x_test = combine_layer_oof_per_label(layer2_oof_test_loaded, label)\n",
    "    for j in range(x_train.shape[1]):\n",
    "        roc = roc_auc_score(train[label], x_train[:,j])\n",
    "        print(label, j, roc) # print out roc for meta feature on meta label (which is just the original train label)\n",
    "    \n",
    "    roc_scores_of_a_label = []\n",
    "    alphas = np.linspace(0,1,1001)\n",
    "    best_roc = 0\n",
    "    best_alpha = 0\n",
    "    for alpha in alphas:\n",
    "        roc = roc_auc_score(train[label], alpha*x_train[:,0] + (1-alpha)*x_train[:,1])\n",
    "        if roc > best_roc:\n",
    "            best_roc = roc\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(label, best_roc, best_alpha)\n",
    "    result[:,i] = best_alpha*x_test[:,0] + (1-best_alpha)*x_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521125524\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(PATH + 'sample_submission.csv')#.head(1000)\n",
    "submission[label_cols] = result\n",
    "sub_id = int(time.time())\n",
    "print(sub_id)\n",
    "submission.to_csv('./StackPreds/layer2_simpleensemble_' + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer2_oof_train_loaded['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes is disabled\n",
      "LightgbmBLE is initialized\n"
     ]
    }
   ],
   "source": [
    "lgb_stacker_params = {\n",
    "    'max_depth':3, \n",
    "    'metric':\"auc\", \n",
    "    'n_estimators':80, \n",
    "    'num_leaves':8, \n",
    "    'boosting_type':\"gbdt\", \n",
    "    'learning_rate':0.1, \n",
    "    'feature_fraction':0.45,\n",
    "    'colsample_bytree':0.45, \n",
    "    'bagging_fraction':0.8, \n",
    "    'bagging_freq':5, \n",
    "    'reg_lambda':0.2\n",
    "}\n",
    "\n",
    "lgb_stacker = LightgbmBLE(None, None, params=lgb_stacker_params, nb=False, seed=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc = []\n",
    "best_rounds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.empty((test.shape[0],len(label_cols)))\n",
    "for i, label in enumerate(label_cols):\n",
    "    assert train.shape == (159571, 27)\n",
    "    x_train = combine_layer_oof_per_label(layer2_oof_train_loaded, label)\n",
    "    x_test = combine_layer_oof_per_label(layer2_oof_test_loaded, label)\n",
    "    train_set = lgb.Dataset(x_train, train[label])\n",
    "\n",
    "    ########## best rounds ##########\n",
    "    # for cv, val_set is not needed\n",
    "#     res = lgb.cv(lgb_stacker_params, train_set, seed=1001, \n",
    "#            early_stopping_rounds=20, num_boost_round=200)\n",
    "#     best_rounds[label] = len(res['auc-mean'])\n",
    "#     auc.append(res['auc-mean'][-1])\n",
    "#     print('{}:\\t\\t{:.6f}'.format(label, res['auc-mean'][-1]))\n",
    "    \n",
    "    ########## preds ##########\n",
    "    model = lgb.train(lgb_stacker_params, train_set, num_boost_round=best_rounds[label])\n",
    "    result[:, i] = model.predict(x_test)\n",
    "#     lgb_stacker.train(x_train, train[label])\n",
    "#     result[:, i] = lgb_stacker.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'identity_hate': 50,\n",
       "  'insult': 25,\n",
       "  'obscene': 76,\n",
       "  'severe_toxic': 25,\n",
       "  'threat': 30,\n",
       "  'toxic': 80},\n",
       " [0.9851148841380788,\n",
       "  0.9901485741396543,\n",
       "  0.994249389154102,\n",
       "  0.9809193866673652,\n",
       "  0.9863534991636291,\n",
       "  0.9844414726863822],\n",
       " 0.9868712009915352)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rounds, auc, sum(auc)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521085451\n"
     ]
    }
   ],
   "source": [
    "sub_title = 'layer3_lgb_w_bestrounds_9layer2'\n",
    "submission = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "submission[label_cols] = result\n",
    "tempid = int(time.time())\n",
    "print(tempid)\n",
    "submission.to_csv('./StackPreds/TopN_XGB/{}_{}.csv'.format(sub_title, tempid), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.923927</td>\n",
       "      <td>0.315186</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.193077</td>\n",
       "      <td>0.850242</td>\n",
       "      <td>0.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.923927      0.315186  0.914692  0.193077  0.850242   \n",
       "1  0000247867823ef7  0.002651      0.000314  0.000839  0.000295  0.001501   \n",
       "2  00013b17ad220c46  0.002769      0.000314  0.000842  0.000295  0.001505   \n",
       "3  00017563c3f7919a  0.002645      0.000313  0.000839  0.000295  0.001501   \n",
       "4  00017695ad8997eb  0.002689      0.000313  0.000840  0.000295  0.001501   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.435900  \n",
       "1       0.000330  \n",
       "2       0.000333  \n",
       "3       0.000330  \n",
       "4       0.000330  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_stacker = SklearnBLE(LogisticRegression, params={}, seed=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_pool = {}\n",
    "#model_pool[ModelName.XGB] = xgb_stacker\n",
    "model_pool[ModelName.LOGREG] = logreg_stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "def get_oof(clf, x_train, y_train, x_test, nfolds, stratified=False, shuffle=True, seed=1001):\n",
    "    #pdb.set_trace()\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((nfolds, ntest))\n",
    "    if stratified:\n",
    "        kf = StratifiedKFold(n_splits=nfolds, shuffle=shuffle, random_state=seed)\n",
    "    else:\n",
    "        kf = KFold(n_splits=nfolds, shuffle=shuffle, random_state=seed)\n",
    "\n",
    "    for i, (tr_index, te_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr, x_te = x_train[tr_index], x_train[te_index]\n",
    "        y_tr, y_te = y_train.iloc[tr_index], y_train.iloc[te_index]\n",
    "        \n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[te_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
