{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "from enum import Enum\n",
    "class ModelName(Enum):\n",
    "    XGB = 1\n",
    "    LGB = 2\n",
    "    LOGREG = 3\n",
    "    NBSVM = 4\n",
    "    RF = 5 # random forest\n",
    "    RNN = 6\n",
    "    NBLSVC = 7\n",
    "    ONESVC = 8\n",
    "    ONELOGREG = 9\n",
    "\n",
    "\n",
    "class BaseLayerEstimator(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            x_train: np array\n",
    "            y_train: pd series\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x_train):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "class OneVSOneReg(BaseLayerEstimator):\n",
    "    def __init__(self, x_train, y_train, model='logistic'):\n",
    "        \"\"\"\n",
    "        x_train: sparse matrix, raw tfidf\n",
    "        y_train: dataframe, with only label columns. should be 6 columns in total\n",
    "        model: only support logistic or svc\n",
    "        \"\"\"\n",
    "        self.r = {}\n",
    "        self.setModelName(model)\n",
    "        assert self.model_name in ['logistic', 'svc']\n",
    "        self.param = {}\n",
    "        self.param['logistic'] = {'identity_hate': 9.0,\n",
    "                                     'insult': 1.5,\n",
    "                                     'obscene': 1.0,\n",
    "                                     'severe_toxic': 4.0,\n",
    "                                     'threat': 9.0,\n",
    "                                     'toxic': 2.7}\n",
    "        self.param['svc'] = {'identity_hate': 0.9,\n",
    "                             'insult': 0.15,\n",
    "                             'obscene': 0.15,\n",
    "                             'severe_toxic': 0.15,\n",
    "                             'threat': 1.0,\n",
    "                             'toxic': 0.29}\n",
    "        \n",
    "        \n",
    "        \n",
    "        for col in y_train.columns:\n",
    "            print('calculating naive bayes for {}'.format(col))\n",
    "            self.r[col] = np.log(self.pr(1, y_train[col].values, x_train) / self.pr(0, y_train[col], x_train))\n",
    "        print('initializing done')\n",
    "        print('OneVsOne is using {} kernel'.format(self.model_name))\n",
    "        \n",
    "    def setModelName(self, name):\n",
    "        self.model_name = name\n",
    "        assert self.model_name in ['logistic', 'svc']\n",
    "        print('OneVsOne is using {} kernel'.format(self.model_name))\n",
    "        \n",
    "    def pr(self, y_i, y, train_features):\n",
    "        p = train_features[np.array(y==y_i)].sum(0)\n",
    "        return (p + 1) / (np.array(y == y_i).sum() + 1)\n",
    "    \n",
    "    def oneVsOneSplit(self, x_train, y_train, label):\n",
    "        print('Starting One vs One dataset splitting')\n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = y_train.values\n",
    "        model_train = x_train[np.array(y_train == 1)]\n",
    "        y_model_train = y_train[np.array(y_train == 1)]\n",
    "        non_model_train = x_train[np.array(y_train == 0)]\n",
    "        non_model_train = non_model_train[:model_train.shape[0]]\n",
    "        y_non_model_train = y_train[np.array(y_train == 0)]\n",
    "        y_non_model_train = y_non_model_train[:model_train.shape[0]]\n",
    "        x_model_stack = vstack([model_train, non_model_train])\n",
    "        y_model_stack = np.concatenate([y_model_train, y_non_model_train])\n",
    "        x_nb = x_model_stack.multiply(self.r[label]).tocsr()\n",
    "        y_nb = y_model_stack\n",
    "        print('splitting done!')\n",
    "        return (x_nb, y_nb)\n",
    "    \n",
    "    def train(self, x_train, y_train, label):\n",
    "        ### construct one vs one\n",
    "        x_nb, y_nb = self.oneVsOneSplit(x_train, y_train, label)\n",
    "        ### start training\n",
    "        if self.model_name is 'logistic':\n",
    "            print('start training logistic regression')\n",
    "            self.model = LogisticRegression(C=self.param['logistic'][label])\n",
    "            self.model.fit(x_nb, y_nb)\n",
    "            print('training done')\n",
    "            \n",
    "        else:\n",
    "            print('start training linear svc regression')\n",
    "            lsvc = LinearSVC(C=self.param['svc'][label])\n",
    "            self.model = CalibratedClassifierCV(lsvc) \n",
    "            self.model.fit(x_nb, y_nb)\n",
    "            print('training done')\n",
    "        \n",
    "\n",
    "    \n",
    "    def predict(self, x_test, label):\n",
    "        print('applying naive bayes to dataset')\n",
    "        x_nb_test = x_test.multiply(self.r[label]).tocsr()\n",
    "        print('predicting')\n",
    "        pred = self.model.predict_proba(x_nb_test)[:,1]\n",
    "        print('predicting done')\n",
    "        return pred\n",
    "    \n",
    "##### example        \n",
    "# aa = OneVSOneReg(train_tfidf, train[label_cols], model='logistic')\n",
    "# aa.setModelName('svc')\n",
    "# aa.train(train_tfidf,train['toxic'], 'toxic')\n",
    "# aa.predict(test_tfidf, 'toxic')\n",
    "\n",
    "\n",
    "\n",
    "class SklearnBLE(BaseLayerEstimator):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "class NbSvmBLE(BaseLayerEstimator, BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, mode=ModelName.NBSVM, seed=0, params=None):\n",
    "        self._mode = mode\n",
    "        params['random_state'] = seed\n",
    "        self._params = params\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        #return self._clf.predict(x.multiply(self._r))\n",
    "        return self._clf.predict_proba(x.multiply(self._r))[:,1] # chance of being 1 ([:,0] chance of being 0)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        #self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        self._clf = LogisticRegression(**self._params).fit(x_nb, y)\n",
    "        if self._mode == ModelName.NBLSVC:\n",
    "            self._clf = CalibratedClassifierCV(LinearSVC(**self._params)).fit(x_nb, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self.fit(x_train, y_train)\n",
    "    \n",
    "    def feature_importance(self):\n",
    "        return self._clf.feature_importance\n",
    "\n",
    "class XgbBLE(BaseLayerEstimator):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict_proba(xgb.DMatrix(x))[:,1]\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "class LightgbmBLE(BaseLayerEstimator):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        #self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('num_iterations', 100)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "        self.gbdt = lgb.train(self.param, dtrain, self.nrounds, verbose_eval=10)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(x)\n",
    "\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Bidirectional, GlobalMaxPool1D, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "class RnnBLE(BaseLayerEstimator):\n",
    "    def __init__(self, window_length, n_features, label_cols, rnn_units=50, dense_units=50, dropout=0.1, mode='LSTM', bidirection=True, batch_size=32, epochs=2):\n",
    "        self._model = RnnBLE.get_lstm_model(window_length, n_features, label_cols, rnn_units, dense_units, dropout, mode, bidirection)\n",
    "        self._batch_size = batch_size\n",
    "        self._epochs = epochs\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_lstm_model(window_length, n_features, label_cols, rnn_units, dense_units, dropout, mode, bidirection):\n",
    "        input = Input(shape=(window_length, n_features))\n",
    "        rnn_layer = LSTM(rnn_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout)\n",
    "        if mode == 'GRU':\n",
    "            rnn_layer = GRU(rnn_units, return_sequences=True, dropout=dropout, recurrent_dropout=dropout)\n",
    "        if bidirection:\n",
    "            x = Bidirectional(rnn_layer)(input)\n",
    "        else:\n",
    "            x = rnn_layer(input)\n",
    "        x = GlobalMaxPool1D()(x)\n",
    "        x = Dense(dense_units, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(len(label_cols), activation='sigmoid')(x)\n",
    "        model = Model(inputs=input, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        return model \n",
    "    \n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        self._model.fit(x_train, y_train, batch_size=self._batch_size, epochs=self._epochs)\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self._model.predict(x)#, batch_size=1024)\n",
    "    \n",
    "    \n",
    "    \n",
    "class BaseLayerDataRepo():\n",
    "    def __init__(self):\n",
    "        self._data_repo = {}\n",
    "    \n",
    "    def add_data(self, data_id, x_train, x_test, y_train, label_cols, compatible_model=[ModelName.LOGREG], rnn_data=False):\n",
    "        \"\"\"\n",
    "        x_train, x_test: ndarray\n",
    "        y_train: pd df\n",
    "        \"\"\"\n",
    "        temp = {}\n",
    "        \n",
    "        temp['data_id'] = data_id\n",
    "        temp['x_train'] = x_train\n",
    "        temp['x_test'] = x_test\n",
    "        temp['labes_cols'] = label_cols\n",
    "        temp['compatible_model'] = set(compatible_model)\n",
    "        \n",
    "        if rnn_data: \n",
    "            temp['y_train'] = y_train # here y_train is a df\n",
    "        else:\n",
    "            label_dict = {}\n",
    "            for col in label_cols:\n",
    "                label_dict[col] = y_train[col]\n",
    "            temp['y_train'] = label_dict # hence y_train is a dict with labels as keys\n",
    "        \n",
    "        self._data_repo[data_id] = temp\n",
    "    \n",
    "    def get_data(self, data_id):\n",
    "        return self._data_repo[data_id]\n",
    "    \n",
    "    def remove_data(self, data_id):\n",
    "        self._data_repo.pop(data_id, None)\n",
    "        \n",
    "    def get_compatible_model(self, data_id):\n",
    "        return self._data_repo[data_id]['compatible_model']\n",
    "    \n",
    "    def remove_compatible_model(self, data_id, model_name):\n",
    "        return self._data_repo[data_id]['compatible_model'].discard(model_name)\n",
    "    \n",
    "    def add_compatible_model(self, data_id, model_name):\n",
    "        return self._data_repo[data_id]['compatible_model'].add(model_name)\n",
    "                  \n",
    "    def get_data_by_compatible_model(self, model_name):\n",
    "        data_to_return = []\n",
    "        for data_id in self._data_repo.keys():\n",
    "            data = self._data_repo[data_id]\n",
    "            if model_name in data['compatible_model']:\n",
    "                data_to_return.append(data)\n",
    "        return data_to_return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data_repo)\n",
    "    \n",
    "    def __str__(self):\n",
    "        output = ''\n",
    "        for data_id in self._data_repo.keys():\n",
    "            output+='data_id: {:20} \\n\\tx_train: {}\\tx_test: {}\\n\\ty_train type: {}\\n\\tcompatible_model: {}\\n '\\\n",
    "            .format(data_id, self._data_repo[data_id]['x_train'].shape, \\\n",
    "                    self._data_repo[data_id]['x_test'].shape, \\\n",
    "                    type(self._data_repo[data_id]['y_train']), \\\n",
    "                    self._data_repo[data_id]['compatible_model'])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
