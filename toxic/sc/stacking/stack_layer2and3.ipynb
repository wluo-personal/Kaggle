{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from base_layer_utils import BaseLayerDataRepo, BaseLayerResultsRepo, ModelName\n",
    "from base_layer_utils import SklearnBLE\n",
    "from base_layer_utils import compute_layer2_oof\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, re, gc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "PATH = '~/data/toxic/data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_layer_oof_per_label(layer1_oof_dict, label):\n",
    "    \"\"\"\n",
    "    Util method for stacking\n",
    "    \"\"\"\n",
    "    x = None\n",
    "    data_list = layer1_oof_dict[label]\n",
    "    for i in range(len(data_list)):\n",
    "        if i == 0:\n",
    "            x = data_list[0]\n",
    "        else:\n",
    "            x = np.concatenate((x, data_list[i]), axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from file\n"
     ]
    }
   ],
   "source": [
    "# load the saved repo. IMPORTANT: set load_from_file to True! or you will overwrite the saved repo\n",
    "base_layer_results_repo = BaseLayerResultsRepo(load_from_file=True, filepath='obj/WithPreprocessedFile/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we will construct a logreg model and a lightgbm model using different layer1 model_data at layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_pool = {}\n",
    "layer2_inputs = {}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_pool[ModelName.LOGREG] = SklearnBLE(LogisticRegression)\n",
    "layer2_inputs[ModelName.LOGREG] = base_layer_results_repo.get_results(threshold=0.95)\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "model_pool[ModelName.LGB] = SklearnBLE(LGBMClassifier)\n",
    "selected = ['ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0',\n",
    "            'ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0']\n",
    "layer2_inputs[ModelName.LGB] = base_layer_results_repo.get_results(chosen_ones=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ModelName.LGB: 5>: <base_layer_utils.SklearnBLE at 0x7f09b5b69828>,\n",
       " <ModelName.LOGREG: 9>: <base_layer_utils.SklearnBLE at 0x7f09aed825f8>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer2 model ModelName.LOGREG OOF\n",
      "Generating Layer2 model ModelName.LGB OOF\n"
     ]
    }
   ],
   "source": [
    "layer2_est_preds, layer2_oof_train, layer2_oof_test, layer2_model_data_list = compute_layer2_oof(model_pool, layer2_inputs, train, label_cols, 4, 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check layer 2 model_data before add it to a repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer2_oof_train['toxic']) # number of model_data just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_oof_train['toxic'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.LGB_layer2', 'ModelName.LOGREG_layer2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer2_est_preds) # list of layer2 model_data just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_est_preds[list(layer2_est_preds.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: you can add layer2 model_data to the base repo, or create another data repo and save them. \n",
    "### Here we will save them to the base repo, because at layer 3, you might want to build a model using model_data from both layer1 and layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.add(layer2_oof_train, layer2_oof_test, layer2_est_preds, layer2_model_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0\tModelName.LGB_layer2\n",
      "0\tModelName.LOGREG_layer2\n"
     ]
    }
   ],
   "source": [
    "_ = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName.LGB_layer2 already existed in the repo. score: 0 update to 0.09911\n",
      "ModelName.LOGREG_layer2 already existed in the repo. score: 0 update to 0.09922\n"
     ]
    }
   ],
   "source": [
    "# give it some fake score\n",
    "base_layer_results_repo.add_score('ModelName.LGB_layer2', 0.09911)\n",
    "base_layer_results_repo.add_score('ModelName.LOGREG_layer2', 0.09922)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.09922\tModelName.LOGREG_layer2\n",
      "0.09911\tModelName.LGB_layer2\n"
     ]
    }
   ],
   "source": [
    "_ = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save it\n",
    "base_layer_results_repo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions_to_file(base_layer_est_preds):\n",
    "    for key in base_layer_est_preds:\n",
    "        submission = pd.read_csv(PATH + 'sample_submission.csv')#.head(1000)\n",
    "        submission[label_cols] = base_layer_est_preds[key]\n",
    "        sub_id = int(time.time())\n",
    "        print(sub_id)\n",
    "        submission.to_csv('./BaseEstPreds/' + key + '_' + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522100333\n",
      "1522100334\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer2_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now build a logreg at stacknet layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_for_layer3 = ['ModelName.LOGREG_layer2',\n",
    "                       'ModelName.LGB_layer2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer3_model_pool = {}\n",
    "layer3_inputs = {}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "layer3_model_pool[ModelName.LOGREG] = SklearnBLE(LogisticRegression)\n",
    "# because you saved layer2 to base_layer_results_repo, we retrieve data from it\n",
    "layer3_inputs[ModelName.LOGREG] = base_layer_results_repo.get_results(chosen_ones=selected_for_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer2 model ModelName.LOGREG OOF\n"
     ]
    }
   ],
   "source": [
    "layer3_est_preds, layer3_oof_train, layer3_oof_test, layer3_model_data_list = compute_layer2_oof(layer3_model_pool, layer3_inputs, train, label_cols, 4, 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if layer3 is the last layer, then just use write_predictions_to_file to convert the layer3_est_preds to a prediction file and submit it, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522101283\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer3_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otherwise, you have layer3_oof_train and layer3_oof_test for even higher layer stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOOD LUCK!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good luck\n"
     ]
    }
   ],
   "source": [
    "print('good luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
