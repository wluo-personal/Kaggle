{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastText import load_model\n",
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from fastText import load_model\n",
    "\n",
    "class FastTextDataGenerator():\n",
    "    # class variables\n",
    "    print('loading FastText model...', flush=True) # flush set true has no effect?\n",
    "    ft_model_path = '/home/kai/data/resources/FastText/wiki.en.bin'\n",
    "    ft_model = load_model(ft_model_path)\n",
    "    n_features = ft_model.get_dimension()\n",
    "    print('fasttext model loaded. embedding dimemsion: {}'.format(n_features))\n",
    "\n",
    "    \n",
    "    def __init__(self, df, label_cols, text_column_name, window_length, batch_size, shuffle=True):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            df: (dataframe) at least contains a text column and label columns\n",
    "            label_cols: (list) names of label columns\n",
    "                        e.g.: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "            text_column_name: (str) text for faxttext embedding\n",
    "                        e.g.: comment or comment_text_cleaned\n",
    "            window_length: (int) pick at most the first n words from a text\n",
    "            batch_size: (int) how large to generate at each batch\n",
    "            shuffle: (boolean)  whether to shuffle df each epoch \n",
    "        Returns:\n",
    "            (tuple) contains training data and labels of the batch size\n",
    "            \n",
    "        \"\"\"        \n",
    "        #self._ft_model = load_model(ft_model_path)\n",
    "#         self._n_features = FastTextDataGenerator.ft_model.get_dimension()\n",
    "#         print('fasttext model loaded. embedding dimemsion: {}'.format(self._n_features))\n",
    "        \n",
    "        self._df = df\n",
    "        self._label_cols = label_cols\n",
    "        self._text_column_name = text_column_name\n",
    "        self._window_length = window_length\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle = shuffle\n",
    "        self.training_steps_per_epoch = round(len(df) / batch_size)\n",
    "        \n",
    "        \n",
    "    def load_new_ft_model(self, new_ft_model_path):\n",
    "        print('loading new model...', flush=True) \n",
    "        FastTextDataGenerator.ft_model = load_model(new_ft_model_path)\n",
    "        FastTextDataGenerator.n_features = FastTextDataGenerator.ft_model.get_dimension()\n",
    "        print('fasttext model loaded. embedding dimemsion: {}'.format(FastTextDataGenerator.n_features))\n",
    "\n",
    "            \n",
    "    def data_gen(self):\n",
    "        \"\"\"\n",
    "        Given a raw dataframe, generates infinite batches of FastText vectors.\n",
    "        \"\"\"\n",
    "        batch_i = 0 # Counter inside the current batch vector\n",
    "        batch_x = None # The current batch's x data\n",
    "        batch_y = None # The current batch's y data\n",
    "\n",
    "        while True: # Loop forever\n",
    "            if self._shuffle:\n",
    "                self._df = self._df.sample(frac=1) \n",
    "\n",
    "            for i, row in self._df.iterrows():\n",
    "                comment = row[self._text_column_name][0] # add [0] to get the string from the pd.Series \n",
    "\n",
    "                if batch_x is None:\n",
    "                    batch_x = np.zeros((self._batch_size, self._window_length, FastTextDataGenerator.n_features), dtype='float32')\n",
    "                    batch_y = np.zeros((self._batch_size, len(self._label_cols)), dtype='float32')\n",
    "                \n",
    "                batch_x[batch_i] = FastTextDataGenerator.text_to_vector(comment, self._window_length)\n",
    "                batch_y[batch_i] = row[self._label_cols].values\n",
    "                batch_i += 1\n",
    "\n",
    "                if batch_i == self._batch_size:\n",
    "                    # Ready to yield the batch\n",
    "                    yield batch_x, batch_y\n",
    "                    batch_x = None\n",
    "                    batch_y = None\n",
    "                    batch_i = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def text_to_vector(text, window_length):\n",
    "        \"\"\"\n",
    "        Given a string, normalizes it, then splits it into words and finally converts\n",
    "        it to a sequence of word vectors.\n",
    "        \"\"\"\n",
    "        text = FastTextDataGenerator.normalize(text)\n",
    "        words = text.split()\n",
    "        window = words[-window_length:]\n",
    "\n",
    "        x = np.zeros((window_length, FastTextDataGenerator.n_features))\n",
    "\n",
    "        for i, word in enumerate(window):\n",
    "            x[i, :] = FastTextDataGenerator.ft_model.get_word_vector(word).astype('float32')\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(s):\n",
    "        \"\"\"\n",
    "        Given a text, cleans and normalizes it. Feel free to add your own stuff.\n",
    "        \"\"\"\n",
    "        #s = s.lower()\n",
    "        # Replace ips\n",
    "        #s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', s)\n",
    "        # Isolate punctuation\n",
    "        #s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "        # Remove some special characters\n",
    "        #s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "        # Replace numbers and symbols with language\n",
    "        s = s.replace('&', ' and ')\n",
    "        s = s.replace('@', ' at ')\n",
    "        s = s.replace('0', ' zero ')\n",
    "        s = s.replace('1', ' one ')\n",
    "        s = s.replace('2', ' two ')\n",
    "        s = s.replace('3', ' three ')\n",
    "        s = s.replace('4', ' four ')\n",
    "        s = s.replace('5', ' five ')\n",
    "        s = s.replace('6', ' six ')\n",
    "        s = s.replace('7', ' seven ')\n",
    "        s = s.replace('8', ' eight ')\n",
    "        s = s.replace('9', ' nine ')\n",
    "        return s\n",
    "\n",
    "    @staticmethod\n",
    "    def df_to_data(df, text_column_name, window_length):\n",
    "        \"\"\"\n",
    "        Convert a given dataframe to a dataset of inputs for the NN.\n",
    "        \"\"\"\n",
    "        x = np.zeros((len(df), window_length, FastTextDataGenerator.n_features), dtype='float32')\n",
    "\n",
    "        for i, comment in enumerate(df[text_column_name].values):\n",
    "            x[i, :] = FastTextDataGenerator.text_to_vector(comment, window_length)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
