{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "import lightgbm as lgb\n",
    "\n",
    "from enum import Enum\n",
    "class ModelName(Enum):\n",
    "    XGB = 1\n",
    "    NBXGB = 2\n",
    "    LGB = 3\n",
    "    NBLGB = 4\n",
    "    LOGREG = 5\n",
    "    NBSVM = 6 # NBLOGREG\n",
    "    LSVC = 7\n",
    "    NBLSVC = 8\n",
    "    RF = 9 # random forest\n",
    "    RNN = 10\n",
    "    ONESVC = 11\n",
    "    ONELOGREG = 12\n",
    "\n",
    "\n",
    "class BaseLayerEstimator(ABC):\n",
    "    \n",
    "    def _pr(self, y_i, y, train_features):\n",
    "        p = train_features[np.array(y==y_i)].sum(0)\n",
    "        return (p + 1) / (np.array(y == y_i).sum() + 1)\n",
    "    \n",
    "    def _nb(self, x_train, y_train):\n",
    "        assert isinstance(y_train, pd.DataFrame)\n",
    "        r = {}\n",
    "        for col in y_train.columns:\n",
    "            print('calculating naive bayes for {}'.format(col))\n",
    "            r[col] = np.log(self._pr(1, y_train[col].values, x_train) / self._pr(0, y_train[col], x_train))\n",
    "        return r\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            x_train: np array\n",
    "            y_train: pd series\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x_train):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "class LogRegAndLsvcBLE(BaseLayerEstimator):\n",
    "    def __init__(self, mode=ModelName.LOGREG, seed=0, params=None):\n",
    "        if mode != ModelName.LOGREG and mode != ModelName.LSVC:\n",
    "            raise ValueError('Invalid mode. Valid modes: ModelName.LOGREG and ModelName.LSVC')\n",
    "        self._mode = mode\n",
    "        params['random_state'] = seed\n",
    "        self._params = params\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self._clf.predict_proba(x)[:,1] # chance of being 1 ([:,0] chance of being 0)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        if self._mode == ModelName.LOGREG:\n",
    "            self._clf = LogisticRegression(**self._params).fit(x_train, y_train)\n",
    "        if self._mode == ModelName.LSVC:\n",
    "            self._clf = CalibratedClassifierCV(LinearSVC(**self._params)).fit(x_train, y_train)\n",
    "    \n",
    "    def feature_importance(self):\n",
    "        return self._clf.feature_importance\n",
    "    \n",
    "    \n",
    "    \n",
    "class LightgbmBLE(BaseLayerEstimator):\n",
    "    def __init__(self, x_train, y_train, label_cols= None, params=None, nb=True, seed=0):\n",
    "        \"\"\"\n",
    "        constructor:\n",
    "\n",
    "            x_train: should be a np/scipy/ 2-d array or matrix. only be used when nb is true\n",
    "            y_train: should be a dataframe\n",
    "            label_cols: (list) if y_train contains multiple labels, provide the list of label names\n",
    "                e.g.: label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "            params: (dict)\n",
    "            nb: (boolean) compute naive bayes or not. (helpful for unbalanced data)\n",
    "            seed: (int) training random seed (not used currently)\n",
    "            \n",
    "        Example:\n",
    "            ll = LightgbmBLE(train_tfidf, train[label_cols], params=params, nb=True)\n",
    "            result = pd.DataFrame()\n",
    "            for col in label_cols:\n",
    "                    print(col)\n",
    "                    ll.train(train_tfidf, train[col], col)\n",
    "                    result[col] = ll.predict(test_tfidf, col)\n",
    "        \"\"\"\n",
    "        #### check naive bayes\n",
    "        if nb:\n",
    "            print('Naive Bayes is enabled')\n",
    "            self.r = self._nb(x_train, y_train)\n",
    "        else:\n",
    "            print('Naive Bayes is disabled')\n",
    "            self.r = None\n",
    "        ##### set values    \n",
    "        self.nb = nb\n",
    "        self.set_params(params)\n",
    "        self.label_cols = label_cols\n",
    "        print('LightgbmBLE is initialized')\n",
    "    \n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _pre_process(self, x, y, label=None):\n",
    "        if self.nb:\n",
    "            if label is None:\n",
    "                raise ValueError('Naive Bayes is enabled. label cannot be None.')\n",
    "            if label not in self.label_cols:\n",
    "                raise ValueError('Label not in label_cols')\n",
    "            print('apply naive bayes to feature set')\n",
    "            x = x.multiply(self.r[label])\n",
    "            if isinstance(x, csr_matrix):\n",
    "                x = x.tocsr()\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        else:\n",
    "            y = y\n",
    "        return (x, y)\n",
    "    \n",
    "    \n",
    "    def train(self, x_train, y_train, label=None, valid_set_percent=0):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            x_train: np/scipy/ 2-d array or matrix\n",
    "            y_train: should be a dataframe\n",
    "            label: (str) if not none, then it's one of the labels in the label_cols\n",
    "                    if nb is set to True when initializing, when label can not be None\n",
    "            valid_set_percent: (float, 0 to 1). \n",
    "                    0: no validation set. (imposible to use early stopping)\n",
    "                    1: use training set as validation set (to check underfitting, and early stopping)\n",
    "                    >0 and <1: use a portion of training set as validation set. (to check overfitting, and early stopping)\n",
    "        \n",
    "        \"\"\"\n",
    "        x, y = self._pre_process(x_train, y_train, label)\n",
    "        \n",
    "        if valid_set_percent != 0:\n",
    "            if valid_set_percent > 1 or valid_set_percent < 0:\n",
    "                raise ValueError('valid_set_percent must >= 0 and <= 1')\n",
    "            if valid_set_percent != 1:\n",
    "                x, x_val, y, y_val = train_test_split(x, y, test_size=valid_set_percent)\n",
    "\n",
    "\n",
    "        lgb_train = lgb.Dataset(x, y)\n",
    "        if valid_set_percent != 0:\n",
    "            if valid_set_percent == 1:\n",
    "                print('Evaluating using training set')\n",
    "                self.model = lgb.train(self.params, lgb_train, valid_sets=lgb_train)\n",
    "            else:\n",
    "                lgb_val = lgb.Dataset(x_val, y_val)\n",
    "                print('Evaluating using validation set ({}% of training set)'.format(valid_set_percent*100))\n",
    "                self.model = lgb.train(self.params, lgb_train, valid_sets=lgb_val)\n",
    "        else:\n",
    "            print('No evaluation set, thus not possible to use early stopping. Please train with your best params.')\n",
    "            self.model = lgb.train(self.params, lgb_train)\n",
    "        \n",
    "        \n",
    "    def predict(self, x_test, label=None):\n",
    "        x, _ = self._pre_process(x_test, y=None, label=label)\n",
    "        print('starting predicting')\n",
    "        if self.model.best_iteration > 0:\n",
    "            print('best_iteration {} is chosen.'.format(best_iteration))\n",
    "            result = self.model.predict(x, num_iteration=bst.best_iteration)\n",
    "        else:\n",
    "            result = self.model.predict(x)\n",
    "        print('predicting done')\n",
    "        return result\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tfidf_data import tfidf_data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, data_id = tfidf_data_process(word_ngram=(1,3), word_max=100000, char_ngram=(2, 5), char_max=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 300000),\n",
       " (159571, 6),\n",
       " (153164, 300000),\n",
       " 'wordtfidf_word_(1, 3)_100000_1_1.0_char_(2, 5)_200000_1_1.0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_params = {\n",
    "    'identity_hate': {'C': 0.01, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'insult': {'C': 0.02, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'obscene': {'C': 0.05, 'class_weight': None, 'fit_intercept': True},\n",
    "    'severe_toxic': {'C': 0.02, 'class_weight': None, 'fit_intercept': True},\n",
    "    'threat': {'C': 0.005, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'toxic': {'C': 0.1, 'class_weight': 'balanced','fit_intercept': True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((x_test.shape[0], len(label_cols)))\n",
    "\n",
    "for i, label in enumerate(label_cols):\n",
    "    lsvc_ble = LogRegAndLsvcBLE(mode=ModelName.LSVC, seed=1001, params=lsvc_params[label])\n",
    "    lsvc_ble.train(x_train, y_train[label].values)\n",
    "    preds[:, i] = lsvc_ble.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_params = {\n",
    "    'identity_hate': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'insult': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'obscene': {'C': 0.7, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "    'severe_toxic': {'C': 0.3,'class_weight': None, 'fit_intercept': True},\n",
    "    'threat': {'C': 0.05, 'class_weight': 'balanced', 'fit_intercept': True}, \n",
    "    'toxic': {'C': 0.8, 'class_weight': 'balanced', 'fit_intercept': True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((x_test.shape[0], len(label_cols)))\n",
    "\n",
    "for i, label in enumerate(label_cols):\n",
    "    logreg_ble = LogRegAndLsvcBLE(mode=ModelName.LOGREG, seed=1001, params=logreg_params[label])\n",
    "    logreg_ble.train(x_train, y_train[label].values)\n",
    "    preds[:, i] = logreg_ble.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params_per_label = {}\n",
    "lgb_params_per_label['toxic'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.9,\n",
    "    'feature_fraction': 0.6,\n",
    "    'lambda_l1': 0.0, \n",
    "    'lambda_l2': 0.0, \n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'num_iterations': 219,\n",
    "    'num_leaves': 61, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "\n",
    "lgb_params_per_label['severe_toxic'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.6,\n",
    "    'lambda_l1': 0.5, \n",
    "    'lambda_l2': 0.0, \n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'num_iterations': 322,\n",
    "    'num_leaves': 11, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "\n",
    "\n",
    "lgb_params_per_label['obscene'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1': 0.0, \n",
    "    'lambda_l2': 0.0, \n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'num_iterations': 274,\n",
    "    'num_leaves': 61, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "\n",
    "lgb_params_per_label['threat'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1': 0.5, \n",
    "    'lambda_l2': 0.0, \n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'num_iterations': 208,\n",
    "    'num_leaves': 11, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "\n",
    "lgb_params_per_label['insult'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.6,\n",
    "    'lambda_l1': 0.0, \n",
    "    'lambda_l2': 0.5, \n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'num_iterations': 454,\n",
    "    'num_leaves': 11, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "\n",
    "lgb_params_per_label['identity_hate'] = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'num_threads': 8, \n",
    "    'bagging_freq': 1, \n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.6,\n",
    "    'lambda_l1': 0.0, \n",
    "    'lambda_l2': 0.0, \n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'num_iterations': 191,\n",
    "    'num_leaves': 61, \n",
    "    'is_unbalance': False\n",
    "}\n",
    "    \n",
    "    \n",
    "#     #'learning_rate': 0.05,\n",
    "#     'is_unbalance': True,\n",
    "#     'early_stopping_round': 25,\n",
    "#     'max_depth': -1,\n",
    "#     'num_boost_round': 3000,\n",
    "#     'application': 'binary',\n",
    "#     'num_leaves': 63,\n",
    "#     'verbosity': 10,\n",
    "#     'metric': 'auc',\n",
    "#     'data_random_seed': 2,\n",
    "#     'bagging_fraction': 1,\n",
    "#     'feature_fraction': 0.6,\n",
    "#     'nthread': 4\n",
    "# #     'lambda_l1': 1,\n",
    "# #     'lambda_l2': 1\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes is enabled\n",
      "calculating naive bayes for toxic\n",
      "calculating naive bayes for severe_toxic\n",
      "calculating naive bayes for obscene\n",
      "calculating naive bayes for threat\n",
      "calculating naive bayes for insult\n",
      "calculating naive bayes for identity_hate\n",
      "LightgbmBLE is initialized\n"
     ]
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "lgb_ble = LightgbmBLE(x_train, y_train, label_cols=label_cols, nb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((x_test.shape[0], len(label_cols)))\n",
    "\n",
    "for i, label in enumerate(label_cols):\n",
    "    lgb_ble.set_params(lgb_params_per_label[label])\n",
    "    lgb_ble.train(x_train, y_train[label].values, label)\n",
    "    preds[:, i] = lgb_ble.predict(x_test, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520733758\n"
     ]
    }
   ],
   "source": [
    "PATH = '~/data/toxic/data/'\n",
    "submission = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = preds\n",
    "import time\n",
    "sub_id = int(time.time())\n",
    "print(sub_id)\n",
    "submission.to_csv('./BaseEstPreds/' + 'test123_' + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "      <td>153164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.207959</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>0.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.349240</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.290001</td>\n",
       "      <td>0.043009</td>\n",
       "      <td>0.234656</td>\n",
       "      <td>0.083987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.226733</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.035457</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  153164.000000  153164.000000  153164.000000  153164.000000   \n",
       "mean        0.207959       0.016811       0.126140       0.004849   \n",
       "std         0.349240       0.083159       0.290001       0.043009   \n",
       "min         0.000028       0.000139       0.000401       0.000014   \n",
       "25%         0.002755       0.001807       0.003215       0.000175   \n",
       "50%         0.010663       0.002533       0.005905       0.000347   \n",
       "75%         0.226733       0.004101       0.025181       0.000862   \n",
       "max         1.000000       0.998685       1.000000       0.999605   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  153164.000000  153164.000000  \n",
       "mean        0.100053       0.017637  \n",
       "std         0.234656       0.083987  \n",
       "min         0.000123       0.000052  \n",
       "25%         0.002449       0.000689  \n",
       "50%         0.005874       0.001342  \n",
       "75%         0.035457       0.003944  \n",
       "max         1.000000       0.999958  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[label_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
