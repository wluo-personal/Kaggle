{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#dpcnn http://ai.tencent.com/ailab/media/publications/ACL3-Brady.pdf\n",
    "#dpcnn with conv1d, model architecture and all parameters copied from neptune-ml since it's publicly available\n",
    "#https://github.com/neptune-ml/kaggle-toxic-starter/blob/master/best_configs/fasttext_dpcnn.yaml\n",
    "#Got it to PLB 0.984 with 10fold cv on local computer after playing with parameters\n",
    "#Try to improve score on your own local pc or throw it in the blender with the rest of them :)\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Conv1D, Conv2D, SpatialDropout1D, Reshape, Concatenate\n",
    "from keras.layers import add, Dropout, PReLU, BatchNormalization, GlobalMaxPooling1D, MaxPool2D, MaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras import initializers, regularizers, constraints, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "def schedule(ind): # seems like not used later\n",
    "    a = [0.001, 0.0005, 0.0001, 0.0001]\n",
    "    return a[ind] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/data/toxic/data/train_preprocessed_clean.csv')\n",
    "test = pd.read_csv('~/data/toxic/data/test_preprocessed_clean.csv')\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"unknown\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"unknown\").values\n",
    "\n",
    "max_features = 100000\n",
    "maxlen = 200\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index_lex, embed_size = word2Vec('lex')\n",
    "embeddings_index_glc, embed_size = word2Vec('gl-common')\n",
    "embeddings_index_glt, embed_size = word2Vec('gl-twitter')\n",
    "embeddings_index_ftc, embed_size = word2Vec('ft-common')\n",
    "embeddings_index_ftw, embed_size = word2Vec('ft-wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2Vec(source):\n",
    "    embed_size = 300\n",
    "    if source.lower() == 'ft-common':\n",
    "        file = '/home/kai/data/resources/FastText/crawl-300d-2M.vec'\n",
    "    elif source.lower() == 'ft-wiki':\n",
    "        file = '/home/kai/data/resources/FastText/wiki.en.vec'\n",
    "    elif source.lower() == 'lex':\n",
    "        file = '/home/kai/data/resources/lexvec/lexvec.commoncrawl.300d.W.pos.vectors'\n",
    "    elif source.lower() == 'gl-common':\n",
    "        file = '/home/kai/data/resources/glove/glove.840B.300d.txt'\n",
    "    elif source.lower() == 'gl-twitter':\n",
    "        file = '/home/kai/data/resources/glove/glove.twitter.27B.200d.txt'\n",
    "        embed_size = 200\n",
    "    def get_coefs(word,*arr): \n",
    "        try:\n",
    "            return word, np.asarray(arr, dtype='float32') \n",
    "        except ValueError:\n",
    "            return 'nnnnnnnaaaaaaa@@!',np.zeros(embed_size)\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(file, encoding='utf8'))\n",
    "    return embeddings_index, embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "\n",
    "all_embs.shape\n",
    "\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "emb_mean,  emb_std\n",
    "\n",
    "del all_embs, X_train, X_test, train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "import json as js\n",
    "with open('/home/kai/data/kaggle/toxic/wl/models/RNN/rnn/dirty_word_dict.json', 'r') as file:\n",
    "    bad_word_dict = js.load(file)\n",
    "print(len(bad_word_dict))\n",
    "    \n",
    "def get_embedding_matrix(embeddings_index, embed_size, max_features, tokenizer, bad_word_dict):\n",
    "    word_index = tokenizer.word_index\n",
    "    #prepare embedding matrix\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((num_words, embed_size))\n",
    "    still_not_found_word = {}\n",
    "    replaced_word = {}\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        try: \n",
    "            embedding_vector = embeddings_index[word] # w2v_model['/en/'+ word] #w2v_model[word]#\n",
    "        except KeyError:\n",
    "            replacement = bad_word_dict.get(word)\n",
    "            embedding_vector = embeddings_index.get(replacement, None)\n",
    "    #         embedding_vector = None #np.zeros(embed_size)\n",
    "            if embedding_vector is None:\n",
    "                still_not_found_word[word] = tokenizer.word_counts[word]#i\n",
    "            else:\n",
    "                if word not in replaced_word:\n",
    "                    replaced_word[word] = replacement\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('{} words not found in embedding file (after replacement attempt)'.format(len(still_not_found_word)))\n",
    "    print('{} words are replaced:'.format(len(replaced_word)))\n",
    "    print(replaced_word)\n",
    "    return embedding_matrix, still_not_found_word, replaced_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(maxlen, max_features, embedding_matrix, embed_size, num_filters=64):    \n",
    "    \n",
    "    filter_sizes = [1,2,3,5]\n",
    "    num_filters = num_filters\n",
    "\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "\n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "\n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "\n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "\n",
    "    outp = Dense(6, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_epoch_patience_pool = [\n",
    "    (1024, 20, 5, 64),\n",
    "#     (1024, 10, 10),\n",
    "#     (1024, 3, 3),\n",
    "#     (1024, 3, 3),\n",
    "#     (1024, 3, 3),\n",
    "    (512, 10, 3, 48),\n",
    "#     (512, 2, 2),\n",
    "#     (512, 2, 2),\n",
    "#     (512, 2, 2),\n",
    "    (256, 5, 2, 32)\n",
    "#     (128, 5, 5),\n",
    "#     (128, 2, 2),\n",
    "#     (128, 2, 2),\n",
    "#     (128, 1, 1),\n",
    "#     (32, 3, 3),\n",
    "#     (32, 2, 2),\n",
    "#     (32, 1, 1),\n",
    "#     (32, 1, 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index_pool = [\n",
    "    (embeddings_index_lex, 300, 'lex'),\n",
    "    (embeddings_index_glc, 300, 'glc'),\n",
    "    (embeddings_index_glt, 200, 'glt'),#,\n",
    "    (embeddings_index_ftc, 300, 'ftc'), \n",
    "    (embeddings_index_ftw, 300, 'ftw')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9806 words not found in embedding file (after replacement attempt)\n",
      "0 words are replaced:\n",
      "{}\n",
      "load model: ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9572\n",
      " ROC-AUC - epoch: 1 - score: 0.927154 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05199, saving model to ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 190us/step - loss: 0.1163 - acc: 0.9572 - val_loss: 0.0520 - val_acc: 0.9819\n",
      "Epoch 2/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9815\n",
      " ROC-AUC - epoch: 2 - score: 0.979105 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05199 to 0.04583, saving model to ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 190us/step - loss: 0.0506 - acc: 0.9815 - val_loss: 0.0458 - val_acc: 0.9833\n",
      "Epoch 3/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9831\n",
      " ROC-AUC - epoch: 3 - score: 0.982844 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04583 to 0.04359, saving model to ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 190us/step - loss: 0.0446 - acc: 0.9831 - val_loss: 0.0436 - val_acc: 0.9838\n",
      "Epoch 4/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9844\n",
      " ROC-AUC - epoch: 4 - score: 0.984700 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04359 to 0.04240, saving model to ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 191us/step - loss: 0.0405 - acc: 0.9844 - val_loss: 0.0424 - val_acc: 0.9840\n",
      "Epoch 5/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9855\n",
      " ROC-AUC - epoch: 5 - score: 0.985489 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04240 to 0.04194, saving model to ./PureCnnModels/cnn_lex_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 190us/step - loss: 0.0371 - acc: 0.9855 - val_loss: 0.0419 - val_acc: 0.9840\n",
      "Epoch 6/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9866\n",
      " ROC-AUC - epoch: 6 - score: 0.985265 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "143613/143613 [==============================] - 25s 177us/step - loss: 0.0340 - acc: 0.9866 - val_loss: 0.0421 - val_acc: 0.9837\n",
      "Epoch 7/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9876\n",
      " ROC-AUC - epoch: 7 - score: 0.984767 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 186us/step - loss: 0.0312 - acc: 0.9876 - val_loss: 0.0427 - val_acc: 0.9839\n",
      "Epoch 8/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9888\n",
      " ROC-AUC - epoch: 8 - score: 0.984302 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 186us/step - loss: 0.0283 - acc: 0.9888 - val_loss: 0.0441 - val_acc: 0.9833\n",
      "Epoch 9/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9899\n",
      " ROC-AUC - epoch: 9 - score: 0.983983 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0255 - acc: 0.9899 - val_loss: 0.0455 - val_acc: 0.9833\n",
      "Epoch 10/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9909\n",
      " ROC-AUC - epoch: 10 - score: 0.982772 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 186us/step - loss: 0.0231 - acc: 0.9909 - val_loss: 0.0475 - val_acc: 0.9831\n",
      "1567722\n",
      "load model: ./PureCnnModels/cnn_lex_512_48_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9723\n",
      " ROC-AUC - epoch: 1 - score: 0.975047 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04945, saving model to ./PureCnnModels/cnn_lex_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 32s 220us/step - loss: 0.0814 - acc: 0.9723 - val_loss: 0.0495 - val_acc: 0.9817\n",
      "Epoch 2/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9830\n",
      " ROC-AUC - epoch: 2 - score: 0.984960 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04945 to 0.04549, saving model to ./PureCnnModels/cnn_lex_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0452 - acc: 0.9829 - val_loss: 0.0455 - val_acc: 0.9825\n",
      "Epoch 3/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9845\n",
      " ROC-AUC - epoch: 3 - score: 0.986834 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04549 to 0.04374, saving model to ./PureCnnModels/cnn_lex_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0395 - acc: 0.9845 - val_loss: 0.0437 - val_acc: 0.9832\n",
      "Epoch 4/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9863\n",
      " ROC-AUC - epoch: 4 - score: 0.987318 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04374 to 0.04338, saving model to ./PureCnnModels/cnn_lex_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0348 - acc: 0.9863 - val_loss: 0.0434 - val_acc: 0.9833\n",
      "Epoch 5/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9878\n",
      " ROC-AUC - epoch: 5 - score: 0.987189 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 28s 193us/step - loss: 0.0307 - acc: 0.9878 - val_loss: 0.0444 - val_acc: 0.9831\n",
      "Epoch 6/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9893\n",
      " ROC-AUC - epoch: 6 - score: 0.986644 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 202us/step - loss: 0.0270 - acc: 0.9893 - val_loss: 0.0475 - val_acc: 0.9826\n",
      "Epoch 7/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9907\n",
      " ROC-AUC - epoch: 7 - score: 0.985400 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 202us/step - loss: 0.0234 - acc: 0.9907 - val_loss: 0.0496 - val_acc: 0.9827\n",
      "1567944\n",
      "load model: ./PureCnnModels/cnn_lex_256_32_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9769\n",
      " ROC-AUC - epoch: 1 - score: 0.981135 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04626, saving model to ./PureCnnModels/cnn_lex_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 37s 255us/step - loss: 0.0662 - acc: 0.9769 - val_loss: 0.0463 - val_acc: 0.9824\n",
      "Epoch 2/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9839\n",
      " ROC-AUC - epoch: 2 - score: 0.985238 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04626 to 0.04275, saving model to ./PureCnnModels/cnn_lex_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 240us/step - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0427 - val_acc: 0.9834\n",
      "Epoch 3/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9858\n",
      " ROC-AUC - epoch: 3 - score: 0.986052 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04275 to 0.04250, saving model to ./PureCnnModels/cnn_lex_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 241us/step - loss: 0.0359 - acc: 0.9858 - val_loss: 0.0425 - val_acc: 0.9834\n",
      "Epoch 4/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9880\n",
      " ROC-AUC - epoch: 4 - score: 0.984876 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 236us/step - loss: 0.0306 - acc: 0.9880 - val_loss: 0.0451 - val_acc: 0.9831\n",
      "Epoch 5/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9899\n",
      " ROC-AUC - epoch: 5 - score: 0.983219 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 236us/step - loss: 0.0258 - acc: 0.9899 - val_loss: 0.0476 - val_acc: 0.9828\n",
      "1568135\n",
      "21663 words not found in embedding file (after replacement attempt)\n",
      "4 words are replaced:\n",
      "{'suxk': 'suck', 'dickus': 'dick', 'fggt': 'faggot', 'sukker': 'suck'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9684\n",
      " ROC-AUC - epoch: 1 - score: 0.900212 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05468, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 29s 205us/step - loss: 0.0969 - acc: 0.9684 - val_loss: 0.0547 - val_acc: 0.9807\n",
      "Epoch 2/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9816\n",
      " ROC-AUC - epoch: 2 - score: 0.981074 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05468 to 0.04819, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 191us/step - loss: 0.0516 - acc: 0.9815 - val_loss: 0.0482 - val_acc: 0.9822\n",
      "Epoch 3/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9827\n",
      " ROC-AUC - epoch: 3 - score: 0.985072 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04819 to 0.04586, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 27s 191us/step - loss: 0.0463 - acc: 0.9827 - val_loss: 0.0459 - val_acc: 0.9829\n",
      "Epoch 4/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9835\n",
      " ROC-AUC - epoch: 4 - score: 0.986628 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04586 to 0.04539, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 192us/step - loss: 0.0429 - acc: 0.9835 - val_loss: 0.0454 - val_acc: 0.9829\n",
      "Epoch 5/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9844\n",
      " ROC-AUC - epoch: 5 - score: 0.987409 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04539 to 0.04465, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 26s 182us/step - loss: 0.0404 - acc: 0.9844 - val_loss: 0.0447 - val_acc: 0.9829\n",
      "Epoch 6/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9852\n",
      " ROC-AUC - epoch: 6 - score: 0.987871 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04465 to 0.04451, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 192us/step - loss: 0.0380 - acc: 0.9852 - val_loss: 0.0445 - val_acc: 0.9830\n",
      "Epoch 7/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9860\n",
      " ROC-AUC - epoch: 7 - score: 0.988075 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0362 - acc: 0.9860 - val_loss: 0.0448 - val_acc: 0.9829\n",
      "Epoch 8/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9867\n",
      " ROC-AUC - epoch: 8 - score: 0.988265 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0339 - acc: 0.9867 - val_loss: 0.0450 - val_acc: 0.9826\n",
      "Epoch 9/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9875\n",
      " ROC-AUC - epoch: 9 - score: 0.988121 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04451 to 0.04362, saving model to ./PureCnnModels/cnn_glc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 192us/step - loss: 0.0318 - acc: 0.9875 - val_loss: 0.0436 - val_acc: 0.9833\n",
      "Epoch 10/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9883\n",
      " ROC-AUC - epoch: 10 - score: 0.988111 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 26s 178us/step - loss: 0.0296 - acc: 0.9883 - val_loss: 0.0439 - val_acc: 0.9832\n",
      "Epoch 11/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9891\n",
      " ROC-AUC - epoch: 11 - score: 0.988092 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0276 - acc: 0.9891 - val_loss: 0.0460 - val_acc: 0.9828\n",
      "Epoch 12/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9899\n",
      " ROC-AUC - epoch: 12 - score: 0.987672 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0258 - acc: 0.9899 - val_loss: 0.0465 - val_acc: 0.9829\n",
      "Epoch 13/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9908\n",
      " ROC-AUC - epoch: 13 - score: 0.987297 \n",
      "\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0238 - acc: 0.9908 - val_loss: 0.0473 - val_acc: 0.9830\n",
      "Epoch 14/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9913\n",
      " ROC-AUC - epoch: 14 - score: 0.986918 \n",
      "\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 187us/step - loss: 0.0222 - acc: 0.9913 - val_loss: 0.0483 - val_acc: 0.9829\n",
      "1568531\n",
      "load model: ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9785\n",
      " ROC-AUC - epoch: 1 - score: 0.984622 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05057, saving model to ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 32s 222us/step - loss: 0.0662 - acc: 0.9785 - val_loss: 0.0506 - val_acc: 0.9813\n",
      "Epoch 2/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9827\n",
      " ROC-AUC - epoch: 2 - score: 0.987671 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05057 to 0.04665, saving model to ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 207us/step - loss: 0.0460 - acc: 0.9827 - val_loss: 0.0466 - val_acc: 0.9822\n",
      "Epoch 3/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9839\n",
      " ROC-AUC - epoch: 3 - score: 0.988695 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04665 to 0.04652, saving model to ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 207us/step - loss: 0.0415 - acc: 0.9839 - val_loss: 0.0465 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9852\n",
      " ROC-AUC - epoch: 4 - score: 0.989142 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 203us/step - loss: 0.0379 - acc: 0.9852 - val_loss: 0.0493 - val_acc: 0.9814\n",
      "Epoch 5/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9862\n",
      " ROC-AUC - epoch: 5 - score: 0.989036 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04652 to 0.04590, saving model to ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 207us/step - loss: 0.0352 - acc: 0.9862 - val_loss: 0.0459 - val_acc: 0.9824\n",
      "Epoch 6/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9873\n",
      " ROC-AUC - epoch: 6 - score: 0.988706 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04590 to 0.04574, saving model to ./PureCnnModels/cnn_glc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 198us/step - loss: 0.0322 - acc: 0.9874 - val_loss: 0.0457 - val_acc: 0.9827\n",
      "Epoch 7/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9884\n",
      " ROC-AUC - epoch: 7 - score: 0.988109 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 202us/step - loss: 0.0293 - acc: 0.9884 - val_loss: 0.0461 - val_acc: 0.9827\n",
      "Epoch 8/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9895\n",
      " ROC-AUC - epoch: 8 - score: 0.987693 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 202us/step - loss: 0.0268 - acc: 0.9895 - val_loss: 0.0485 - val_acc: 0.9819\n",
      "Epoch 9/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9905\n",
      " ROC-AUC - epoch: 9 - score: 0.987145 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 203us/step - loss: 0.0241 - acc: 0.9905 - val_loss: 0.0503 - val_acc: 0.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568812\n",
      "load model: ./PureCnnModels/cnn_glc_256_32_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9776\n",
      " ROC-AUC - epoch: 1 - score: 0.984675 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04726, saving model to ./PureCnnModels/cnn_glc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 38s 266us/step - loss: 0.0657 - acc: 0.9776 - val_loss: 0.0473 - val_acc: 0.9821\n",
      "Epoch 2/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9829\n",
      " ROC-AUC - epoch: 2 - score: 0.986972 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04726 to 0.04616, saving model to ./PureCnnModels/cnn_glc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 241us/step - loss: 0.0445 - acc: 0.9829 - val_loss: 0.0462 - val_acc: 0.9821\n",
      "Epoch 3/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9846\n",
      " ROC-AUC - epoch: 3 - score: 0.987860 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04616 to 0.04568, saving model to ./PureCnnModels/cnn_glc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 242us/step - loss: 0.0396 - acc: 0.9846 - val_loss: 0.0457 - val_acc: 0.9820\n",
      "Epoch 4/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9859\n",
      " ROC-AUC - epoch: 4 - score: 0.987976 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 237us/step - loss: 0.0356 - acc: 0.9859 - val_loss: 0.0461 - val_acc: 0.9818\n",
      "Epoch 5/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9872\n",
      " ROC-AUC - epoch: 5 - score: 0.987664 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04568 to 0.04556, saving model to ./PureCnnModels/cnn_glc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 242us/step - loss: 0.0324 - acc: 0.9872 - val_loss: 0.0456 - val_acc: 0.9824\n",
      "1569004\n",
      "32291 words not found in embedding file (after replacement attempt)\n",
      "2 words are replaced:\n",
      "{'assraped': 'ass', 'dickus': 'dick'}\n",
      "load model: ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9593\n",
      " ROC-AUC - epoch: 1 - score: 0.889345 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05725, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 21s 144us/step - loss: 0.1262 - acc: 0.9593 - val_loss: 0.0573 - val_acc: 0.9809\n",
      "Epoch 2/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9807\n",
      " ROC-AUC - epoch: 2 - score: 0.977978 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05725 to 0.05036, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 17s 119us/step - loss: 0.0563 - acc: 0.9807 - val_loss: 0.0504 - val_acc: 0.9817\n",
      "Epoch 3/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9817\n",
      " ROC-AUC - epoch: 3 - score: 0.984115 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05036 to 0.04711, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 18s 128us/step - loss: 0.0504 - acc: 0.9817 - val_loss: 0.0471 - val_acc: 0.9826\n",
      "Epoch 4/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9827\n",
      " ROC-AUC - epoch: 4 - score: 0.986702 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04711 to 0.04631, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 17s 120us/step - loss: 0.0469 - acc: 0.9827 - val_loss: 0.0463 - val_acc: 0.9827\n",
      "Epoch 5/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9832\n",
      " ROC-AUC - epoch: 5 - score: 0.987961 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04631 to 0.04530, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 130us/step - loss: 0.0442 - acc: 0.9832 - val_loss: 0.0453 - val_acc: 0.9829\n",
      "Epoch 6/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9838\n",
      " ROC-AUC - epoch: 6 - score: 0.988502 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04530 to 0.04437, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 17s 120us/step - loss: 0.0423 - acc: 0.9838 - val_loss: 0.0444 - val_acc: 0.9830\n",
      "Epoch 7/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9844\n",
      " ROC-AUC - epoch: 7 - score: 0.989150 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04437 to 0.04422, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 130us/step - loss: 0.0402 - acc: 0.9844 - val_loss: 0.0442 - val_acc: 0.9830\n",
      "Epoch 8/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9852\n",
      " ROC-AUC - epoch: 8 - score: 0.989322 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04422 to 0.04396, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 129us/step - loss: 0.0383 - acc: 0.9852 - val_loss: 0.0440 - val_acc: 0.9830\n",
      "Epoch 9/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9855\n",
      " ROC-AUC - epoch: 9 - score: 0.989565 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04396 to 0.04357, saving model to ./PureCnnModels/cnn_glt_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 17s 120us/step - loss: 0.0369 - acc: 0.9855 - val_loss: 0.0436 - val_acc: 0.9834\n",
      "Epoch 10/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9861\n",
      " ROC-AUC - epoch: 10 - score: 0.989580 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 18s 126us/step - loss: 0.0354 - acc: 0.9861 - val_loss: 0.0439 - val_acc: 0.9833\n",
      "Epoch 11/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9867\n",
      " ROC-AUC - epoch: 11 - score: 0.989436 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "143613/143613 [==============================] - 17s 117us/step - loss: 0.0339 - acc: 0.9867 - val_loss: 0.0441 - val_acc: 0.9833\n",
      "Epoch 12/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9873\n",
      " ROC-AUC - epoch: 12 - score: 0.989409 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "143613/143613 [==============================] - 18s 126us/step - loss: 0.0323 - acc: 0.9873 - val_loss: 0.0446 - val_acc: 0.9830\n",
      "Epoch 13/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9879\n",
      " ROC-AUC - epoch: 13 - score: 0.989374 \n",
      "\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "143613/143613 [==============================] - 17s 118us/step - loss: 0.0309 - acc: 0.9879 - val_loss: 0.0444 - val_acc: 0.9834\n",
      "Epoch 14/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9882\n",
      " ROC-AUC - epoch: 14 - score: 0.989225 \n",
      "\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "143613/143613 [==============================] - 18s 127us/step - loss: 0.0297 - acc: 0.9882 - val_loss: 0.0452 - val_acc: 0.9830\n",
      "1569267\n",
      "load model: ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9720\n",
      " ROC-AUC - epoch: 1 - score: 0.972471 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05089, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 23s 161us/step - loss: 0.0854 - acc: 0.9720 - val_loss: 0.0509 - val_acc: 0.9817\n",
      "Epoch 2/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9816\n",
      " ROC-AUC - epoch: 2 - score: 0.981411 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05089 to 0.04650, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 131us/step - loss: 0.0504 - acc: 0.9816 - val_loss: 0.0465 - val_acc: 0.9826\n",
      "Epoch 3/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9827\n",
      " ROC-AUC - epoch: 3 - score: 0.984390 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04650 to 0.04563, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 20s 140us/step - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0456 - val_acc: 0.9825\n",
      "Epoch 4/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9837\n",
      " ROC-AUC - epoch: 4 - score: 0.986255 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04563 to 0.04421, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 131us/step - loss: 0.0425 - acc: 0.9836 - val_loss: 0.0442 - val_acc: 0.9827\n",
      "Epoch 5/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9846\n",
      " ROC-AUC - epoch: 5 - score: 0.986814 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04421 to 0.04146, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 20s 141us/step - loss: 0.0400 - acc: 0.9846 - val_loss: 0.0415 - val_acc: 0.9838\n",
      "Epoch 6/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9851\n",
      " ROC-AUC - epoch: 6 - score: 0.987369 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "143613/143613 [==============================] - 20s 138us/step - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0423 - val_acc: 0.9835\n",
      "Epoch 7/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9860\n",
      " ROC-AUC - epoch: 7 - score: 0.987756 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04146 to 0.04120, saving model to ./PureCnnModels/cnn_glt_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 19s 132us/step - loss: 0.0355 - acc: 0.9860 - val_loss: 0.0412 - val_acc: 0.9837\n",
      "Epoch 8/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9868\n",
      " ROC-AUC - epoch: 8 - score: 0.987706 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 20s 138us/step - loss: 0.0336 - acc: 0.9868 - val_loss: 0.0439 - val_acc: 0.9831\n",
      "Epoch 9/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9876\n",
      " ROC-AUC - epoch: 9 - score: 0.987842 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "143613/143613 [==============================] - 18s 128us/step - loss: 0.0315 - acc: 0.9876 - val_loss: 0.0448 - val_acc: 0.9827\n",
      "Epoch 10/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9884\n",
      " ROC-AUC - epoch: 10 - score: 0.987383 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 20s 137us/step - loss: 0.0296 - acc: 0.9884 - val_loss: 0.0443 - val_acc: 0.9829\n",
      "1569477\n",
      "load model: ./PureCnnModels/cnn_glt_256_32_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9758\n",
      " ROC-AUC - epoch: 1 - score: 0.978988 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04735, saving model to ./PureCnnModels/cnn_glt_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 193us/step - loss: 0.0719 - acc: 0.9758 - val_loss: 0.0474 - val_acc: 0.9827\n",
      "Epoch 2/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9822\n",
      " ROC-AUC - epoch: 2 - score: 0.985955 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04735 to 0.04503, saving model to ./PureCnnModels/cnn_glt_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 24s 170us/step - loss: 0.0477 - acc: 0.9823 - val_loss: 0.0450 - val_acc: 0.9830\n",
      "Epoch 3/5\n",
      "143104/143613 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9837\n",
      " ROC-AUC - epoch: 3 - score: 0.986640 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04503 to 0.04268, saving model to ./PureCnnModels/cnn_glt_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 24s 167us/step - loss: 0.0427 - acc: 0.9837 - val_loss: 0.0427 - val_acc: 0.9834\n",
      "Epoch 4/5\n",
      "143104/143613 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9847\n",
      " ROC-AUC - epoch: 4 - score: 0.987723 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 22s 156us/step - loss: 0.0395 - acc: 0.9847 - val_loss: 0.0460 - val_acc: 0.9828\n",
      "Epoch 5/5\n",
      "143104/143613 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9856\n",
      " ROC-AUC - epoch: 5 - score: 0.987879 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 24s 165us/step - loss: 0.0366 - acc: 0.9856 - val_loss: 0.0433 - val_acc: 0.9835\n",
      "1569612\n",
      "23891 words not found in embedding file (after replacement attempt)\n",
      "3 words are replaced:\n",
      "{'suxk': 'suck', 'dickus': 'dick', 'fggt': 'faggot'}\n",
      "load model: ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9682\n",
      " ROC-AUC - epoch: 1 - score: 0.907848 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05287, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 31s 218us/step - loss: 0.0985 - acc: 0.9682 - val_loss: 0.0529 - val_acc: 0.9812\n",
      "Epoch 2/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9820\n",
      " ROC-AUC - epoch: 2 - score: 0.979812 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05287 to 0.04737, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 194us/step - loss: 0.0496 - acc: 0.9820 - val_loss: 0.0474 - val_acc: 0.9822\n",
      "Epoch 3/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9832\n",
      " ROC-AUC - epoch: 3 - score: 0.983782 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04737 to 0.04645, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 193us/step - loss: 0.0444 - acc: 0.9832 - val_loss: 0.0465 - val_acc: 0.9824\n",
      "Epoch 4/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9841\n",
      " ROC-AUC - epoch: 4 - score: 0.985100 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04645 to 0.04508, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 194us/step - loss: 0.0411 - acc: 0.9841 - val_loss: 0.0451 - val_acc: 0.9828\n",
      "Epoch 5/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9850\n",
      " ROC-AUC - epoch: 5 - score: 0.985722 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04508 to 0.04355, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 194us/step - loss: 0.0382 - acc: 0.9850 - val_loss: 0.0436 - val_acc: 0.9833\n",
      "Epoch 6/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9860\n",
      " ROC-AUC - epoch: 6 - score: 0.986328 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04355 to 0.04343, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 26s 184us/step - loss: 0.0357 - acc: 0.9860 - val_loss: 0.0434 - val_acc: 0.9834\n",
      "Epoch 7/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9869\n",
      " ROC-AUC - epoch: 7 - score: 0.986566 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04343 to 0.04340, saving model to ./PureCnnModels/cnn_ftc_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 194us/step - loss: 0.0333 - acc: 0.9869 - val_loss: 0.0434 - val_acc: 0.9830\n",
      "Epoch 8/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9879\n",
      " ROC-AUC - epoch: 8 - score: 0.986411 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 189us/step - loss: 0.0310 - acc: 0.9879 - val_loss: 0.0438 - val_acc: 0.9831\n",
      "Epoch 9/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9886\n",
      " ROC-AUC - epoch: 9 - score: 0.986154 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 189us/step - loss: 0.0287 - acc: 0.9886 - val_loss: 0.0444 - val_acc: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9895\n",
      " ROC-AUC - epoch: 10 - score: 0.985534 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 188us/step - loss: 0.0266 - acc: 0.9895 - val_loss: 0.0456 - val_acc: 0.9827\n",
      "Epoch 11/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9904\n",
      " ROC-AUC - epoch: 11 - score: 0.984837 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "143613/143613 [==============================] - 26s 179us/step - loss: 0.0241 - acc: 0.9904 - val_loss: 0.0467 - val_acc: 0.9826\n",
      "Epoch 12/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9915\n",
      " ROC-AUC - epoch: 12 - score: 0.984454 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 188us/step - loss: 0.0220 - acc: 0.9915 - val_loss: 0.0487 - val_acc: 0.9822\n",
      "1569960\n",
      "load model: ./PureCnnModels/cnn_ftc_512_48_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9709\n",
      " ROC-AUC - epoch: 1 - score: 0.980079 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04722, saving model to ./PureCnnModels/cnn_ftc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 34s 236us/step - loss: 0.0823 - acc: 0.9709 - val_loss: 0.0472 - val_acc: 0.9823\n",
      "Epoch 2/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9828\n",
      " ROC-AUC - epoch: 2 - score: 0.986083 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04722 to 0.04391, saving model to ./PureCnnModels/cnn_ftc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 209us/step - loss: 0.0461 - acc: 0.9828 - val_loss: 0.0439 - val_acc: 0.9830\n",
      "Epoch 3/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9842\n",
      " ROC-AUC - epoch: 3 - score: 0.987362 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04391 to 0.04312, saving model to ./PureCnnModels/cnn_ftc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 29s 201us/step - loss: 0.0410 - acc: 0.9842 - val_loss: 0.0431 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9853\n",
      " ROC-AUC - epoch: 4 - score: 0.987666 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04312 to 0.04175, saving model to ./PureCnnModels/cnn_ftc_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 210us/step - loss: 0.0375 - acc: 0.9853 - val_loss: 0.0417 - val_acc: 0.9833\n",
      "Epoch 5/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9866\n",
      " ROC-AUC - epoch: 5 - score: 0.987611 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0339 - acc: 0.9866 - val_loss: 0.0421 - val_acc: 0.9834\n",
      "Epoch 6/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9879\n",
      " ROC-AUC - epoch: 6 - score: 0.987030 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0307 - acc: 0.9879 - val_loss: 0.0447 - val_acc: 0.9825\n",
      "Epoch 7/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9890\n",
      " ROC-AUC - epoch: 7 - score: 0.986873 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 30s 206us/step - loss: 0.0277 - acc: 0.9890 - val_loss: 0.0447 - val_acc: 0.9830\n",
      "1570190\n",
      "load model: ./PureCnnModels/cnn_ftc_256_32_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9772\n",
      " ROC-AUC - epoch: 1 - score: 0.986498 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04552, saving model to ./PureCnnModels/cnn_ftc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 38s 267us/step - loss: 0.0662 - acc: 0.9772 - val_loss: 0.0455 - val_acc: 0.9825\n",
      "Epoch 2/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9835\n",
      " ROC-AUC - epoch: 2 - score: 0.989119 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04552 to 0.04255, saving model to ./PureCnnModels/cnn_ftc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 242us/step - loss: 0.0429 - acc: 0.9835 - val_loss: 0.0425 - val_acc: 0.9833\n",
      "Epoch 3/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9852\n",
      " ROC-AUC - epoch: 3 - score: 0.989366 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04255 to 0.04172, saving model to ./PureCnnModels/cnn_ftc_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 242us/step - loss: 0.0378 - acc: 0.9852 - val_loss: 0.0417 - val_acc: 0.9837\n",
      "Epoch 4/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9868\n",
      " ROC-AUC - epoch: 4 - score: 0.989336 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 237us/step - loss: 0.0334 - acc: 0.9868 - val_loss: 0.0425 - val_acc: 0.9831\n",
      "Epoch 5/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9884\n",
      " ROC-AUC - epoch: 5 - score: 0.988945 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 237us/step - loss: 0.0294 - acc: 0.9884 - val_loss: 0.0444 - val_acc: 0.9832\n",
      "1570384\n",
      "5940 words not found in embedding file (after replacement attempt)\n",
      "4 words are replaced:\n",
      "{'suxk': 'suck', 'assraped': 'ass', 'fggt': 'faggot', 'assface': 'ass'}\n",
      "load model: ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9741\n",
      " ROC-AUC - epoch: 1 - score: 0.933235 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05037, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 31s 219us/step - loss: 0.0896 - acc: 0.9741 - val_loss: 0.0504 - val_acc: 0.9823\n",
      "Epoch 2/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9817\n",
      " ROC-AUC - epoch: 2 - score: 0.982714 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05037 to 0.04452, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 192us/step - loss: 0.0498 - acc: 0.9817 - val_loss: 0.0445 - val_acc: 0.9835\n",
      "Epoch 3/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9832\n",
      " ROC-AUC - epoch: 3 - score: 0.987183 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04452 to 0.04327, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 193us/step - loss: 0.0443 - acc: 0.9832 - val_loss: 0.0433 - val_acc: 0.9834\n",
      "Epoch 4/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9843\n",
      " ROC-AUC - epoch: 4 - score: 0.988808 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04327 to 0.04148, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 192us/step - loss: 0.0408 - acc: 0.9843 - val_loss: 0.0415 - val_acc: 0.9836\n",
      "Epoch 5/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9850\n",
      " ROC-AUC - epoch: 5 - score: 0.989662 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04148 to 0.04088, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 26s 183us/step - loss: 0.0381 - acc: 0.9850 - val_loss: 0.0409 - val_acc: 0.9835\n",
      "Epoch 6/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9860\n",
      " ROC-AUC - epoch: 6 - score: 0.990089 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04088 to 0.03996, saving model to ./PureCnnModels/cnn_ftw_1024_64_w_dict.hdf5\n",
      "143613/143613 [==============================] - 28s 193us/step - loss: 0.0353 - acc: 0.9860 - val_loss: 0.0400 - val_acc: 0.9840\n",
      "Epoch 7/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9869\n",
      " ROC-AUC - epoch: 7 - score: 0.990273 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 188us/step - loss: 0.0330 - acc: 0.9869 - val_loss: 0.0418 - val_acc: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9877\n",
      " ROC-AUC - epoch: 8 - score: 0.990170 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 189us/step - loss: 0.0306 - acc: 0.9877 - val_loss: 0.0406 - val_acc: 0.9840\n",
      "Epoch 9/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9886\n",
      " ROC-AUC - epoch: 9 - score: 0.989961 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 188us/step - loss: 0.0286 - acc: 0.9886 - val_loss: 0.0412 - val_acc: 0.9838\n",
      "Epoch 10/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9897\n",
      " ROC-AUC - epoch: 10 - score: 0.989662 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "143613/143613 [==============================] - 27s 188us/step - loss: 0.0262 - acc: 0.9897 - val_loss: 0.0421 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9905\n",
      " ROC-AUC - epoch: 11 - score: 0.989278 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "143613/143613 [==============================] - 26s 179us/step - loss: 0.0241 - acc: 0.9905 - val_loss: 0.0437 - val_acc: 0.9834\n",
      "1570705\n",
      "load model: ./PureCnnModels/cnn_ftw_512_48_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9755\n",
      " ROC-AUC - epoch: 1 - score: 0.978889 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04693, saving model to ./PureCnnModels/cnn_ftw_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 34s 236us/step - loss: 0.0761 - acc: 0.9755 - val_loss: 0.0469 - val_acc: 0.9830\n",
      "Epoch 2/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9826\n",
      " ROC-AUC - epoch: 2 - score: 0.985816 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04693 to 0.04421, saving model to ./PureCnnModels/cnn_ftw_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 209us/step - loss: 0.0460 - acc: 0.9826 - val_loss: 0.0442 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9841\n",
      " ROC-AUC - epoch: 3 - score: 0.988028 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04421 to 0.04249, saving model to ./PureCnnModels/cnn_ftw_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 208us/step - loss: 0.0411 - acc: 0.9841 - val_loss: 0.0425 - val_acc: 0.9834\n",
      "Epoch 4/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9854\n",
      " ROC-AUC - epoch: 4 - score: 0.988818 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04249 to 0.04170, saving model to ./PureCnnModels/cnn_ftw_512_48_w_dict.hdf5\n",
      "143613/143613 [==============================] - 30s 209us/step - loss: 0.0372 - acc: 0.9854 - val_loss: 0.0417 - val_acc: 0.9837\n",
      "Epoch 5/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9865\n",
      " ROC-AUC - epoch: 5 - score: 0.989096 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 28s 195us/step - loss: 0.0340 - acc: 0.9865 - val_loss: 0.0419 - val_acc: 0.9837\n",
      "Epoch 6/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9878\n",
      " ROC-AUC - epoch: 6 - score: 0.988705 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 205us/step - loss: 0.0307 - acc: 0.9878 - val_loss: 0.0420 - val_acc: 0.9837\n",
      "Epoch 7/10\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9889\n",
      " ROC-AUC - epoch: 7 - score: 0.988236 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "143613/143613 [==============================] - 29s 204us/step - loss: 0.0277 - acc: 0.9889 - val_loss: 0.0433 - val_acc: 0.9835\n",
      "1570933\n",
      "load model: ./PureCnnModels/cnn_ftw_256_32_w_dict.hdf5\n",
      "no model found\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9779\n",
      " ROC-AUC - epoch: 1 - score: 0.983787 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04321, saving model to ./PureCnnModels/cnn_ftw_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 39s 273us/step - loss: 0.0646 - acc: 0.9779 - val_loss: 0.0432 - val_acc: 0.9834\n",
      "Epoch 2/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9834\n",
      " ROC-AUC - epoch: 2 - score: 0.987372 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04321 to 0.04120, saving model to ./PureCnnModels/cnn_ftw_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 243us/step - loss: 0.0430 - acc: 0.9834 - val_loss: 0.0412 - val_acc: 0.9834\n",
      "Epoch 3/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9851\n",
      " ROC-AUC - epoch: 3 - score: 0.988335 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04120 to 0.04059, saving model to ./PureCnnModels/cnn_ftw_256_32_w_dict.hdf5\n",
      "143613/143613 [==============================] - 35s 243us/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.0406 - val_acc: 0.9838\n",
      "Epoch 4/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9868\n",
      " ROC-AUC - epoch: 4 - score: 0.988853 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 238us/step - loss: 0.0336 - acc: 0.9868 - val_loss: 0.0414 - val_acc: 0.9835\n",
      "Epoch 5/5\n",
      "143360/143613 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9884\n",
      " ROC-AUC - epoch: 5 - score: 0.988691 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "143613/143613 [==============================] - 34s 238us/step - loss: 0.0295 - acc: 0.9884 - val_loss: 0.0420 - val_acc: 0.9840\n",
      "1571130\n"
     ]
    }
   ],
   "source": [
    "for embeddings_index, embed_size, embedding_name in embeddings_index_pool:\n",
    "    \n",
    "    embedding_matrix, _, _ = get_embedding_matrix(embeddings_index, embed_size, max_features, tokenizer, bad_word_dict)\n",
    "\n",
    "    for batch_size, epochs, patience, num_filters in batch_epoch_patience_pool:\n",
    "\n",
    "        model = get_model(maxlen, max_features, embedding_matrix, embed_size)\n",
    "\n",
    "        X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.90)#, random_state=233)\n",
    "\n",
    "        run_name = \"cnn_{}_{}_{}_w_dict\".format(embedding_name, batch_size, num_filters)\n",
    "        model_file = './PureCnnModels/' + run_name + '.hdf5'\n",
    "        try: \n",
    "            print('load model: ' + str(model_file))\n",
    "            model.load_weights(model_file)\n",
    "        except OSError: \n",
    "            print('no model found')\n",
    "\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n",
    "        checkpoint = ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')    \n",
    "        roc_auc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "        hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                         callbacks=[roc_auc, checkpoint, early], verbose=1)\n",
    "\n",
    "\n",
    "        model.load_weights(model_file)\n",
    "        y_pred = model.predict(x_test, batch_size=1024)\n",
    "        submission = pd.read_csv('~/data/toxic/data/sample_submission.csv')\n",
    "        submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "        import time\n",
    "        sub_id = str(int(time.time()))[3:]\n",
    "        print(sub_id)\n",
    "        submission.to_csv('./PureCnnPreds/' + run_name + '_' + sub_id + '.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)\n",
    "K.set_session(tf.Session(graph=tf.get_default_graph(), config=session_conf))\n",
    "\n",
    "#model\n",
    "#wrote out all the blocks instead of looping for simplicity\n",
    "filter_nr = 64\n",
    "filter_size = 3\n",
    "max_pool_size = 3\n",
    "max_pool_strides = 2\n",
    "dense_nr = 256\n",
    "spatial_dropout = 0.2\n",
    "dense_dropout = 0.5\n",
    "train_embed = False\n",
    "conv_kern_reg = regularizers.l2(0.00001)\n",
    "conv_bias_reg = regularizers.l2(0.00001)\n",
    "\n",
    "comment = Input(shape=(maxlen,))\n",
    "emb_comment = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=train_embed)(comment)\n",
    "emb_comment = SpatialDropout1D(spatial_dropout)(emb_comment)\n",
    "\n",
    "block1 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(emb_comment)\n",
    "block1 = BatchNormalization()(block1)\n",
    "block1 = PReLU()(block1)\n",
    "block1 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block1)\n",
    "block1 = BatchNormalization()(block1)\n",
    "block1 = PReLU()(block1)\n",
    "\n",
    "#we pass embedded comment through conv1d with filter size 1 because it needs to have the same shape as block output\n",
    "#if you choose filter_nr = embed_size (300 in this case) you don't have to do this part and can add emb_comment directly to block1_output\n",
    "resize_emb = Conv1D(filter_nr, kernel_size=1, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(emb_comment)\n",
    "resize_emb = PReLU()(resize_emb)\n",
    "    \n",
    "block1_output = add([block1, resize_emb])\n",
    "block1_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block1_output)\n",
    "\n",
    "block2 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block1_output)\n",
    "block2 = BatchNormalization()(block2)\n",
    "block2 = PReLU()(block2)\n",
    "block2 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block2)\n",
    "block2 = BatchNormalization()(block2)\n",
    "block2 = PReLU()(block2)\n",
    "    \n",
    "block2_output = add([block2, block1_output])\n",
    "block2_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block2_output)\n",
    "\n",
    "block3 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block2_output)\n",
    "block3 = BatchNormalization()(block3)\n",
    "block3 = PReLU()(block3)\n",
    "block3 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block3)\n",
    "block3 = BatchNormalization()(block3)\n",
    "block3 = PReLU()(block3)\n",
    "    \n",
    "block3_output = add([block3, block2_output])\n",
    "block3_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block3_output)\n",
    "\n",
    "block4 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block3_output)\n",
    "block4 = BatchNormalization()(block4)\n",
    "block4 = PReLU()(block4)\n",
    "block4 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block4)\n",
    "block4 = BatchNormalization()(block4)\n",
    "block4 = PReLU()(block4)\n",
    "\n",
    "block4_output = add([block4, block3_output])\n",
    "block4_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block4_output)\n",
    "\n",
    "block5 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block4_output)\n",
    "block5 = BatchNormalization()(block5)\n",
    "block5 = PReLU()(block5)\n",
    "block5 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block5)\n",
    "block5 = BatchNormalization()(block5)\n",
    "block5 = PReLU()(block5)\n",
    "\n",
    "block5_output = add([block5, block4_output])\n",
    "block5_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block5_output)\n",
    "\n",
    "block6 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block5_output)\n",
    "block6 = BatchNormalization()(block6)\n",
    "block6 = PReLU()(block6)\n",
    "block6 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block6)\n",
    "block6 = BatchNormalization()(block6)\n",
    "block6 = PReLU()(block6)\n",
    "\n",
    "block6_output = add([block6, block5_output])\n",
    "block6_output = MaxPooling1D(pool_size=max_pool_size, strides=max_pool_strides)(block6_output)\n",
    "\n",
    "block7 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block6_output)\n",
    "block7 = BatchNormalization()(block7)\n",
    "block7 = PReLU()(block7)\n",
    "block7 = Conv1D(filter_nr, kernel_size=filter_size, padding='same', activation='linear', \n",
    "            kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg)(block7)\n",
    "block7 = BatchNormalization()(block7)\n",
    "block7 = PReLU()(block7)\n",
    "\n",
    "block7_output = add([block7, block6_output])\n",
    "output = GlobalMaxPooling1D()(block7_output)\n",
    "\n",
    "output = Dense(dense_nr, activation='linear')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = PReLU()(output)\n",
    "output = Dropout(dense_dropout)(output)\n",
    "output = Dense(6, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(comment, output)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizers.Adam(lr=1e-4),\n",
    "            metrics=['accuracy'])\n",
    "            \n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(x_train, y_train, train_size=0.9)#, random_state=233)\n",
    "\n",
    "run_name = \"cnn_{}_{}_w_dict\".format('ftc', batch_size)\n",
    "model_file = './PureCnnModels/' + run_name + '.hdf5'\n",
    "try: \n",
    "    print('load model: ' + str(model_file))\n",
    "    model.load_weights(model_file)\n",
    "except OSError: \n",
    "    print('no model found')\n",
    "\n",
    "#lr = callbacks.LearningRateScheduler(schedule) # instead using fixed lr: 1e-4\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "ra_val = RocAucEvaluation(validation_data=(Xval, yval), interval = 1)\n",
    "checkpoint = ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(Xtrain, ytrain, batch_size=batch_size, epochs=epochs, validation_data=(Xval, yval), \n",
    "          callbacks = [ra_val, early, checkpoint] ,verbose=1)\n",
    "\n",
    "\n",
    "model.load_weights(model_file)\n",
    "y_pred = model.predict(x_test,batch_size=1024,verbose=1)\n",
    "submission = pd.read_csv('~/data/toxic/data/sample_submission.csv')\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "import time\n",
    "sub_id = str(int(time.time()))[3:]\n",
    "print(sub_id)\n",
    "submission.to_csv('./PureCnnPreds/' + run_name + '_' + sub_id + '.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.993278</td>\n",
       "      <td>3.908302e-01</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.192109</td>\n",
       "      <td>0.826996</td>\n",
       "      <td>2.555371e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>9.759669e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.748934e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>1.736008e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.260338e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.984340e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9.113581e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>9.894452e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.017124e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.993278  3.908302e-01  0.952778  0.192109  0.826996   \n",
       "1  0000247867823ef7  0.000467  9.759669e-07  0.000011  0.000022  0.000024   \n",
       "2  00013b17ad220c46  0.000141  1.736008e-07  0.000001  0.000011  0.000007   \n",
       "3  00017563c3f7919a  0.000034  1.984340e-06  0.000004  0.000003  0.000011   \n",
       "4  00017695ad8997eb  0.000953  9.894452e-07  0.000019  0.000040  0.000047   \n",
       "\n",
       "   identity_hate  \n",
       "0   2.555371e-01  \n",
       "1   1.748934e-06  \n",
       "2   1.260338e-06  \n",
       "3   9.113581e-07  \n",
       "4   3.017124e-06  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./PureCnnPreds/' + run_name + '_' + sub_id + '.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 200, 300)     30000000    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 200, 300)     0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 200, 64)      57664       spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 200, 64)      256         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_81 (PReLU)              (None, 200, 64)      12800       batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 200, 64)      12352       p_re_lu_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 200, 64)      256         conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 200, 64)      19264       spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_82 (PReLU)              (None, 200, 64)      12800       batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_83 (PReLU)              (None, 200, 64)      12800       conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 200, 64)      0           p_re_lu_82[0][0]                 \n",
      "                                                                 p_re_lu_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 99, 64)       0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 99, 64)       12352       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 99, 64)       256         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_84 (PReLU)              (None, 99, 64)       6336        batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 99, 64)       12352       p_re_lu_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 99, 64)       256         conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_85 (PReLU)              (None, 99, 64)       6336        batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 99, 64)       0           p_re_lu_85[0][0]                 \n",
      "                                                                 max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 49, 64)       0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 49, 64)       12352       max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 49, 64)       256         conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_86 (PReLU)              (None, 49, 64)       3136        batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 49, 64)       12352       p_re_lu_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 49, 64)       256         conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_87 (PReLU)              (None, 49, 64)       3136        batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 49, 64)       0           p_re_lu_87[0][0]                 \n",
      "                                                                 max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 24, 64)       0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 24, 64)       12352       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 24, 64)       256         conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_88 (PReLU)              (None, 24, 64)       1536        batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 24, 64)       12352       p_re_lu_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 24, 64)       256         conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_89 (PReLU)              (None, 24, 64)       1536        batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 24, 64)       0           p_re_lu_89[0][0]                 \n",
      "                                                                 max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 11, 64)       0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 11, 64)       12352       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 11, 64)       256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_90 (PReLU)              (None, 11, 64)       704         batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 11, 64)       12352       p_re_lu_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 11, 64)       256         conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_91 (PReLU)              (None, 11, 64)       704         batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 11, 64)       0           p_re_lu_91[0][0]                 \n",
      "                                                                 max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 5, 64)        0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 5, 64)        12352       max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 64)        256         conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_92 (PReLU)              (None, 5, 64)        320         batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 5, 64)        12352       p_re_lu_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 64)        256         conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_93 (PReLU)              (None, 5, 64)        320         batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 5, 64)        0           p_re_lu_93[0][0]                 \n",
      "                                                                 max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 2, 64)        0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 2, 64)        12352       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 64)        256         conv1d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_94 (PReLU)              (None, 2, 64)        128         batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 2, 64)        12352       p_re_lu_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 64)        256         conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_95 (PReLU)              (None, 2, 64)        128         batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 2, 64)        0           p_re_lu_95[0][0]                 \n",
      "                                                                 max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 64)           0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          16640       global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 256)          1024        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_96 (PReLU)              (None, 256)          256         batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           p_re_lu_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            1542        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,323,270\n",
      "Trainable params: 320,966\n",
      "Non-trainable params: 30,002,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
