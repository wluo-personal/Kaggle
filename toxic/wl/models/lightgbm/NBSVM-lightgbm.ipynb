{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 30)\n",
      "(153164, 24)\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'cleaned_train.csv')\n",
    "test = pd.read_csv(PATH + 'cleaned_test.csv')\n",
    "\n",
    "\n",
    "train_sentence = train['comment_text_cleaned_polarity']\n",
    "test_sentence = test['comment_text_cleaned_polarity']\n",
    "\n",
    "\n",
    "train_sentence_retain_punctuation = train['comment_text_cleaned_retain_punctuation']\n",
    "test_sentence_retain_punctuation = test['comment_text_cleaned_retain_punctuation']\n",
    "\n",
    "text = train_sentence\n",
    "\n",
    "text_retain_punctuation = train_sentence_retain_punctuation\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting char\n",
      "fitting phrase\n",
      "transforming train skip gram\n",
      "transforming train char\n",
      "transforming train phrase\n",
      "transforming test char\n",
      "transforming test phrase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<159571x300000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 162813546 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "char_vectorizer = TfidfVectorizer(ngram_range=(2,5), \n",
    "                                  strip_accents='unicode', \n",
    "                                  max_features=200000, \n",
    "                                  analyzer='char', \n",
    "                                  sublinear_tf=True)\n",
    "\n",
    "print('fitting char')\n",
    "char_vectorizer.fit(text_retain_punctuation.values)\n",
    "print('fitting phrase')\n",
    "phrase_vectorizer.fit(text.values)\n",
    "\n",
    "print('transforming train skip gram')\n",
    "\n",
    "print('transforming train char')\n",
    "train_char = char_vectorizer.transform(train_sentence_retain_punctuation.values)\n",
    "print('transforming train phrase')\n",
    "train_phrase = phrase_vectorizer.transform(train_sentence.values)\n",
    "\n",
    "\n",
    "print('transforming test char')\n",
    "test_char = char_vectorizer.transform(test_sentence_retain_punctuation.values)\n",
    "print('transforming test phrase')\n",
    "test_phrase = phrase_vectorizer.transform(test_sentence.values)\n",
    "\n",
    "\n",
    "train_tfidf = hstack((train_char, train_phrase), format='csr')\n",
    "test_tfidf = hstack((test_char, test_phrase), format='csr')\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_val, y_train_df, y_val_df = train_test_split(train_tfidf, train, test_size=0.33)\n",
    "# # Split the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "split_index = round(len(train) * 0.999) #################################\n",
    "shuffled_train = train#.sample(frac=1)\n",
    "x_train = train_tfidf[:split_index]\n",
    "y_train_df = train.iloc[:split_index]\n",
    "#######\n",
    "x_val = train_tfidf[split_index:]\n",
    "y_val_df = train.iloc[split_index:]\n",
    "# Get test data ready\n",
    "x_test = test_tfidf\n",
    "\n",
    "\n",
    "# train toxic\n",
    "def pr(y_i, y, train_features):\n",
    "    p = train_features[y==y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)\n",
    "r_dict = {label: np.log(pr(1, y_train_df[label].values, x_train) / pr(0,  y_train_df[label].values, x_train)) for label in label_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = {label: x_train.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "val_set = {label: x_val.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "test_set = {label: x_test.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's auc: 0.955896\n",
      "[20]\tvalid_0's auc: 0.9664\n",
      "[30]\tvalid_0's auc: 0.972706\n",
      "[40]\tvalid_0's auc: 0.974617\n",
      "[50]\tvalid_0's auc: 0.975766\n",
      "[60]\tvalid_0's auc: 0.975818\n",
      "[70]\tvalid_0's auc: 0.975509\n",
      "[80]\tvalid_0's auc: 0.975836\n",
      "[90]\tvalid_0's auc: 0.97558\n",
      "[100]\tvalid_0's auc: 0.975754\n"
     ]
    }
   ],
   "source": [
    "for \n",
    "lgb_train_set = lgb.Dataset(train_set['toxic'], y_train_df['toxic'].values)\n",
    "lgb_eval_set = lgb.Dataset(val_set['toxic'], y_val_df['toxic'].values, reference=lgb_train_set)\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': {'binary', 'auc'},\n",
    "#     'learning_rate': 0.2,\n",
    "#     'num_iterations': 100,\n",
    "#     'num_leaves': 171,\n",
    "#     'device': 'cpu',\n",
    "#     'num_threads': 24,\n",
    "#     'max_depth': -1,\n",
    "# #     'min_data_in_leaf': 5,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 1,\n",
    "#     'feature_fraction': 0.8,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 1}\n",
    "\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'application': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'auc',\n",
    "    'data_random_seed': 2,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.6,\n",
    "    'nthread': 4,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1\n",
    "} \n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train_set,\n",
    "                valid_sets=lgb_eval_set,\n",
    "               verbose_eval=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9757536846018412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y = y_val_df['toxic']\n",
    "pred = gbm.predict(val_set['toxic'])\n",
    "print('accuracy is {}'.format(roc_auc_score(y,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_char = {v: k for k, v in char_vectorizer.vocabulary_.items()}\n",
    "inv_phrase = {v: k for k, v in phrase_vectorizer.vocabulary_.items()}\n",
    "features = []\n",
    "features_char = [inv_char[i] for i in range(0,train_char.shape[1] )]\n",
    "features_phrase = [inv_phrase[i] for i in range(0,train_phrase.shape[1])]\n",
    "features.extend(features_char)\n",
    "features.extend(features_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame()\n",
    "df_importance['score'] = pd.Series(gbm.feature_importance()) \n",
    "df_importance['feature'] = pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218188</th>\n",
       "      <td>46</td>\n",
       "      <td>cleaned_neutral_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59935</th>\n",
       "      <td>45</td>\n",
       "      <td>ck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238597</th>\n",
       "      <td>40</td>\n",
       "      <td>hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168584</th>\n",
       "      <td>38</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13651</th>\n",
       "      <td>36</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176282</th>\n",
       "      <td>32</td>\n",
       "      <td>tard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259985</th>\n",
       "      <td>31</td>\n",
       "      <td>original_neutral_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>31</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169118</th>\n",
       "      <td>29</td>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198234</th>\n",
       "      <td>28</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143807</th>\n",
       "      <td>26</td>\n",
       "      <td>oo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101210</th>\n",
       "      <td>26</td>\n",
       "      <td>idi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>25</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89102</th>\n",
       "      <td>25</td>\n",
       "      <td>gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218202</th>\n",
       "      <td>25</td>\n",
       "      <td>cleaned_neutral_0 original_neutral_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>25</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11058</th>\n",
       "      <td>23</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47904</th>\n",
       "      <td>23</td>\n",
       "      <td>ant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147812</th>\n",
       "      <td>23</td>\n",
       "      <td>ov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018</th>\n",
       "      <td>22</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50448</th>\n",
       "      <td>22</td>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96233</th>\n",
       "      <td>22</td>\n",
       "      <td>hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172680</th>\n",
       "      <td>22</td>\n",
       "      <td>stup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100568</th>\n",
       "      <td>22</td>\n",
       "      <td>ick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171342</th>\n",
       "      <td>22</td>\n",
       "      <td>ss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157591</th>\n",
       "      <td>22</td>\n",
       "      <td>re a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175235</th>\n",
       "      <td>22</td>\n",
       "      <td>t the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12271</th>\n",
       "      <td>21</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101282</th>\n",
       "      <td>0</td>\n",
       "      <td>ids .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101281</th>\n",
       "      <td>0</td>\n",
       "      <td>ids )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101280</th>\n",
       "      <td>0</td>\n",
       "      <td>ids (</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101277</th>\n",
       "      <td>0</td>\n",
       "      <td>idr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101287</th>\n",
       "      <td>0</td>\n",
       "      <td>ids d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101276</th>\n",
       "      <td>0</td>\n",
       "      <td>idow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101275</th>\n",
       "      <td>0</td>\n",
       "      <td>idow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101274</th>\n",
       "      <td>0</td>\n",
       "      <td>idot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101273</th>\n",
       "      <td>0</td>\n",
       "      <td>idos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101272</th>\n",
       "      <td>0</td>\n",
       "      <td>idor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101271</th>\n",
       "      <td>0</td>\n",
       "      <td>idor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101286</th>\n",
       "      <td>0</td>\n",
       "      <td>ids c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101288</th>\n",
       "      <td>0</td>\n",
       "      <td>ids e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101304</th>\n",
       "      <td>0</td>\n",
       "      <td>idst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101297</th>\n",
       "      <td>0</td>\n",
       "      <td>ids s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101303</th>\n",
       "      <td>0</td>\n",
       "      <td>idson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101302</th>\n",
       "      <td>0</td>\n",
       "      <td>idso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101301</th>\n",
       "      <td>0</td>\n",
       "      <td>idsai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101300</th>\n",
       "      <td>0</td>\n",
       "      <td>idsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101299</th>\n",
       "      <td>0</td>\n",
       "      <td>ids w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101298</th>\n",
       "      <td>0</td>\n",
       "      <td>ids t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101296</th>\n",
       "      <td>0</td>\n",
       "      <td>ids r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101289</th>\n",
       "      <td>0</td>\n",
       "      <td>ids f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101295</th>\n",
       "      <td>0</td>\n",
       "      <td>ids p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101294</th>\n",
       "      <td>0</td>\n",
       "      <td>ids o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101293</th>\n",
       "      <td>0</td>\n",
       "      <td>ids m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101292</th>\n",
       "      <td>0</td>\n",
       "      <td>ids l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101291</th>\n",
       "      <td>0</td>\n",
       "      <td>ids i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101290</th>\n",
       "      <td>0</td>\n",
       "      <td>ids h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0</td>\n",
       "      <td>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score                                            feature\n",
       "4          51                                                  !\n",
       "218188     46                                  cleaned_neutral_0\n",
       "59935      45                                                 ck\n",
       "238597     40                                               hell\n",
       "168584     38                                                sex\n",
       "13651      36                                                me \n",
       "176282     32                                               tard\n",
       "259985     31                                 original_neutral_0\n",
       "1050       31                                                  )\n",
       "169118     29                                               shit\n",
       "198234     28                                               your\n",
       "143807     26                                                 oo\n",
       "101210     26                                                idi\n",
       "6752       25                                               ass \n",
       "89102      25                                                gay\n",
       "218202     25               cleaned_neutral_0 original_neutral_0\n",
       "6999       25                                                 ba\n",
       "11058      23                                                 he\n",
       "47904      23                                                ant\n",
       "147812     23                                                 ov\n",
       "20018      22                                               your\n",
       "50448      22                                                ass\n",
       "96233      22                                                hit\n",
       "172680     22                                               stup\n",
       "100568     22                                                ick\n",
       "171342     22                                                ss \n",
       "157591     22                                              re a \n",
       "175235     22                                              t the\n",
       "12271      21                                                  j\n",
       "5          21                                                 ! \n",
       "...       ...                                                ...\n",
       "101282      0                                              ids .\n",
       "101281      0                                              ids )\n",
       "101280      0                                              ids (\n",
       "101277      0                                                idr\n",
       "101287      0                                              ids d\n",
       "101276      0                                              idow \n",
       "101275      0                                               idow\n",
       "101274      0                                               idot\n",
       "101273      0                                               idos\n",
       "101272      0                                              idor \n",
       "101271      0                                               idor\n",
       "101286      0                                              ids c\n",
       "101288      0                                              ids e\n",
       "101304      0                                               idst\n",
       "101297      0                                              ids s\n",
       "101303      0                                              idson\n",
       "101302      0                                               idso\n",
       "101301      0                                              idsai\n",
       "101300      0                                               idsa\n",
       "101299      0                                              ids w\n",
       "101298      0                                              ids t\n",
       "101296      0                                              ids r\n",
       "101289      0                                              ids f\n",
       "101295      0                                              ids p\n",
       "101294      0                                              ids o\n",
       "101293      0                                              ids m\n",
       "101292      0                                              ids l\n",
       "101291      0                                              ids i\n",
       "101290      0                                              ids h\n",
       "299999      0  zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz...\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[20]\tvalid_0's auc: 0.961945\n",
      "[40]\tvalid_0's auc: 0.980012\n",
      "[60]\tvalid_0's auc: 0.986639\n",
      "[80]\tvalid_0's auc: 0.99028\n",
      "[100]\tvalid_0's auc: 0.99275\n",
      "severe_toxic\n",
      "[20]\tvalid_0's auc: 0.98983\n",
      "[40]\tvalid_0's auc: 0.996956\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "lgb_train_set = {}\n",
    "lgb_eval_set = {}\n",
    "gbm_model = {}\n",
    "y_pred = pd.DataFrame()\n",
    "y_pred['id'] = test['id']\n",
    "for col in label_cols:\n",
    "    # create dataset for lightgbm\n",
    "\n",
    "\n",
    "    params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary', 'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'auc',\n",
    "    'data_random_seed': 2,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.6,\n",
    "    'nthread': 4,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1\n",
    "    } \n",
    "\n",
    "    print(col)\n",
    "    lgb_train_set[col] = lgb.Dataset(train_set[col], y_train_df[col].values)\n",
    "    lgb_eval_set[col] = lgb.Dataset(train_set[col], y_train_df[col].values, reference=lgb_train_set[col])\n",
    "    \n",
    "\n",
    "    gbm_model[col] = lgb.train(params,\n",
    "                        lgb_train_set[col],\n",
    "                        valid_sets=lgb_eval_set[col],\n",
    "                       verbose_eval=20)\n",
    "    y_pred[col] =  gbm_model[col].predict(test_set[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred.to_csv(PATH + 'lgbm_nb_tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
