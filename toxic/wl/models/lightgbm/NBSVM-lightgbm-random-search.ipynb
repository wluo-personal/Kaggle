{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 30)\n",
      "(153164, 24)\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'cleaned_train.csv')\n",
    "test = pd.read_csv(PATH + 'cleaned_test.csv')\n",
    "\n",
    "\n",
    "train_sentence = train['comment_text_cleaned_polarity']\n",
    "test_sentence = test['comment_text_cleaned_polarity']\n",
    "\n",
    "\n",
    "train_sentence_retain_punctuation = train['comment_text_cleaned_retain_punctuation']\n",
    "test_sentence_retain_punctuation = test['comment_text_cleaned_retain_punctuation']\n",
    "\n",
    "text = train_sentence\n",
    "\n",
    "text_retain_punctuation = train_sentence_retain_punctuation\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting char\n",
      "fitting phrase\n",
      "transforming train skip gram\n",
      "transforming train char\n",
      "transforming train phrase\n",
      "transforming test char\n",
      "transforming test phrase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<159571x300000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 127727707 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "# train toxic\n",
    "def pr(y_i, y, train_features):\n",
    "    p = train_features[y==y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)\n",
    "\n",
    "def generate_tfidf(ngram_char_low, ngram_char_max):\n",
    "\n",
    "    phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                        strip_accents='unicode', \n",
    "                                        max_features=100000, \n",
    "                                        analyzer='word',\n",
    "                                        sublinear_tf=True,\n",
    "                                        stop_words='english',\n",
    "                                        token_pattern=r'\\w{1,}')\n",
    "    char_vectorizer = TfidfVectorizer(ngram_range=(ngram_char_low,ngram_char_max), \n",
    "                                      strip_accents='unicode', \n",
    "                                      max_features=200000, \n",
    "                                      analyzer='char', \n",
    "                                        max_df= 0.3,\n",
    "                                      sublinear_tf=True)\n",
    "\n",
    "    print('fitting char')\n",
    "    char_vectorizer.fit(text_retain_punctuation.values)\n",
    "    print('fitting phrase')\n",
    "    phrase_vectorizer.fit(text.values)\n",
    "\n",
    "    print('transforming train skip gram')\n",
    "\n",
    "    print('transforming train char')\n",
    "    train_char = char_vectorizer.transform(train_sentence_retain_punctuation.values)\n",
    "    print('transforming train phrase')\n",
    "    train_phrase = phrase_vectorizer.transform(train_sentence.values)\n",
    "\n",
    "\n",
    "    print('transforming test char')\n",
    "    test_char = char_vectorizer.transform(test_sentence_retain_punctuation.values)\n",
    "    print('transforming test phrase')\n",
    "    test_phrase = phrase_vectorizer.transform(test_sentence.values)\n",
    "\n",
    "\n",
    "    train_tfidf = hstack((train_char, train_phrase), format='csr')\n",
    "    test_tfidf = hstack((test_char, test_phrase), format='csr')\n",
    "    \n",
    "    #########################################\n",
    "    # from sklearn.model_selection import train_test_split\n",
    "    # x_train, x_val, y_train_df, y_val_df = train_test_split(train_tfidf, train, test_size=0.33)\n",
    "    # # Split the dataset\n",
    "\n",
    "\n",
    "\n",
    "    # Split the dataset\n",
    "    split_index = round(len(train) * 0.9) #################################\n",
    "    shuffled_train = train#.sample(frac=1)\n",
    "    x_train = train_tfidf[:split_index]\n",
    "    y_train_df = train.iloc[:split_index]\n",
    "    #######\n",
    "    x_val = train_tfidf[split_index:]\n",
    "    y_val_df = train.iloc[split_index:]\n",
    "    # Get test data ready\n",
    "    x_test = test_tfidf\n",
    "\n",
    "\n",
    "    r_dict = {label: np.log(pr(1, y_train_df[label].values, x_train) / pr(0,  y_train_df[label].values, x_train)) for label in label_cols}\n",
    "\n",
    "    train_set = {label: x_train.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "    val_set = {label: x_val.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "    test_set = {label: x_test.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "    return {'train_set':train_set,\n",
    "            'val_set':val_set,\n",
    "            'test_set':test_set,\n",
    "            'y_train_df':y_train_df,\n",
    "            'y_val_df':y_val_df}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_val, y_train_df, y_val_df = train_test_split(train_tfidf, train, test_size=0.33)\n",
    "# # Split the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "split_index = round(len(train) * 0.9) #################################\n",
    "shuffled_train = train#.sample(frac=1)\n",
    "x_train = train_tfidf[:split_index]\n",
    "y_train_df = train.iloc[:split_index]\n",
    "#######\n",
    "x_val = train_tfidf[split_index:]\n",
    "y_val_df = train.iloc[split_index:]\n",
    "# Get test data ready\n",
    "x_test = test_tfidf\n",
    "\n",
    "\n",
    "# train toxic\n",
    "def pr(y_i, y, train_features):\n",
    "    p = train_features[y==y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)\n",
    "r_dict = {label: np.log(pr(1, y_train_df[label].values, x_train) / pr(0,  y_train_df[label].values, x_train)) for label in label_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = {label: x_train.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "val_set = {label: x_val.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "test_set = {label: x_test.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train_set = lgb.Dataset(train_set['toxic'], y_train_df['toxic'].values)\n",
    "lgb_eval_set = lgb.Dataset(val_set['toxic'], y_val_df['toxic'].values, reference=lgb_train_set)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary', 'auc'},\n",
    "    'learning_rate': 0.2,\n",
    "    'num_iterations': 100,\n",
    "    'num_leaves': 51,\n",
    "    'device': 'cpu',\n",
    "    'num_threads': 24,\n",
    "    'max_depth': -1,\n",
    "#     'min_data_in_leaf': 5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'nthread': 4,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train_set,\n",
    "                valid_sets=lgb_eval_set,\n",
    "               verbose_eval=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9755264834289482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y = y_val_df['toxic']\n",
    "pred = gbm.predict(val_set['toxic'])\n",
    "print('accuracy is {}'.format(roc_auc_score(y,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_char = {v: k for k, v in char_vectorizer.vocabulary_.items()}\n",
    "inv_phrase = {v: k for k, v in phrase_vectorizer.vocabulary_.items()}\n",
    "features = []\n",
    "features_char = [inv_char[i] for i in range(0,train_char.shape[1] )]\n",
    "features_phrase = [inv_phrase[i] for i in range(0,train_phrase.shape[1])]\n",
    "features.extend(features_char)\n",
    "features.extend(features_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame()\n",
    "df_importance['score'] = pd.Series(gbm.feature_importance()) \n",
    "df_importance['feature'] = pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297477</th>\n",
       "      <td>26</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169110</th>\n",
       "      <td>21</td>\n",
       "      <td>shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237763</th>\n",
       "      <td>20</td>\n",
       "      <td>hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176280</th>\n",
       "      <td>20</td>\n",
       "      <td>tard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168581</th>\n",
       "      <td>20</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210956</th>\n",
       "      <td>18</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172670</th>\n",
       "      <td>18</td>\n",
       "      <td>stup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86948</th>\n",
       "      <td>17</td>\n",
       "      <td>fuc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101216</th>\n",
       "      <td>16</td>\n",
       "      <td>idi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59952</th>\n",
       "      <td>16</td>\n",
       "      <td>ck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59888</th>\n",
       "      <td>16</td>\n",
       "      <td>cist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89116</th>\n",
       "      <td>16</td>\n",
       "      <td>gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67012</th>\n",
       "      <td>15</td>\n",
       "      <td>diot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8848</th>\n",
       "      <td>15</td>\n",
       "      <td>dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37974</th>\n",
       "      <td>15</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68970</th>\n",
       "      <td>14</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136916</th>\n",
       "      <td>14</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164439</th>\n",
       "      <td>14</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126703</th>\n",
       "      <td>14</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183593</th>\n",
       "      <td>14</td>\n",
       "      <td>uck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148870</th>\n",
       "      <td>13</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23181</th>\n",
       "      <td>13</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16713</th>\n",
       "      <td>13</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17870</th>\n",
       "      <td>13</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95157</th>\n",
       "      <td>13</td>\n",
       "      <td>hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84793</th>\n",
       "      <td>13</td>\n",
       "      <td>fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177727</th>\n",
       "      <td>12</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19377</th>\n",
       "      <td>12</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198237</th>\n",
       "      <td>12</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100660</th>\n",
       "      <td>0</td>\n",
       "      <td>icle/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100659</th>\n",
       "      <td>0</td>\n",
       "      <td>icle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100658</th>\n",
       "      <td>0</td>\n",
       "      <td>icle-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100655</th>\n",
       "      <td>0</td>\n",
       "      <td>icle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100665</th>\n",
       "      <td>0</td>\n",
       "      <td>icly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100654</th>\n",
       "      <td>0</td>\n",
       "      <td>icl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100653</th>\n",
       "      <td>0</td>\n",
       "      <td>icky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100652</th>\n",
       "      <td>0</td>\n",
       "      <td>icky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100651</th>\n",
       "      <td>0</td>\n",
       "      <td>ickw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100650</th>\n",
       "      <td>0</td>\n",
       "      <td>ickt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100649</th>\n",
       "      <td>0</td>\n",
       "      <td>ickst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100664</th>\n",
       "      <td>0</td>\n",
       "      <td>icly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100666</th>\n",
       "      <td>0</td>\n",
       "      <td>icm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100682</th>\n",
       "      <td>0</td>\n",
       "      <td>icom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100675</th>\n",
       "      <td>0</td>\n",
       "      <td>ico w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>0</td>\n",
       "      <td>icolo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100680</th>\n",
       "      <td>0</td>\n",
       "      <td>icole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100679</th>\n",
       "      <td>0</td>\n",
       "      <td>icola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100678</th>\n",
       "      <td>0</td>\n",
       "      <td>icol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100677</th>\n",
       "      <td>0</td>\n",
       "      <td>icode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100676</th>\n",
       "      <td>0</td>\n",
       "      <td>icod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100674</th>\n",
       "      <td>0</td>\n",
       "      <td>ico t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100667</th>\n",
       "      <td>0</td>\n",
       "      <td>icn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100673</th>\n",
       "      <td>0</td>\n",
       "      <td>ico i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100672</th>\n",
       "      <td>0</td>\n",
       "      <td>ico c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100671</th>\n",
       "      <td>0</td>\n",
       "      <td>ico a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100670</th>\n",
       "      <td>0</td>\n",
       "      <td>ico .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100669</th>\n",
       "      <td>0</td>\n",
       "      <td>ico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100668</th>\n",
       "      <td>0</td>\n",
       "      <td>ico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>0</td>\n",
       "      <td>zuckerberg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score     feature\n",
       "297477     26         you\n",
       "169110     21        shit\n",
       "237763     20        hell\n",
       "176280     20        tard\n",
       "168581     20         sex\n",
       "210956     18          as\n",
       "172670     18        stup\n",
       "5          17            \n",
       "86948      17         fuc\n",
       "101216     16         idi\n",
       "59952      16          ck\n",
       "59888      16        cist\n",
       "89116      16         gay\n",
       "67012      15        diot\n",
       "8848       15        dick\n",
       "37974      15           ?\n",
       "68970      14           e\n",
       "136916     14           o\n",
       "164439     14          s \n",
       "126703     14           n\n",
       "183593     14         uck\n",
       "148870     13           p\n",
       "23181      13           )\n",
       "16713      13           s\n",
       "17870      13           t\n",
       "95157      13       hell \n",
       "84793      13         fag\n",
       "177727     12          th\n",
       "19377      12           w\n",
       "198237     12        your\n",
       "...       ...         ...\n",
       "100660      0       icle/\n",
       "100659      0       icle.\n",
       "100658      0       icle-\n",
       "100655      0        icle\n",
       "100665      0       icly \n",
       "100654      0         icl\n",
       "100653      0       icky \n",
       "100652      0        icky\n",
       "100651      0        ickw\n",
       "100650      0        ickt\n",
       "100649      0       ickst\n",
       "100664      0        icly\n",
       "100666      0         icm\n",
       "100682      0        icom\n",
       "100675      0       ico w\n",
       "100681      0       icolo\n",
       "100680      0       icole\n",
       "100679      0       icola\n",
       "100678      0        icol\n",
       "100677      0       icode\n",
       "100676      0        icod\n",
       "100674      0       ico t\n",
       "100667      0         icn\n",
       "100673      0       ico i\n",
       "100672      0       ico c\n",
       "100671      0       ico a\n",
       "100670      0       ico .\n",
       "100669      0        ico \n",
       "100668      0         ico\n",
       "299996      0  zuckerberg\n",
       "\n",
       "[299997 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86952</th>\n",
       "      <td>12</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233830</th>\n",
       "      <td>3</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score feature\n",
       "86952      12    fuck\n",
       "233830      3    fuck"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance[df_importance['feature'] == 'fuck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
