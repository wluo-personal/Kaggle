{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.calibration import CalibratedClassifierCV \n",
    "from sklearn.metrics import roc_auc_score \n",
    "from scipy.sparse import csr_matrix, hstack \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 30)\n",
      "(153164, 24)\n",
      "fitting char\n",
      "fitting phrase\n",
      "transforming train skip gram\n",
      "transforming train char\n",
      "transforming train phrase\n",
      "transforming test char\n",
      "transforming test phrase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'cleaned_train.csv')\n",
    "test = pd.read_csv(PATH + 'cleaned_test.csv')\n",
    "\n",
    "\n",
    "train_sentence = train['comment_text_cleaned_polarity']\n",
    "test_sentence = test['comment_text_cleaned_polarity']\n",
    "\n",
    "\n",
    "train_sentence_retain_punctuation = train['comment_text_cleaned_retain_punctuation']\n",
    "test_sentence_retain_punctuation = test['comment_text_cleaned_retain_punctuation']\n",
    "\n",
    "text = train_sentence\n",
    "\n",
    "text_retain_punctuation = train_sentence_retain_punctuation\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "###########################\n",
    "\n",
    "\n",
    "phrase_vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                    strip_accents='unicode', \n",
    "                                    max_features=100000, \n",
    "                                    analyzer='word',\n",
    "                                    sublinear_tf=True,\n",
    "                                    token_pattern=r'\\w{1,}')\n",
    "char_vectorizer = TfidfVectorizer(ngram_range=(2,5), \n",
    "                                  strip_accents='unicode', \n",
    "                                  max_features=200000, \n",
    "                                  analyzer='char', \n",
    "                                  sublinear_tf=True)\n",
    "\n",
    "print('fitting char')\n",
    "char_vectorizer.fit(text_retain_punctuation.values)\n",
    "print('fitting phrase')\n",
    "phrase_vectorizer.fit(text.values)\n",
    "\n",
    "print('transforming train skip gram')\n",
    "\n",
    "print('transforming train char')\n",
    "train_char = char_vectorizer.transform(train_sentence_retain_punctuation.values)\n",
    "print('transforming train phrase')\n",
    "train_phrase = phrase_vectorizer.transform(train_sentence.values)\n",
    "\n",
    "\n",
    "print('transforming test char')\n",
    "test_char = char_vectorizer.transform(test_sentence_retain_punctuation.values)\n",
    "print('transforming test phrase')\n",
    "test_phrase = phrase_vectorizer.transform(test_sentence.values)\n",
    "\n",
    "\n",
    "train_tfidf = hstack((train_char, train_phrase), format='csr')\n",
    "test_tfidf = hstack((test_char, test_phrase), format='csr')\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "#######################\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_val, y_train_df, y_val_df = train_test_split(train_tfidf, train, test_size=0.33)\n",
    "# # Split the dataset\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "split_index = round(len(train) * 0.9) #################################\n",
    "# shuffled_train = train#.sample(frac=1)\n",
    "x_train = train_tfidf[:split_index]\n",
    "y_train_df = train.iloc[:split_index]\n",
    "#######\n",
    "x_val = train_tfidf[split_index:]\n",
    "y_val_df = train.iloc[split_index:]\n",
    "# Get test data ready\n",
    "x_test = test_tfidf\n",
    "\n",
    "\n",
    "# train toxic\n",
    "def pr(y_i, y, train_features):\n",
    "    p = train_features[y==y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)\n",
    "r_dict = {label: np.log(pr(1, y_train_df[label].values, x_train) / pr(0,  y_train_df[label].values, x_train)) for label in label_cols}\n",
    "\n",
    "\n",
    "train_set = {label: x_train.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "val_set = {label: x_val.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "test_set = {label: x_test.multiply(r_dict[label]).tocsr() for label in r_dict }\n",
    "\n",
    "# del r_dict, x_train, x_val\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseLayerEstimator(ABC):\n",
    "    \n",
    "    def _pr(self, y_i, y, train_features):\n",
    "        p = train_features[np.array(y==y_i)].sum(0)\n",
    "        return (p + 1) / (np.array(y == y_i).sum() + 1)\n",
    "    \n",
    "    def _nb(self, x_train, y_train):\n",
    "        assert isinstance(y_train, pd.DataFrame)\n",
    "        r = {}\n",
    "        for col in y_train.columns:\n",
    "            print('calculating naive bayes for {}'.format(col))\n",
    "            r[col] = np.log(self._pr(1, y_train[col].values, x_train) / self._pr(0, y_train[col], x_train))\n",
    "        return r\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            x_train: np array\n",
    "            y_train: pd series\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, x_train):\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "class XGBoostBase(BaseLayerEstimator):\n",
    "    def __init__(self, x_train, y_train, params=None, nb=True, seed=0):\n",
    "        \"\"\"\n",
    "        constructor:\n",
    "\n",
    "            x_train: should be a np/scipy/ 2-d array or matrix. only be used when nb is true\n",
    "            y_train: should be a dataframe\n",
    "        \"\"\"\n",
    "        #### check naive bayes\n",
    "        if nb:\n",
    "            print('Naive Bayes is enabled')\n",
    "            self.r = self._nb(x_train, y_train)\n",
    "        else:\n",
    "            print('Naive Bayes is disabled')\n",
    "            self.r = None\n",
    "        ##### set values\n",
    "        self.seed = seed\n",
    "        self.nb = nb\n",
    "        self.set_params(params)\n",
    "        print('XGBoostBase is initialized')\n",
    "    \n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "        self.params['seed'] = self.seed\n",
    "    \n",
    "    \n",
    "    def _pre_process(self, x_train, y_train, label=None):\n",
    "        if self.nb:\n",
    "            assert label is not None\n",
    "            print('apply naive bayes to feature set')\n",
    "            x = x_train.multiply(self.r[label])\n",
    "            if isinstance(x_train, csr_matrix):\n",
    "                x = x.tocsr()\n",
    "        else:\n",
    "            x = x_train\n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y = y_train.values\n",
    "        else:\n",
    "            y = y_train\n",
    "        return (x, y)\n",
    "    \n",
    "    \n",
    "    def train(self, x_train, y_train, label=None):\n",
    "        x, y = self._pre_process(x_train, y_train, label)\n",
    "        self.params['eval_set'] = [x, y]\n",
    "        self.model = xgboost.XGBClassifier(**self.params)\n",
    "        self.model.fit(x,y)\n",
    "        \n",
    "        \n",
    "    def predict(self, x_train, label=None):\n",
    "        x, _ = self._pre_process(x_train, y_train=None, label=label)\n",
    "        print('starting predicting')\n",
    "        result = self.model.predict_proba(x)[:,1]\n",
    "        print('predicting done')\n",
    "        return result\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes is enabled\n",
      "calculating naive bayes for toxic\n",
      "calculating naive bayes for severe_toxic\n",
      "calculating naive bayes for obscene\n",
      "calculating naive bayes for threat\n",
      "calculating naive bayes for insult\n",
      "calculating naive bayes for identity_hate\n",
      "XGBoostBase is initialized\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'nthread': 20,\n",
    "    'n_estimators' : 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'eval_metric': 'auc',\n",
    "    'verbose_eval': 10,\n",
    "    'silent': False\n",
    "    } \n",
    "xx = XGBoostBase(train_tfidf, train[label_cols], params=params, nb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n",
      "severe_toxic\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n",
      "obscene\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n",
      "threat\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n",
      "insult\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n",
      "identity_hate\n",
      "apply naive bayes to feature set\n",
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['id'] = test['id']\n",
    "for col in label_cols:\n",
    "    print(col)\n",
    "    xx.train(train_tfidf, train[col], col)\n",
    "    result[col] = xx.predict(test_tfidf, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(PATH + 'xgbtest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=600,\n",
       "       n_jobs=1, nthread=20, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgboost.XGBClassifier()\n",
    "clf.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply naive bayes to feature set\n",
      "starting predicting\n",
      "predicting done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1148539 ,  0.00081353,  0.00049475, ...,  0.00089766,\n",
       "        0.00043752,  0.00040467], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.predict(test_tfidf, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.281409</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>1.641622e-02</td>\n",
       "      <td>0.987579</td>\n",
       "      <td>0.114854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>3.484975e-06</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.045801</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>1.816888e-05</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>5.671510e-06</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>7.531781e-06</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>5.061864e-05</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>1.354918e-06</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.178491</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>1.428693e-05</td>\n",
       "      <td>0.044514</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>4.769408e-07</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>1.275922e-06</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.689559</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.387596</td>\n",
       "      <td>1.099135e-05</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.035027</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.013859</td>\n",
       "      <td>1.011858e-05</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1.223115e-06</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.566632e-06</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>3.972904e-07</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>1.601638e-06</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.035907</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>1.203295e-05</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.002641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>1.926978e-06</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>4.773964e-07</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.022806</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>8.776693e-06</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>6.219589e-06</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.181538</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>5.071803e-03</td>\n",
       "      <td>0.018339</td>\n",
       "      <td>0.011966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>1.086847e-04</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.052330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>4.741286e-07</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.031067</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>3.956750e-06</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>1.802280e-05</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.000376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>4.018455e-06</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>2.664674e-06</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.105772</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>1.806282e-05</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>0.002853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>7.986750e-06</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153134</th>\n",
       "      <td>fff3ae2e177b6bb3</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>1.459915e-06</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>fff4109e837f7acc</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>8.011703e-06</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>fff4373a81ef9f2a</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>4.632679e-06</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>fff460574ddbcd80</td>\n",
       "      <td>0.054204</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.026273</td>\n",
       "      <td>1.002566e-03</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>fff4fc0a1555be5c</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>1.799771e-05</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>fff5b9bb944d634c</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>3.224532e-07</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>fff5c4a77fe0c05f</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>2.993710e-06</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>fff5fb61bd637c82</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>3.003599e-06</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>fff69311f306df44</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>3.939686e-06</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>fff6ad63666fb304</td>\n",
       "      <td>0.981816</td>\n",
       "      <td>0.112214</td>\n",
       "      <td>0.927569</td>\n",
       "      <td>2.238996e-05</td>\n",
       "      <td>0.445391</td>\n",
       "      <td>0.001589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>2.318148e-05</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>5.777157e-07</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>3.760620e-07</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>4.925228e-06</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.625338</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>1.911718e-06</td>\n",
       "      <td>0.013635</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.116346</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>1.050451e-04</td>\n",
       "      <td>0.064281</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>4.863203e-06</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.947260</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.446744</td>\n",
       "      <td>3.033726e-04</td>\n",
       "      <td>0.670359</td>\n",
       "      <td>0.010261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.043175</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>1.532017e-07</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.685155</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.419070</td>\n",
       "      <td>2.137856e-04</td>\n",
       "      <td>0.090254</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.934130</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.034539</td>\n",
       "      <td>6.688386e-05</td>\n",
       "      <td>0.339958</td>\n",
       "      <td>0.622887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.058757</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>1.662037e-05</td>\n",
       "      <td>0.994616</td>\n",
       "      <td>0.358714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.015034</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>2.704404e-05</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>2.356831e-07</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.824835</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>6.568503e-06</td>\n",
       "      <td>0.679136</td>\n",
       "      <td>0.001458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.211101</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>7.949834e-06</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>2.982202e-05</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>6.317881e-06</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>2.211029e-05</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.954652</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>7.101418e-05</td>\n",
       "      <td>0.233167</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene        threat  \\\n",
       "0       00001cee341fdb12  0.999947      0.281409  0.997474  1.641622e-02   \n",
       "1       0000247867823ef7  0.011992      0.000180  0.002092  3.484975e-06   \n",
       "2       00013b17ad220c46  0.045801      0.000435  0.014519  1.816888e-05   \n",
       "3       00017563c3f7919a  0.001886      0.000060  0.000670  5.671510e-06   \n",
       "4       00017695ad8997eb  0.020567      0.000131  0.004855  7.531781e-06   \n",
       "5       0001ea8717f6de06  0.004622      0.000115  0.001488  5.061864e-05   \n",
       "6       00024115d4cbde0f  0.001517      0.000013  0.002438  1.354918e-06   \n",
       "7       000247e83dcc1211  0.178491      0.000530  0.003522  1.428693e-05   \n",
       "8       00025358d4737918  0.012535      0.000158  0.006464  4.769408e-07   \n",
       "9       00026d1092fe71cc  0.005762      0.000029  0.001152  1.275922e-06   \n",
       "10      0002eadc3b301559  0.689559      0.000572  0.387596  1.099135e-05   \n",
       "11      0002f87b16116a7f  0.035027      0.000119  0.013859  1.011858e-05   \n",
       "12      0003806b11932181  0.001675      0.000017  0.000492  1.223115e-06   \n",
       "13      0003e1cccfd5a40a  0.002764      0.000008  0.000538  2.566632e-06   \n",
       "14      00059ace3e3e9a53  0.001280      0.000026  0.000367  3.972904e-07   \n",
       "15      000634272d0d44eb  0.003042      0.000175  0.000519  1.601638e-06   \n",
       "16      000663aff0fffc80  0.035907      0.001282  0.002707  1.203295e-05   \n",
       "17      000689dd34e20979  0.004613      0.000082  0.001642  1.926978e-06   \n",
       "18      000834769115370c  0.001649      0.000068  0.000810  4.773964e-07   \n",
       "19      000844b52dee5f3f  0.022806      0.000413  0.003437  8.776693e-06   \n",
       "20      00084da5d4ead7aa  0.016279      0.000948  0.002739  6.219589e-06   \n",
       "21      00091c35fa9d0465  0.181538      0.006059  0.022430  5.071803e-03   \n",
       "22      000968ce11f5ee34  0.042827      0.000050  0.004663  1.086847e-04   \n",
       "23      0009734200a85047  0.006670      0.000034  0.000385  4.741286e-07   \n",
       "24      00097b6214686db5  0.031067      0.000071  0.015600  3.956750e-06   \n",
       "25      0009aef4bd9e1697  0.006445      0.000048  0.002619  1.802280e-05   \n",
       "26      000a02d807ae0254  0.006370      0.000251  0.000650  4.018455e-06   \n",
       "27      000a6c6d4e89b9bc  0.010811      0.000299  0.002349  2.664674e-06   \n",
       "28      000bafe2080bba82  0.105772      0.000118  0.001511  1.806282e-05   \n",
       "29      000bf0a9894b2807  0.015808      0.000044  0.003058  7.986750e-06   \n",
       "...                  ...       ...           ...       ...           ...   \n",
       "153134  fff3ae2e177b6bb3  0.008076      0.000004  0.001022  1.459915e-06   \n",
       "153135  fff4109e837f7acc  0.006237      0.000117  0.001161  8.011703e-06   \n",
       "153136  fff4373a81ef9f2a  0.003804      0.000017  0.000686  4.632679e-06   \n",
       "153137  fff460574ddbcd80  0.054204      0.000161  0.026273  1.002566e-03   \n",
       "153138  fff4fc0a1555be5c  0.006126      0.000025  0.001820  1.799771e-05   \n",
       "153139  fff5b9bb944d634c  0.003467      0.000182  0.000586  3.224532e-07   \n",
       "153140  fff5c4a77fe0c05f  0.011065      0.000255  0.001997  2.993710e-06   \n",
       "153141  fff5fb61bd637c82  0.006092      0.000106  0.000576  3.003599e-06   \n",
       "153142  fff69311f306df44  0.014568      0.000686  0.003669  3.939686e-06   \n",
       "153143  fff6ad63666fb304  0.981816      0.112214  0.927569  2.238996e-05   \n",
       "153144  fff7159b3ee95618  0.009851      0.000110  0.003044  2.318148e-05   \n",
       "153145  fff718ffe5f05559  0.007341      0.000106  0.001265  5.777157e-07   \n",
       "153146  fff7fc22a0cdccd3  0.003669      0.000055  0.003387  3.760620e-07   \n",
       "153147  fff83b80284d8440  0.004936      0.000020  0.001706  4.925228e-06   \n",
       "153148  fff8ef316d0c6990  0.625338      0.000162  0.003683  1.911718e-06   \n",
       "153149  fff8f521a7dbcd47  0.116346      0.000385  0.013532  1.050451e-04   \n",
       "153150  fff8f64043129fa2  0.003278      0.000035  0.000824  4.863203e-06   \n",
       "153151  fff9d70fe0722906  0.947260      0.033824  0.446744  3.033726e-04   \n",
       "153152  fff9fa508f400ee6  0.043175      0.000058  0.024936  1.532017e-07   \n",
       "153153  fffa3fae1890b40a  0.685155      0.000212  0.419070  2.137856e-04   \n",
       "153154  fffa8a11c4378854  0.934130      0.036640  0.034539  6.688386e-05   \n",
       "153155  fffac2a094c8e0e2  0.999973      0.058757  0.999382  1.662037e-05   \n",
       "153156  fffb5451268fb5ba  0.015034      0.000039  0.004134  2.704404e-05   \n",
       "153157  fffc2b34bbe61c8d  0.005410      0.000042  0.000642  2.356831e-07   \n",
       "153158  fffc489742ffe69b  0.824835      0.001548  0.192301  6.568503e-06   \n",
       "153159  fffcd0960ee309b5  0.211101      0.000624  0.022066  7.949834e-06   \n",
       "153160  fffd7a9a6eb32c16  0.012194      0.000224  0.008840  2.982202e-05   \n",
       "153161  fffda9e8d6fafa9e  0.003319      0.000036  0.002491  6.317881e-06   \n",
       "153162  fffe8f1340a79fc2  0.006827      0.000124  0.002020  2.211029e-05   \n",
       "153163  ffffce3fb183ee80  0.954652      0.000050  0.955315  7.101418e-05   \n",
       "\n",
       "          insult  identity_hate  \n",
       "0       0.987579       0.114854  \n",
       "1       0.008555       0.000814  \n",
       "2       0.007328       0.000495  \n",
       "3       0.000987       0.000080  \n",
       "4       0.003565       0.000179  \n",
       "5       0.002206       0.000040  \n",
       "6       0.003876       0.000061  \n",
       "7       0.044514       0.000645  \n",
       "8       0.001734       0.000846  \n",
       "9       0.003141       0.000030  \n",
       "10      0.009483       0.002060  \n",
       "11      0.005367       0.000109  \n",
       "12      0.002691       0.000070  \n",
       "13      0.001074       0.000029  \n",
       "14      0.000362       0.000016  \n",
       "15      0.000959       0.000121  \n",
       "16      0.012464       0.002641  \n",
       "17      0.001406       0.000039  \n",
       "18      0.000401       0.000022  \n",
       "19      0.004520       0.000189  \n",
       "20      0.003404       0.000414  \n",
       "21      0.018339       0.011966  \n",
       "22      0.019523       0.052330  \n",
       "23      0.003511       0.000203  \n",
       "24      0.005192       0.000150  \n",
       "25      0.005164       0.000376  \n",
       "26      0.000741       0.000118  \n",
       "27      0.007793       0.001039  \n",
       "28      0.015360       0.002853  \n",
       "29      0.003081       0.000071  \n",
       "...          ...            ...  \n",
       "153134  0.001299       0.000021  \n",
       "153135  0.001086       0.000175  \n",
       "153136  0.000200       0.000041  \n",
       "153137  0.011384       0.001103  \n",
       "153138  0.005583       0.000185  \n",
       "153139  0.000757       0.000180  \n",
       "153140  0.003847       0.000157  \n",
       "153141  0.000813       0.000160  \n",
       "153142  0.008513       0.000732  \n",
       "153143  0.445391       0.001589  \n",
       "153144  0.010895       0.000121  \n",
       "153145  0.007821       0.000064  \n",
       "153146  0.002384       0.000012  \n",
       "153147  0.000984       0.000079  \n",
       "153148  0.013635       0.001375  \n",
       "153149  0.064281       0.001340  \n",
       "153150  0.001849       0.000123  \n",
       "153151  0.670359       0.010261  \n",
       "153152  0.002434       0.000085  \n",
       "153153  0.090254       0.000949  \n",
       "153154  0.339958       0.622887  \n",
       "153155  0.994616       0.358714  \n",
       "153156  0.002406       0.000273  \n",
       "153157  0.001477       0.000043  \n",
       "153158  0.679136       0.001458  \n",
       "153159  0.008451       0.000473  \n",
       "153160  0.009315       0.000591  \n",
       "153161  0.001593       0.000898  \n",
       "153162  0.006932       0.000438  \n",
       "153163  0.233167       0.000405  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
