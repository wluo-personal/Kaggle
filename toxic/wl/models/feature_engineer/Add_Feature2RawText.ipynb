{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'cleaned_train.csv')\n",
    "test = pd.read_csv(PATH + 'cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_train = pd.DataFrame()\n",
    "pd_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".    627750\n",
       "?    125691\n",
       "-     95898\n",
       ")     90458\n",
       ":     87338\n",
       "(     84749\n",
       "'     81880\n",
       "!     64191\n",
       "/     40234\n",
       ";     18165\n",
       "|     13967\n",
       "_     11677\n",
       "]      7441\n",
       "[      6846\n",
       "{      6351\n",
       "}      5991\n",
       "#      5941\n",
       "%      4939\n",
       "*      4743\n",
       "&      3012\n",
       "+      2633\n",
       ">      1623\n",
       "@      1622\n",
       "$       967\n",
       "^       655\n",
       "\\       567\n",
       "`       538\n",
       "<       519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import string\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# char_vectorizer = CountVectorizer(ngram_range=(1,1), \n",
    "#                                   strip_accents='unicode', \n",
    "#                                   analyzer='char')\n",
    "# char_vectorizer.fit(train.comment_text_cleaned_retain_punctuation.values)\n",
    "# char_matrix = char_vectorizer.transform(train.comment_text_cleaned_retain_punctuation.values)\n",
    "# char_sum = np.array(char_matrix.sum(0))[0]\n",
    "\n",
    "# char_index_map = {}\n",
    "# for each in f'([{string.punctuation}\"“”¨«»®´·º½¾¿¡§£₤‘’])':\n",
    "#     try:\n",
    "#         char_index_map[each] = char_vectorizer.vocabulary_[each]\n",
    "#     except Exception as e:\n",
    "#         pass\n",
    "# char_index_count = pd.Series()\n",
    "# # char_index_values = list(char_index_map.values())\n",
    "# for each in char_index_map:\n",
    "#     char_index_count[each] = char_sum[char_index_map[each]]\n",
    "    \n",
    "# char_index_count.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 1. '?' Count\n",
    "f1 = lambda x: ' count_qesmark_{}'.format(x.count('?')) if x.count('?') <= 20 else ' count_qesmark_21'\n",
    "pd_train['count_qesmark'] = train.comment_text_cleaned_retain_punctuation.apply(f1)\n",
    "pd_test['count_qesmark'] = test.comment_text_cleaned_retain_punctuation.apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature 2. '!' Count\n",
    "f2 = lambda x: ' count_exclamation_{}'.format(x.count('!')) if x.count('!') <= 20 else ' count_exclamation_21'\n",
    "pd_train['count_exclamation'] = train.comment_text_cleaned_retain_punctuation.apply(f2)\n",
    "pd_test['count_exclamation'] = test.comment_text_cleaned_retain_punctuation.apply(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 3. '...' Count\n",
    "f3 = lambda x: ' count_threedot_{}'.format(x.count('...')) if x.count('...') <= 20 else ' count_threedot_21'\n",
    "pd_train['count_exclamation'] = train.comment_text_cleaned_retain_punctuation.apply(f3)\n",
    "pd_test['count_exclamation'] = test.comment_text_cleaned_retain_punctuation.apply(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 4. '..' Count\n",
    "f4 = lambda x: ' count_twodot_{}'.format(x.count('..')) if x.count('..') <= 20 else ' count_twodot_21'\n",
    "pd_train['count_twodot'] = train.comment_text_cleaned_retain_punctuation.apply(f4)\n",
    "pd_test['count_twodot'] = test.comment_text_cleaned_retain_punctuation.apply(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 5. '*' Count\n",
    "f5 = lambda x: ' count_star_{}'.format(x.count('*')) if x.count('*') <= 20 else ' count_star_21'\n",
    "pd_train['count_star'] = train.comment_text_cleaned_retain_punctuation.apply(f5)\n",
    "pd_test['count_star'] = test.comment_text_cleaned_retain_punctuation.apply(f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 50. '$' Count\n",
    "f50 = lambda x: ' count_dollarsign_{}'.format(x.count('$')) if x.count('$') <= 20 else ' count_dollarsign_21'\n",
    "pd_train['count_dollarsign'] = train.comment_text_cleaned_retain_punctuation.apply(f50)\n",
    "pd_test['count_dollarsign'] = test.comment_text_cleaned_retain_punctuation.apply(f50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Feature 51. '-' Count\n",
    "# f51 = lambda x: 'count_subtract_{}'.format(x.count('-')) if x.count('-') <= 20 else 'count_subtract_21'\n",
    "# pd_train['count_subtract'] = train.comment_text_cleaned_retain_punctuation.apply(f51)\n",
    "# pd_test['count_subtract'] = test.comment_text_cleaned_retain_punctuation.apply(f51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Feature 52. ':' Count\n",
    "# f52 = lambda x: 'count_colon_{}'.format(x.count(':')) if x.count(':') <= 20 else 'count_colon_21'\n",
    "# pd_train['count_colon'] = train.comment_text_cleaned_retain_punctuation.apply(f52)\n",
    "# pd_test['count_colon'] = test.comment_text_cleaned_retain_punctuation.apply(f52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Feature 53. ',' Count\n",
    "# f52 = lambda x: 'count_comma_{}'.format(x.count(',')) if x.count(',') <= 20 else 'count_comma_21'\n",
    "# pd_train['count_comma'] = train.comment_text_cleaned_retain_punctuation.apply(f52)\n",
    "# pd_test['count_comma'] = test.comment_text_cleaned_retain_punctuation.apply(f52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Feature 6. word Count\n",
    "p_25 = train['word_count'].describe()['25%']\n",
    "p_50 = train['word_count'].describe()['50%']\n",
    "p_75 = train['word_count'].describe()['75%']\n",
    "\n",
    "def f6(x):\n",
    "    base = ' count_word_{}'\n",
    "    if x < p_25:\n",
    "        return base.format(25)\n",
    "    elif p_25 <= x < p_50:\n",
    "        return base.format(50)\n",
    "    elif p_50 <= x < p_75:\n",
    "        return base.format(75)\n",
    "    else:\n",
    "        return base.format(100)\n",
    "\n",
    "pd_train['count_word'] = train['word_count'].apply(f6)\n",
    "pd_test['count_word'] = test['word_count'].apply(f6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Feature 7. unique word Count\n",
    "# p_25 = train['unique_word_count'].describe()['25%']\n",
    "# p_50 = train['unique_word_count'].describe()['50%']\n",
    "# p_75 = train['unique_word_count'].describe()['75%']\n",
    "\n",
    "# def f7(x):\n",
    "#     base = 'count_unique_word_{}'\n",
    "#     if x < p_25:\n",
    "#         return base.format(25)\n",
    "#     elif p_25 <= x < p_50:\n",
    "#         return base.format(50)\n",
    "#     elif p_50 <= x < p_75:\n",
    "#         return base.format(75)\n",
    "#     else:\n",
    "#         return base.format(100)\n",
    "\n",
    "# pd_train['count_unique_word'] = train['unique_word_count'].apply(f7)\n",
    "# pd_test['count_unique_word'] = test['unique_word_count'].apply(f7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_feature = pd.DataFrame()\n",
    "# df_feature_test =  pd.DataFrame()\n",
    "# df_feature['count_char'] = train['comment_text_cleaned'].apply(lambda x: len(x))\n",
    "# df_feature_test['count_char'] = test['comment_text_cleaned'].apply(lambda x: len(x))\n",
    "# df_feature['count_unique_char'] = train['comment_text_cleaned'].apply(lambda x: len(set(x.split())))\n",
    "# df_feature_test['count_unique_char'] = test['comment_text_cleaned'].apply(lambda x: len(set(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Feature 8. char Count\n",
    "\n",
    "# p_25 = df_feature['count_char'].describe()['25%']\n",
    "# p_50 = df_feature['count_char'].describe()['50%']\n",
    "# p_75 = df_feature['count_char'].describe()['75%']\n",
    "\n",
    "\n",
    "# def f8(x):\n",
    "#     base = 'count_char_{}'\n",
    "#     if x < p_25:\n",
    "#         return base.format(25)\n",
    "#     elif p_25 <= x < p_50:\n",
    "#         return base.format(50)\n",
    "#     elif p_50 <= x < p_75:\n",
    "#         return base.format(75)\n",
    "#     else:\n",
    "#         return base.format(100)\n",
    "\n",
    "# pd_train['count_char'] = df_feature['count_char'].apply(f8)\n",
    "# pd_test['count_char'] = df_feature_test['count_char'].apply(f8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Feature 9. unique char Count\n",
    "\n",
    "# p_25 = df_feature['count_unique_char'].describe()['25%']\n",
    "# p_50 = df_feature['count_unique_char'].describe()['50%']\n",
    "# p_75 = df_feature['count_unique_char'].describe()['75%']\n",
    "\n",
    "\n",
    "# def f9(x):\n",
    "#     base = 'count_unique_char_{}'\n",
    "#     if x < p_25:\n",
    "#         return base.format(25)\n",
    "#     elif p_25 <= x < p_50:\n",
    "#         return base.format(50)\n",
    "#     elif p_50 <= x < p_75:\n",
    "#         return base.format(75)\n",
    "#     else:\n",
    "#         return base.format(100)\n",
    "\n",
    "# pd_train['count_unique_char'] = df_feature['count_unique_char'].apply(f9)\n",
    "# pd_test['count_unique_char'] = df_feature_test['count_unique_char'].apply(f9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text_cleaned_features'] = train['comment_text_cleaned_polarity'].copy()\n",
    "test['comment_text_cleaned_features'] = test['comment_text_cleaned_polarity'].copy()\n",
    "for each in pd_train.columns:\n",
    "    train['comment_text_cleaned_features'] = train['comment_text_cleaned_features'] + pd_train[each]\n",
    "    test['comment_text_cleaned_features'] = test['comment_text_cleaned_features'] + pd_test[each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(PATH + 'cleaned_train.csv', index=False)\n",
    "test.to_csv(PATH + 'cleaned_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
